{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mittelmanjournal/NFL-Neural-Network-Project/blob/main/Unoptimized_NFL_neural_net_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[MPG Regression for car data](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb)\n",
        "\n",
        "\n",
        "[Fashion image classification neural network](https://colab.research.google.com/github/mmphego/TensorFlow-Course/blob/master/fashion_mnist.ipynb)\n",
        "\n",
        "Above are the two Google Colab pages that I read through to understand how to create my own network."
      ],
      "metadata": {
        "id": "j7OfHyeo9Nf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary libraries**\n",
        "\n",
        "This code sets up the basics for machine learning in a Google Colaboratory notebook. It imports TensorFlow, a powerful machine learning library, along with NumPy for numerical operations, Matplotlib for plotting, and Pandas for data manipulation. The last line prints the TensorFlow version, useful for checking compatibility and features. Overall, it's a starting point for machine learning tasks, ensuring the necessary tools are available."
      ],
      "metadata": {
        "id": "aersvL3cwmv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzLKpmZICaWN",
        "outputId": "8cba890d-3720-4cde-c12c-b9abc23cb698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Copy the dataset into the workspace**\n",
        "and then get all of the feature/column names from the first line in the dataset.\n",
        "The class names (the different ways the neural net can \"interpret\" the input) are simply \"away win\", \"tie\", \"home win\". Then drop the first row from the dataset because these are the column names we already saved.\n",
        "<P>The first column in the dataset as we see it printed below represents the TRUE/ACTUAL output given that input, where 0 represents away win, 1 represents tie and 2 represents home win</P>\n"
      ],
      "metadata": {
        "id": "KVxxzzhdyM5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "328ed59c-1f0b-4022-f676-bdc8d1ea00ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "1          2           1        2002        0         8      0  2002   \n",
              "2          2           1        2002        0         8      0  2002   \n",
              "3          0           1        2002        0         8      0  2002   \n",
              "4          2           1        2002        0         8      0  2002   \n",
              "5          0           1        2002        0         8      0  2002   \n",
              "...      ...         ...         ...      ...       ...    ...   ...   \n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "1             1304        3      0  ...             0.421384   \n",
              "2             1304        3      2  ...             0.333333   \n",
              "3             1304        3      0  ...             0.340426   \n",
              "4             1304        3      0  ...             0.441860   \n",
              "5             1304        3      0  ...             0.000000   \n",
              "...            ...      ...    ...  ...                  ...   \n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "1                0.610063             0.528302             0.503145   \n",
              "2                0.545455             0.454545             0.787879   \n",
              "3                0.404255             0.340426             0.340426   \n",
              "4                0.674419             0.593023             0.651163   \n",
              "5                0.000000             0.000000             0.000000   \n",
              "...                   ...                  ...                  ...   \n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "1                0.364780           0.251572           0.132075   \n",
              "2                0.575758           0.060606           0.060606   \n",
              "3                0.191489           0.000000           0.000000   \n",
              "4                0.476744           0.151163           0.069767   \n",
              "5                0.000000           0.000000           0.000000   \n",
              "...                   ...                ...                ...   \n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "1           52.100000       1.767296       1.723270  \n",
              "2           51.000000       1.727273       1.727273  \n",
              "3           47.333333       1.510638       1.468085  \n",
              "4           50.200000       2.546512       2.500000  \n",
              "5            0.000000       0.000000       0.000000  \n",
              "...               ...            ...            ...  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5232 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3245bfed-2802-4f4a-a10b-234e390554ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.421384</td>\n",
              "      <td>0.610063</td>\n",
              "      <td>0.528302</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>0.364780</td>\n",
              "      <td>0.251572</td>\n",
              "      <td>0.132075</td>\n",
              "      <td>52.100000</td>\n",
              "      <td>1.767296</td>\n",
              "      <td>1.723270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.727273</td>\n",
              "      <td>1.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.333333</td>\n",
              "      <td>1.510638</td>\n",
              "      <td>1.468085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.476744</td>\n",
              "      <td>0.151163</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>50.200000</td>\n",
              "      <td>2.546512</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2002</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5232 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3245bfed-2802-4f4a-a10b-234e390554ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3245bfed-2802-4f4a-a10b-234e390554ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3245bfed-2802-4f4a-a10b-234e390554ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f79e6b29-bfed-4b1f-ade5-d41a55c17ab0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f79e6b29-bfed-4b1f-ade5-d41a55c17ab0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f79e6b29-bfed-4b1f-ade5-d41a55c17ab0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#upload the file to this path, drag and drop dataset\n",
        "file_path = '/content/sample_data/dataset.csv'\n",
        "# Specify skiprows=1 to skip the first row (header) since we will use it as column names\n",
        "raw_dataset = pd.read_csv(file_path, na_values='?', comment='\\t',\n",
        "                          sep=',', skipinitialspace=True, skiprows=0)\n",
        "\n",
        "# The column names are automatically inferred from the header row\n",
        "column_names = raw_dataset.columns.tolist()\n",
        "class_names = ['away win','tie','home win']\n",
        "\n",
        "raw_dataset.drop(index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "oNcLBE1I3Uwl",
        "outputId": "03e62260-1ad9-40ac-a3f2-c38362daacf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c6011a2-c9d4-4edc-9579-a6ef32aa136e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c6011a2-c9d4-4edc-9579-a6ef32aa136e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c6011a2-c9d4-4edc-9579-a6ef32aa136e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c6011a2-c9d4-4edc-9579-a6ef32aa136e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9acabbb0-8088-45a8-a622-6635a0d328e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9acabbb0-8088-45a8-a622-6635a0d328e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9acabbb0-8088-45a8-a622-6635a0d328e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Drop any \"bad\" values**"
      ],
      "metadata": {
        "id": "BXCXiDlM24fK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meHViIVw3VKR",
        "outputId": "882c3522-9333-45a5-93b0-e1cac7a717f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "winner               0\n",
              "seasonWeek           0\n",
              "seasonYear           0\n",
              "weekday              0\n",
              "monthDay             0\n",
              "                    ..\n",
              "home_K_fga_50+_pg    0\n",
              "home_K_fgm_50+_pg    0\n",
              "home_K_fglng_ps      0\n",
              "home_K_xpa_pg        0\n",
              "home_K_xpm_pg        0\n",
              "Length: 702, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x6p-jbxl4jIG"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "pjFS7TbE4lep",
        "outputId": "fb70becd-ed03-4195-dda1-dc3a97bf0756"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      winner  seasonWeek  seasonYear  weekday  monthDay  month  year  \\\n",
              "5228       2          19        2021        6        15      4  2022   \n",
              "5229       2          19        2021        0        16      4  2022   \n",
              "5230       0          19        2021        0        16      4  2022   \n",
              "5231       2          19        2021        0        16      4  2022   \n",
              "5232       2          19        2021        1        17      4  2022   \n",
              "\n",
              "      militaryTime  stadium  field  ...  home_K_fgm_20-29_pg  \\\n",
              "5228          2015        3      3  ...             0.631579   \n",
              "5229          1300        3      0  ...             0.389474   \n",
              "5230          1640        1     -1  ...             0.405797   \n",
              "5231          2015        3      0  ...             0.500000   \n",
              "5232          2015        0     -1  ...             0.320000   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "5228             0.473684             0.315789             0.631579   \n",
              "5229             0.510526             0.473684             0.600000   \n",
              "5230             0.659420             0.608696             0.550725   \n",
              "5231             0.685714             0.642857             0.585714   \n",
              "5232             0.640000             0.520000             0.880000   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "5228             0.473684           0.473684           0.368421   \n",
              "5229             0.457895           0.210526           0.115789   \n",
              "5230             0.434783           0.485507           0.275362   \n",
              "5231             0.500000           0.300000           0.214286   \n",
              "5232             0.720000           0.360000           0.240000   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "5228        58.000000       5.684211       5.526316  \n",
              "5229        50.583333       2.489474       2.389474  \n",
              "5230        57.111111       2.572464       2.463768  \n",
              "5231        55.250000       4.028571       3.785714  \n",
              "5232        54.500000       4.520000       4.280000  \n",
              "\n",
              "[5 rows x 702 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dc62195-a277-45fb-b1c0-c3f55579437e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winner</th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5228</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>5.684211</td>\n",
              "      <td>5.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.457895</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>50.583333</td>\n",
              "      <td>2.489474</td>\n",
              "      <td>2.389474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>1640</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.485507</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>57.111111</td>\n",
              "      <td>2.572464</td>\n",
              "      <td>2.463768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>3.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>4.280000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 702 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dc62195-a277-45fb-b1c0-c3f55579437e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dc62195-a277-45fb-b1c0-c3f55579437e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dc62195-a277-45fb-b1c0-c3f55579437e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-328a9bde-1757-4e09-bb02-34eabd2c51ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-328a9bde-1757-4e09-bb02-34eabd2c51ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-328a9bde-1757-4e09-bb02-34eabd2c51ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset.tail() # can also do dataset.head() to see front"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **80% of the dataset will be used for training and 20% will be used to test how well the neural net can generalize to data it hasn't seen before**"
      ],
      "metadata": {
        "id": "ERLSshJl3HBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FWHtNJwP4i-l"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TP1qzu-Q6p6d",
        "outputId": "8abad292-1d09-413a-ed28-0940b6519ac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    count         mean        std     min          25%  \\\n",
              "winner             4186.0     1.141185   0.989015     0.0     0.000000   \n",
              "seasonWeek         4186.0     9.342570   5.277457     1.0     5.000000   \n",
              "seasonYear         4186.0  2012.384615   6.346596  2002.0  2007.000000   \n",
              "weekday            4186.0     0.454849   1.353606     0.0     0.000000   \n",
              "monthDay           4186.0    15.794314   8.666252     1.0     9.000000   \n",
              "...                   ...          ...        ...     ...          ...   \n",
              "home_K_fga_50+_pg  4186.0     0.185284   0.134692     0.0     0.104265   \n",
              "home_K_fgm_50+_pg  4186.0     0.108272   0.090102     0.0     0.048913   \n",
              "home_K_fglng_ps    4186.0    42.153775  19.773753     0.0    46.125000   \n",
              "home_K_xpa_pg      4186.0     2.166116   1.257211     0.0     1.976870   \n",
              "home_K_xpm_pg      4186.0     2.117324   1.230122     0.0     1.939297   \n",
              "\n",
              "                           50%          75%     max  \n",
              "winner                2.000000     2.000000     2.0  \n",
              "seasonWeek            9.000000    14.000000    21.0  \n",
              "seasonYear         2012.000000  2018.000000  2023.0  \n",
              "weekday               0.000000     0.000000     6.0  \n",
              "monthDay             16.000000    23.000000    31.0  \n",
              "...                        ...          ...     ...  \n",
              "home_K_fga_50+_pg     0.178759     0.270588     2.0  \n",
              "home_K_fgm_50+_pg     0.096154     0.153846     1.0  \n",
              "home_K_fglng_ps      50.900000    53.000000    62.0  \n",
              "home_K_xpa_pg         2.333333     2.700000    20.0  \n",
              "home_K_xpm_pg         2.280710     2.636364    20.0  \n",
              "\n",
              "[702 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54a8c7ba-f405-440a-bd1c-1d384435dc82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>winner</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>1.141185</td>\n",
              "      <td>0.989015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonWeek</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>9.342570</td>\n",
              "      <td>5.277457</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonYear</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2012.384615</td>\n",
              "      <td>6.346596</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>2012.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>2023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekday</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.454849</td>\n",
              "      <td>1.353606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthDay</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>15.794314</td>\n",
              "      <td>8.666252</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.185284</td>\n",
              "      <td>0.134692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104265</td>\n",
              "      <td>0.178759</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>0.108272</td>\n",
              "      <td>0.090102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048913</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>42.153775</td>\n",
              "      <td>19.773753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.125000</td>\n",
              "      <td>50.900000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2.166116</td>\n",
              "      <td>1.257211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.976870</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "      <td>4186.0</td>\n",
              "      <td>2.117324</td>\n",
              "      <td>1.230122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.939297</td>\n",
              "      <td>2.280710</td>\n",
              "      <td>2.636364</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>702 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54a8c7ba-f405-440a-bd1c-1d384435dc82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54a8c7ba-f405-440a-bd1c-1d384435dc82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54a8c7ba-f405-440a-bd1c-1d384435dc82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb623e51-3d26-44ab-9199-fab6caf93ec7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb623e51-3d26-44ab-9199-fab6caf93ec7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb623e51-3d26-44ab-9199-fab6caf93ec7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_dataset.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the data into the inputs/features and the outputs/labels of each input**\n",
        "\n",
        "for both the test and training data"
      ],
      "metadata": {
        "id": "z1rBqCFp5esj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "U5awj7rR63tp",
        "outputId": "58ccc49f-ff58-43f2-c6c0-5d88933509fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      seasonWeek  seasonYear  weekday  monthDay  month  year  militaryTime  \\\n",
              "3483           5        2017        0         8      1  2017          1300   \n",
              "1591          13        2008        0        30      2  2008          1302   \n",
              "3727           5        2018        0         7      1  2018          1625   \n",
              "3863          16        2018        6        22      3  2018          1630   \n",
              "1876          17        2009        0         3      4  2010          1304   \n",
              "\n",
              "      stadium  field  visSeasonWinsComingIntoGame  ...  home_K_fgm_20-29_pg  \\\n",
              "3483        3      0                            3  ...             0.000000   \n",
              "1591        3      0                            6  ...             0.407407   \n",
              "3727        3      0                            2  ...             0.388889   \n",
              "3863        3      0                            7  ...             0.378378   \n",
              "1876        3      0                           13  ...             0.460076   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "3483             0.000000             0.000000             0.000000   \n",
              "1591             0.567901             0.493827             0.506173   \n",
              "3727             0.500000             0.333333             0.833333   \n",
              "3863             0.472973             0.425676             0.628378   \n",
              "1876             0.555133             0.494297             0.524715   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "3483             0.000000           0.000000           0.000000   \n",
              "1591             0.382716           0.086420           0.024691   \n",
              "3727             0.777778           0.388889           0.333333   \n",
              "3863             0.500000           0.216216           0.114865   \n",
              "1876             0.391635           0.277567           0.144487   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "3483         0.000000       0.000000       0.000000  \n",
              "1591        50.333333       2.234568       2.197531  \n",
              "3727        61.000000       3.277778       3.000000  \n",
              "3863        52.222222       2.216216       2.162162  \n",
              "1876        50.823529       2.034221       1.988593  \n",
              "\n",
              "[5 rows x 701 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-757f9a34-80c4-4ef4-8f71-d0ebd3e857da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>visSeasonWinsComingIntoGame</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3483</th>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2017</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1591</th>\n",
              "      <td>13</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>1302</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.567901</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>50.333333</td>\n",
              "      <td>2.234568</td>\n",
              "      <td>2.197531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3727</th>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>1625</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>3.277778</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>16</td>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2018</td>\n",
              "      <td>1630</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>2.216216</td>\n",
              "      <td>2.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>17</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.460076</td>\n",
              "      <td>0.555133</td>\n",
              "      <td>0.494297</td>\n",
              "      <td>0.524715</td>\n",
              "      <td>0.391635</td>\n",
              "      <td>0.277567</td>\n",
              "      <td>0.144487</td>\n",
              "      <td>50.823529</td>\n",
              "      <td>2.034221</td>\n",
              "      <td>1.988593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 701 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-757f9a34-80c4-4ef4-8f71-d0ebd3e857da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-757f9a34-80c4-4ef4-8f71-d0ebd3e857da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-757f9a34-80c4-4ef4-8f71-d0ebd3e857da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9716d900-750a-4046-a234-24e2877fd05c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9716d900-750a-4046-a234-24e2877fd05c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9716d900-750a-4046-a234-24e2877fd05c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('winner')\n",
        "test_labels = test_features.pop('winner')\n",
        "\n",
        "train_features.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jlyMnxgS7FtK",
        "outputId": "a3d5534e-a1ef-43fd-f3bc-e3285919d8a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          mean        std\n",
              "winner                1.141185   0.989015\n",
              "seasonWeek            9.342570   5.277457\n",
              "seasonYear         2012.384615   6.346596\n",
              "weekday               0.454849   1.353606\n",
              "monthDay             15.794314   8.666252\n",
              "...                        ...        ...\n",
              "home_K_fga_50+_pg     0.185284   0.134692\n",
              "home_K_fgm_50+_pg     0.108272   0.090102\n",
              "home_K_fglng_ps      42.153775  19.773753\n",
              "home_K_xpa_pg         2.166116   1.257211\n",
              "home_K_xpm_pg         2.117324   1.230122\n",
              "\n",
              "[702 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-883e5459-63fb-4d3f-a76e-d149241f14e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>winner</th>\n",
              "      <td>1.141185</td>\n",
              "      <td>0.989015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonWeek</th>\n",
              "      <td>9.342570</td>\n",
              "      <td>5.277457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seasonYear</th>\n",
              "      <td>2012.384615</td>\n",
              "      <td>6.346596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekday</th>\n",
              "      <td>0.454849</td>\n",
              "      <td>1.353606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monthDay</th>\n",
              "      <td>15.794314</td>\n",
              "      <td>8.666252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <td>0.185284</td>\n",
              "      <td>0.134692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <td>0.108272</td>\n",
              "      <td>0.090102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <td>42.153775</td>\n",
              "      <td>19.773753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <td>2.166116</td>\n",
              "      <td>1.257211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "      <td>2.117324</td>\n",
              "      <td>1.230122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>702 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-883e5459-63fb-4d3f-a76e-d149241f14e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-883e5459-63fb-4d3f-a76e-d149241f14e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-883e5459-63fb-4d3f-a76e-d149241f14e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5d89e59-94bb-49ab-9403-92b6f4c4b679\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5d89e59-94bb-49ab-9403-92b6f4c4b679')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5d89e59-94bb-49ab-9403-92b6f4c4b679 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_dataset.describe().transpose()[['mean', 'std']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalize training features**\n",
        "\n",
        "each feature/column's values are all normalized with a mean of 0 and a standard deviation of 1 (done because parameter axis=-1), read more [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization)"
      ],
      "metadata": {
        "id": "xh9PRBQI8-FL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n5g0wiXA7Q3B"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8asWeQO47iRn"
      },
      "outputs": [],
      "source": [
        "normalizer.adapt(np.array(train_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gTBrf8jb7vln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb79c00-4dfc-42fd-ade8-ea770c7390e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.34256744e+00 2.01238477e+03 4.54849511e-01 1.57943153e+01\n",
            "  1.73124623e+00 2.01245288e+03 1.51749573e+03 2.32513189e+00\n",
            "  2.20950770e+00 4.43358612e+00 4.28045702e+00 2.93836631e-02\n",
            "  9.10601654e+01 5.18459091e+01 3.90379982e+01 1.76301911e-01\n",
            "  7.19213963e-01 2.74335861e-01 4.43345696e-01 5.91065502e+00\n",
            "  3.26684093e+00 2.64381242e+00 2.10099459e+00 9.75871801e-01\n",
            "  1.90942139e+02 1.01315109e+02 2.86813164e+01 5.23647881e+01\n",
            "  7.05716782e+01 3.73019600e+01 2.79049206e+01 1.20879091e-01\n",
            "  1.92661591e+01 3.15387325e+01 2.23488937e+02 1.38432479e+00\n",
            "  8.73745620e-01 8.70491886e+00 3.76401825e+01 5.45011978e+01\n",
            "  2.14167905e+00 1.39274435e+01 1.32018551e-01 3.19696164e+00\n",
            "  1.35517206e+01 1.83017895e-01 8.43762517e-01 3.47252083e+01\n",
            "  1.68324394e+01 5.33862293e-01 1.80491379e+02 9.85998764e+01\n",
            "  2.60011883e+01 2.75948353e+01 5.06925316e+01 3.33793488e+01\n",
            "  3.05817771e+00 2.26232314e+00 1.86626892e+01 7.43701458e-02\n",
            "  6.70884311e-01 4.87792740e+01 3.16250381e+01 1.30148888e+01\n",
            "  5.70791931e+01 4.14832920e-01 2.36776090e+00 5.04885063e+01\n",
            "  4.44847641e+01 1.64610803e-01 1.84540573e+02 9.93967896e+01\n",
            "  2.69226017e+01 1.91182480e+01 5.92200165e+01 3.60398865e+01\n",
            "  4.12363482e+00 2.53177667e+00 3.20332413e+01 2.04060987e-01\n",
            "  1.26183128e+00 5.23231049e+01 3.90700226e+01 8.83513987e-01\n",
            "  3.84488678e+00 4.01843376e-02 2.04333916e-01 3.18476467e+01\n",
            "  8.63869858e+00 5.71007244e-02 1.85422394e+02 9.28029175e+01\n",
            "  2.67928829e+01 2.80329647e+01 6.08626328e+01 4.33628769e+01\n",
            "  5.99454021e+00 3.52508235e+00 4.85445213e+01 3.09367239e-01\n",
            "  1.91924906e+00 5.66422081e+01 5.31081848e+01 2.11984128e-01\n",
            "  1.31175923e+00 1.27210086e-02 6.18043803e-02 3.02658558e+01\n",
            "  7.77692080e+00 6.72867894e-02 1.88450943e+02 1.00515778e+02\n",
            "  2.69006157e+01 2.28654957e+01 5.99861336e+01 4.11822701e+01\n",
            "  4.90724707e+00 2.95026660e+00 3.90858421e+01 2.57393986e-01\n",
            "  1.54613566e+00 5.58197098e+01 4.48831329e+01 1.41345128e-01\n",
            "  8.82811189e-01 1.21621639e-02 4.33503687e-02 2.25078659e+01\n",
            "  5.37318087e+00 5.64009883e-02 1.94005463e+02 1.14635902e+02\n",
            "  2.71046314e+01 1.49297647e+01 6.06664886e+01 4.17654037e+01\n",
            "  3.62975287e+00 2.33639693e+00 2.68266926e+01 2.03053400e-01\n",
            "  1.08712578e+00 5.78396950e+01 3.44122658e+01 2.18429733e-02\n",
            "  1.00912020e-01 3.88091803e-03 6.26403140e-03 5.62579298e+00\n",
            "  7.28040755e-01 3.29532772e-02 1.92804276e+02 1.27439529e+02\n",
            "  2.74421825e+01 2.64887733e+01 6.82682800e+01 4.55143127e+01\n",
            "  1.03020966e-02 1.91086275e-03 1.39039949e-01 7.23373741e-02\n",
            "  3.95816239e-03 3.11213285e-01 4.64450628e-01 1.90497899e+00\n",
            "  8.03658366e-01 4.40297276e-01 1.69713842e-03 1.91010269e+02\n",
            "  1.35699219e+02 2.74995213e+01 2.76722450e+01 6.84995041e+01\n",
            "  4.83635750e+01 7.38343410e-03 1.26038829e-03 1.20127805e-01\n",
            "  4.96555604e-02 3.56479292e-03 2.48519123e-01 4.15351331e-01\n",
            "  1.85103655e+00 8.39330614e-01 4.13353831e-01 1.15077721e-03\n",
            "  1.90905853e+02 1.37751953e+02 2.72885704e+01 2.55492077e+01\n",
            "  6.48700562e+01 4.56509590e+01 6.63542654e-03 9.43356776e-04\n",
            "  1.17303021e-01 4.18783650e-02 1.94926164e-03 2.17740312e-01\n",
            "  3.63563061e-01 1.84648168e+00 8.97047520e-01 3.91218275e-01\n",
            "  1.46226992e-03 1.91252716e+02 1.23799316e+02 2.72639694e+01\n",
            "  2.83913002e+01 6.77393799e+01 4.76997070e+01 1.58603173e-02\n",
            "  3.17839975e-03 1.60521373e-01 8.88716951e-02 4.79450496e-03\n",
            "  3.58304620e-01 4.76259083e-01 2.23832417e+00 9.11561966e-01\n",
            "  4.93944317e-01 1.98758068e-03 1.87994965e+02 1.10121826e+02\n",
            "  2.68492527e+01 2.40912457e+01 6.04331055e+01 4.25515862e+01\n",
            "  4.07059267e-02 5.78725012e-03 2.07712188e-01 6.45370781e-02\n",
            "  3.35041666e-03 1.65145248e-01 2.65761793e-01 3.37764406e+00\n",
            "  1.37224090e+00 3.72323781e-01 1.24303857e-03 1.86958603e+02\n",
            "  1.08847565e+02 2.68380280e+01 2.73392315e+01 6.21244469e+01\n",
            "  4.64457626e+01 5.23603223e-02 6.35685725e-03 2.36716181e-01\n",
            "  6.07336275e-02 3.45540862e-03 1.37652069e-01 2.14933529e-01\n",
            "  3.91049743e+00 1.59565449e+00 3.75588506e-01 1.01132994e-03\n",
            "  1.85510437e+02 1.03082428e+02 2.68282280e+01 2.61672173e+01\n",
            "  6.08213158e+01 4.57011414e+01 7.51579553e-02 8.97077285e-03\n",
            "  3.59568775e-01 6.12792410e-02 3.71878664e-03 1.25756398e-01\n",
            "  1.72041237e-01 3.53456712e+00 1.19125736e+00 3.18664491e-01\n",
            "  6.05215202e-04 1.81423553e+02 8.79326324e+01 2.66879997e+01\n",
            "  2.19591484e+01 5.93948784e+01 4.41669769e+01 1.49781853e-01\n",
            "  1.62061285e-02 6.95143938e-01 4.09622230e-02 2.89830449e-03\n",
            "  2.04405840e-02 2.71926466e-02 3.17599559e+00 6.01923347e-01\n",
            "  1.08896747e-01 2.07544392e-04 1.81684158e+02 8.83408813e+01\n",
            "  2.66101265e+01 1.95446739e+01 5.77064171e+01 3.99985657e+01\n",
            "  1.38049573e-01 1.51434531e-02 6.30015731e-01 4.40611616e-02\n",
            "  4.53423383e-03 2.52282601e-02 3.33922468e-02 3.11097836e+00\n",
            "  6.44316733e-01 1.12150326e-01 2.72242905e-04 1.83027695e+02\n",
            "  9.35485001e+01 2.69997520e+01 2.13948841e+01 6.39658127e+01\n",
            "  4.56060791e+01 1.16074570e-01 9.74090118e-03 3.87565494e-01\n",
            "  5.62325455e-02 3.08014918e-03 4.88924459e-02 7.28877112e-02\n",
            "  3.56983209e+00 1.10391784e+00 1.64295897e-01 4.54260269e-04\n",
            "  1.82671509e+02 9.19804153e+01 2.67064018e+01 2.05305729e+01\n",
            "  5.82491493e+01 4.18588104e+01 1.29536912e-01 1.04117226e-02\n",
            "  4.03264374e-01 4.73682955e-02 2.36114953e-03 3.68617587e-02\n",
            "  6.12981282e-02 3.30105209e+00 9.80823219e-01 1.27320558e-01\n",
            "  4.23837075e-04 2.97166748e+01 1.78294182e+01 9.28774261e+01\n",
            "  1.70383084e+00 1.40117133e+00 2.06669532e-02 2.04378031e-02\n",
            "  3.89481544e-01 3.73832613e-01 4.49422032e-01 3.94679278e-01\n",
            "  4.65074688e-01 3.40317219e-01 1.79992706e-01 1.05793186e-01\n",
            "  4.08029823e+01 2.07796860e+00 2.02848458e+00 4.55613899e+00\n",
            "  4.15002298e+00 2.55613867e-02 9.08444672e+01 5.15583038e+01\n",
            "  3.91180191e+01 1.68179616e-01 5.73978364e-01 1.82801530e-01\n",
            "  3.89678121e-01 5.84041882e+00 3.23005176e+00 2.61036730e+00\n",
            "  2.12147808e+00 9.77305353e-01 1.90948395e+02 1.01322731e+02\n",
            "  2.86903954e+01 5.39187737e+01 7.20976944e+01 3.85518188e+01\n",
            "  2.83655014e+01 1.18251301e-01 1.94509010e+01 3.18350468e+01\n",
            "  2.25448288e+02 1.40592062e+00 8.77223849e-01 8.77298355e+00\n",
            "  3.77629547e+01 5.45819168e+01 2.14524937e+00 1.39984741e+01\n",
            "  1.32452101e-01 3.23089385e+00 1.35907116e+01 1.86243623e-01\n",
            "  8.39883924e-01 3.46642914e+01 1.69209785e+01 5.34002721e-01\n",
            "  1.80527451e+02 9.87094879e+01 2.60162430e+01 2.74209232e+01\n",
            "  5.10528069e+01 3.32933769e+01 3.07300091e+00 2.27199268e+00\n",
            "  1.86413460e+01 7.35723823e-02 6.78389192e-01 4.91737404e+01\n",
            "  3.16159458e+01 1.30091038e+01 5.69052658e+01 4.13589805e-01\n",
            "  2.37324309e+00 5.08837814e+01 4.45831833e+01 1.65537119e-01\n",
            "  1.84448105e+02 9.89552917e+01 2.69371662e+01 1.97921562e+01\n",
            "  5.96399956e+01 3.67238350e+01 4.15856695e+00 2.54249310e+00\n",
            "  3.22416534e+01 2.06705153e-01 1.27835286e+00 5.18654404e+01\n",
            "  3.96171265e+01 9.36319232e-01 4.10908842e+00 4.26203944e-02\n",
            "  2.14672774e-01 3.23918571e+01 9.26029682e+00 5.80286868e-02\n",
            "  1.85175095e+02 9.24503098e+01 2.67718544e+01 2.74964123e+01\n",
            "  6.04758720e+01 4.23874817e+01 5.98261261e+00 3.53636551e+00\n",
            "  4.83550415e+01 3.15211087e-01 1.91471624e+00 5.72660675e+01\n",
            "  5.26715393e+01 2.40690172e-01 1.43163061e+00 1.99477151e-02\n",
            "  6.63732812e-02 3.07520237e+01 7.82328033e+00 6.85350895e-02\n",
            "  1.88524567e+02 1.00530807e+02 2.68447170e+01 2.24727612e+01\n",
            "  5.90857658e+01 3.99070892e+01 4.88124990e+00 2.93395972e+00\n",
            "  3.87179756e+01 2.60098904e-01 1.53717768e+00 5.67488251e+01\n",
            "  4.50008354e+01 1.44980490e-01 8.99968028e-01 1.69412531e-02\n",
            "  4.80880886e-02 2.25866356e+01 5.31896877e+00 5.50496541e-02\n",
            "  1.94020477e+02 1.14585754e+02 2.71020012e+01 1.48621540e+01\n",
            "  6.05604324e+01 4.15580521e+01 3.69501591e+00 2.38270831e+00\n",
            "  2.73949757e+01 2.07129225e-01 1.09722531e+00 5.74916077e+01\n",
            "  3.42138748e+01 2.53352839e-02 1.19817533e-01 6.37947069e-03\n",
            "  8.62695090e-03 5.80477524e+00 7.86501706e-01 3.36171165e-02\n",
            "  1.92907043e+02 1.27498802e+02 2.74075451e+01 2.60912571e+01\n",
            "  6.73929749e+01 4.50379906e+01 9.20246262e-03 1.96252554e-03\n",
            "  1.38596714e-01 7.20054805e-02 3.70953116e-03 3.09372187e-01\n",
            "  4.63952541e-01 1.90562832e+00 8.04076731e-01 4.38211977e-01\n",
            "  1.71735324e-03 1.91059006e+02 1.36001923e+02 2.74099445e+01\n",
            "  2.70308056e+01 6.73298721e+01 4.76258850e+01 6.94597838e-03\n",
            "  1.19525846e-03 1.18633240e-01 4.84321229e-02 3.40463663e-03\n",
            "  2.45802805e-01 4.04292464e-01 1.84046710e+00 8.41856480e-01\n",
            "  4.07691926e-01 1.30992371e-03 1.90804810e+02 1.38076157e+02\n",
            "  2.73108006e+01 2.57840366e+01 6.54813385e+01 4.58788834e+01\n",
            "  6.31094165e-03 9.26585461e-04 1.15506373e-01 4.04094942e-02\n",
            "  2.09296681e-03 2.11124286e-01 3.51783782e-01 1.81350744e+00\n",
            "  8.68736982e-01 3.85816336e-01 1.40064163e-03 1.91185898e+02\n",
            "  1.23581696e+02 2.72802200e+01 2.84663219e+01 6.75472641e+01\n",
            "  4.77914467e+01 1.60231851e-02 3.33620864e-03 1.59943968e-01\n",
            "  8.94872621e-02 4.72147670e-03 3.56770039e-01 4.73254383e-01\n",
            "  2.20363665e+00 9.02780771e-01 4.84886736e-01 2.05679541e-03\n",
            "  1.88036499e+02 1.10155258e+02 2.68203487e+01 2.38012390e+01\n",
            "  6.01206284e+01 4.24964256e+01 4.07080017e-02 5.66416280e-03\n",
            "  2.03509435e-01 6.37034103e-02 3.67132924e-03 1.63683087e-01\n",
            "  2.60856867e-01 3.33970571e+00 1.36365592e+00 3.67143810e-01\n",
            "  1.13905070e-03 1.86993530e+02 1.08807434e+02 2.68934593e+01\n",
            "  2.81134739e+01 6.30477829e+01 4.72876282e+01 5.30630015e-02\n",
            "  6.18968625e-03 2.36373156e-01 6.00426421e-02 3.62795242e-03\n",
            "  1.39288470e-01 2.14488849e-01 3.92424130e+00 1.59782052e+00\n",
            "  3.79439652e-01 9.85785155e-04 1.85620102e+02 1.03145981e+02\n",
            "  2.68609619e+01 2.59450455e+01 6.09049149e+01 4.53991776e+01\n",
            "  7.43291825e-02 8.95801745e-03 3.62421542e-01 6.34976625e-02\n",
            "  3.90778715e-03 1.30172938e-01 1.80285379e-01 3.55016780e+00\n",
            "  1.19682956e+00 3.17922384e-01 7.02810998e-04 1.81417099e+02\n",
            "  8.79235229e+01 2.67135735e+01 2.28007660e+01 6.02173882e+01\n",
            "  4.54663124e+01 1.52351782e-01 1.65249947e-02 7.03119755e-01\n",
            "  4.11283895e-02 2.76226038e-03 2.14667581e-02 2.85239071e-02\n",
            "  3.18411779e+00 6.01278543e-01 1.10938795e-01 9.52905320e-05\n",
            "  1.81652664e+02 8.84288101e+01 2.66306725e+01 1.93554630e+01\n",
            "  5.79170990e+01 3.99211464e+01 1.39863282e-01 1.53820245e-02\n",
            "  6.36650562e-01 4.53872047e-02 4.62018978e-03 2.58093942e-02\n",
            "  3.48405950e-02 3.14529157e+00 6.68132842e-01 1.15691215e-01\n",
            "  2.72874866e-04 1.83028214e+02 9.35176468e+01 2.69137611e+01\n",
            "  2.09431305e+01 6.27262192e+01 4.46693459e+01 1.19907752e-01\n",
            "  9.81983170e-03 3.95795107e-01 5.68366386e-02 3.12731951e-03\n",
            "  4.90974076e-02 7.25742206e-02 3.60702872e+00 1.09947598e+00\n",
            "  1.63479462e-01 4.15409653e-04 1.82636627e+02 9.19173584e+01\n",
            "  2.66581497e+01 2.05050068e+01 5.82613297e+01 4.18719368e+01\n",
            "  1.27404571e-01 1.08968820e-02 3.98102343e-01 4.76021729e-02\n",
            "  2.52600620e-03 3.68927903e-02 6.03209957e-02 3.28208566e+00\n",
            "  9.65649068e-01 1.26114070e-01 4.18336684e-04 2.97090263e+01\n",
            "  1.82023392e+01 9.42840271e+01 1.76177454e+00 1.44708061e+00\n",
            "  2.16129329e-02 2.13757232e-02 4.03663933e-01 3.87448072e-01\n",
            "  4.65022266e-01 4.07790214e-01 4.80964124e-01 3.51107508e-01\n",
            "  1.85284078e-01 1.08272374e-01 4.21537666e+01 2.16611743e+00\n",
            "  2.11732435e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(normalizer.mean.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZBr1_tPE7xRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "d3d71e1b-dcd5-4b91-af09-9063cabfb385"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      seasonWeek  seasonYear  weekday  monthDay  month  year  militaryTime  \\\n",
              "3483           5        2017        0         8      1  2017          1300   \n",
              "1591          13        2008        0        30      2  2008          1302   \n",
              "3727           5        2018        0         7      1  2018          1625   \n",
              "3863          16        2018        6        22      3  2018          1630   \n",
              "1876          17        2009        0         3      4  2010          1304   \n",
              "\n",
              "      stadium  field  visSeasonWinsComingIntoGame  ...  home_K_fgm_20-29_pg  \\\n",
              "3483        3      0                            3  ...             0.000000   \n",
              "1591        3      0                            6  ...             0.407407   \n",
              "3727        3      0                            2  ...             0.388889   \n",
              "3863        3      0                            7  ...             0.378378   \n",
              "1876        3      0                           13  ...             0.460076   \n",
              "\n",
              "      home_K_fga_30-39_pg  home_K_fgm_30-39_pg  home_K_fga_40-49_pg  \\\n",
              "3483             0.000000             0.000000             0.000000   \n",
              "1591             0.567901             0.493827             0.506173   \n",
              "3727             0.500000             0.333333             0.833333   \n",
              "3863             0.472973             0.425676             0.628378   \n",
              "1876             0.555133             0.494297             0.524715   \n",
              "\n",
              "      home_K_fgm_40-49_pg  home_K_fga_50+_pg  home_K_fgm_50+_pg  \\\n",
              "3483             0.000000           0.000000           0.000000   \n",
              "1591             0.382716           0.086420           0.024691   \n",
              "3727             0.777778           0.388889           0.333333   \n",
              "3863             0.500000           0.216216           0.114865   \n",
              "1876             0.391635           0.277567           0.144487   \n",
              "\n",
              "      home_K_fglng_ps  home_K_xpa_pg  home_K_xpm_pg  \n",
              "3483         0.000000       0.000000       0.000000  \n",
              "1591        50.333333       2.234568       2.197531  \n",
              "3727        61.000000       3.277778       3.000000  \n",
              "3863        52.222222       2.216216       2.162162  \n",
              "1876        50.823529       2.034221       1.988593  \n",
              "\n",
              "[5 rows x 701 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fb6f240-79d6-45bd-89b2-e3db7a3b8612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seasonWeek</th>\n",
              "      <th>seasonYear</th>\n",
              "      <th>weekday</th>\n",
              "      <th>monthDay</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>militaryTime</th>\n",
              "      <th>stadium</th>\n",
              "      <th>field</th>\n",
              "      <th>visSeasonWinsComingIntoGame</th>\n",
              "      <th>...</th>\n",
              "      <th>home_K_fgm_20-29_pg</th>\n",
              "      <th>home_K_fga_30-39_pg</th>\n",
              "      <th>home_K_fgm_30-39_pg</th>\n",
              "      <th>home_K_fga_40-49_pg</th>\n",
              "      <th>home_K_fgm_40-49_pg</th>\n",
              "      <th>home_K_fga_50+_pg</th>\n",
              "      <th>home_K_fgm_50+_pg</th>\n",
              "      <th>home_K_fglng_ps</th>\n",
              "      <th>home_K_xpa_pg</th>\n",
              "      <th>home_K_xpm_pg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3483</th>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2017</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1591</th>\n",
              "      <td>13</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>1302</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.567901</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>50.333333</td>\n",
              "      <td>2.234568</td>\n",
              "      <td>2.197531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3727</th>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>1625</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>3.277778</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>16</td>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2018</td>\n",
              "      <td>1630</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.628378</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>2.216216</td>\n",
              "      <td>2.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>17</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>1304</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.460076</td>\n",
              "      <td>0.555133</td>\n",
              "      <td>0.494297</td>\n",
              "      <td>0.524715</td>\n",
              "      <td>0.391635</td>\n",
              "      <td>0.277567</td>\n",
              "      <td>0.144487</td>\n",
              "      <td>50.823529</td>\n",
              "      <td>2.034221</td>\n",
              "      <td>1.988593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 701 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fb6f240-79d6-45bd-89b2-e3db7a3b8612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fb6f240-79d6-45bd-89b2-e3db7a3b8612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fb6f240-79d6-45bd-89b2-e3db7a3b8612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f98db05-69d9-42e1-ab56-ab89c5e9d1d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f98db05-69d9-42e1-ab56-ab89c5e9d1d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f98db05-69d9-42e1-ab56-ab89c5e9d1d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_features.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dde3420-dca7-4299-f956-b5bb708981eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4186\n",
            "4186\n"
          ]
        }
      ],
      "source": [
        "print(len(train_labels))\n",
        "print(len(train_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "Each label is an integer between 0 and 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ecde4b-2504-46c9-cf88-ea82bd9e4c82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2831    0\n",
              "4377    0\n",
              "2557    2\n",
              "1977    2\n",
              "4477    2\n",
              "       ..\n",
              "3483    0\n",
              "1591    2\n",
              "3727    0\n",
              "3863    2\n",
              "1876    2\n",
              "Name: winner, Length: 4186, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ece2c1a-8e5c-4799-dac0-9971f43ed0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1047\n",
            "1047\n"
          ]
        }
      ],
      "source": [
        "print(len(test_labels))\n",
        "print(len(test_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup neural network's layers**\n",
        "\n",
        "Arbitrary layer setup, will use hyper parameter tuning (must learn how to do this) later to try to optimize layer structure, optimization algorithm (currently using adam), loss function (currently using SparseCategoricalCrossentropy) and other hyper parameters."
      ],
      "metadata": {
        "id": "YIm36YEy-Ewe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_model(norm):\n",
        "    model = tf.keras.Sequential([\n",
        "        norm,\n",
        "        tf.keras.layers.Dense(2800, activation='relu'),\n",
        "        tf.keras.layers.Dense(1400, activation='relu'),\n",
        "        tf.keras.layers.Dense(700, activation='relu'),\n",
        "        tf.keras.layers.Dense(350, activation='relu'),\n",
        "        tf.keras.layers.Dense(100, activation='relu'),\n",
        "        tf.keras.layers.Dense(25, activation='relu'), # not half but you get what I mean\n",
        "        tf.keras.layers.Dense(3)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model given the input of training features, output of training labels, for 60 epochs, with a batch size of 96. Print out info given the Custom Callback class."
      ],
      "metadata": {
        "id": "8qwHVEXX_wmP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea5be31-e49c-4b66-8165-4ed704bb55b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 1:11 - loss: 1.0735 - accuracy: 0.4375 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 1.1999 - accuracy: 0.4531   Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 1.1415 - accuracy: 0.4514 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 1.0275 - accuracy: 0.4766 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.9611 - accuracy: 0.4875 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.9091 - accuracy: 0.5139 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.8986 - accuracy: 0.5208 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.8728 - accuracy: 0.5156 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.8502 - accuracy: 0.5289 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.8427 - accuracy: 0.5396 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.8287 - accuracy: 0.5426 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.8249 - accuracy: 0.5503 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.8108 - accuracy: 0.5561 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.7977 - accuracy: 0.5625 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.7890 - accuracy: 0.5618 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.7795 - accuracy: 0.5658 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.7718 - accuracy: 0.5723 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.7627 - accuracy: 0.5793 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.7619 - accuracy: 0.5850 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.7558 - accuracy: 0.5896 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.7496 - accuracy: 0.5913 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.7445 - accuracy: 0.5938 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.7386 - accuracy: 0.5956 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.7340 - accuracy: 0.5972 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.7318 - accuracy: 0.5950 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.7282 - accuracy: 0.5970 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.7266 - accuracy: 0.5992 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.7236 - accuracy: 0.6019 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.7202 - accuracy: 0.6027 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.7146 - accuracy: 0.6069 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.7128 - accuracy: 0.6065 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.7112 - accuracy: 0.6064 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.7095 - accuracy: 0.6073 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.7079 - accuracy: 0.6069 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.7060 - accuracy: 0.6065 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.7035 - accuracy: 0.6076 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.7050 - accuracy: 0.6073 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.7032 - accuracy: 0.6077 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.7031 - accuracy: 0.6092 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.6993 - accuracy: 0.6120 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.7003 - accuracy: 0.6110 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.6969 - accuracy: 0.6131 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.6979 - accuracy: 0.6124 Batch 43\n",
            "44/44 [==============================] - 8s 137ms/step - loss: 0.6975 - accuracy: 0.6140\n",
            "Epoch 2/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.5710 - accuracy: 0.7292 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.5478 - accuracy: 0.7656 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.5444 - accuracy: 0.7639 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.5466 - accuracy: 0.7526 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.5501 - accuracy: 0.7458 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.5576 - accuracy: 0.7431 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.5552 - accuracy: 0.7455 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.5401 - accuracy: 0.7526 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.5359 - accuracy: 0.7546 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.5365 - accuracy: 0.7542 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.5339 - accuracy: 0.7519 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.5359 - accuracy: 0.7491 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.5361 - accuracy: 0.7508 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.5350 - accuracy: 0.7522 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.5331 - accuracy: 0.7535 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.5267 - accuracy: 0.7572 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.5230 - accuracy: 0.7586 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.5224 - accuracy: 0.7564 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.5210 - accuracy: 0.7571 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.5236 - accuracy: 0.7573 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.5230 - accuracy: 0.7560 Batch 21\n",
            "22/44 [==============>...............] - ETA: 2s - loss: 0.5303 - accuracy: 0.7505 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.5309 - accuracy: 0.7486 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.5293 - accuracy: 0.7517 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.5295 - accuracy: 0.7496 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.5278 - accuracy: 0.7508 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.5323 - accuracy: 0.7469 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.5333 - accuracy: 0.7448 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.5344 - accuracy: 0.7457 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.5342 - accuracy: 0.7469 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.5348 - accuracy: 0.7440 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.5321 - accuracy: 0.7461 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.5322 - accuracy: 0.7456 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.5317 - accuracy: 0.7469 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.5287 - accuracy: 0.7491 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.5263 - accuracy: 0.7491 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.5281 - accuracy: 0.7483 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.5282 - accuracy: 0.7489 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.5268 - accuracy: 0.7497 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.5285 - accuracy: 0.7492 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.5316 - accuracy: 0.7480 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5310 - accuracy: 0.7478 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.7483 Batch 43\n",
            "44/44 [==============================] - 7s 158ms/step - loss: 0.5311 - accuracy: 0.7489\n",
            "Epoch 3/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.4069 - accuracy: 0.8125 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.4264 - accuracy: 0.8073 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.4244 - accuracy: 0.8264 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.4308 - accuracy: 0.8203 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.4184 - accuracy: 0.8292 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 4s - loss: 0.4074 - accuracy: 0.8333 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 4s - loss: 0.4030 - accuracy: 0.8333 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.3936 - accuracy: 0.8411 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.3950 - accuracy: 0.8380 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.3945 - accuracy: 0.8385 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.3869 - accuracy: 0.8390 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.3827 - accuracy: 0.8420 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.3773 - accuracy: 0.8438 Batch 13\n",
            "14/44 [========>.....................] - ETA: 3s - loss: 0.3820 - accuracy: 0.8408 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.3827 - accuracy: 0.8396 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.3885 - accuracy: 0.8346 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.3781 - accuracy: 0.8388 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.3746 - accuracy: 0.8420 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.3756 - accuracy: 0.8410 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.3769 - accuracy: 0.8401 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.3843 - accuracy: 0.8378 Batch 21\n",
            "22/44 [==============>...............] - ETA: 2s - loss: 0.3917 - accuracy: 0.8343 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.3911 - accuracy: 0.8342 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.3930 - accuracy: 0.8329 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.4002 - accuracy: 0.8279 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.3988 - accuracy: 0.8289 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.3978 - accuracy: 0.8283 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.3963 - accuracy: 0.8300 Batch 28\n",
            "29/44 [==================>...........] - ETA: 1s - loss: 0.3979 - accuracy: 0.8294 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.4009 - accuracy: 0.8285 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.4007 - accuracy: 0.8286 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.4006 - accuracy: 0.8285 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.3995 - accuracy: 0.8292 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.4017 - accuracy: 0.8275 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.4013 - accuracy: 0.8280 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.4024 - accuracy: 0.8270 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.4035 - accuracy: 0.8269 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.4042 - accuracy: 0.8265 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.4072 - accuracy: 0.8243 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.4059 - accuracy: 0.8253 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.4100 - accuracy: 0.8237 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4110 - accuracy: 0.8227 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8222 Batch 43\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 0.4105 - accuracy: 0.8237\n",
            "Epoch 4/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.2757 - accuracy: 0.9375 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.3008 - accuracy: 0.9115 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.3033 - accuracy: 0.8993 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.2949 - accuracy: 0.8984 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.2823 - accuracy: 0.9062 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.2841 - accuracy: 0.9028 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.2740 - accuracy: 0.9092 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.2684 - accuracy: 0.9102 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.2677 - accuracy: 0.9086 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.2653 - accuracy: 0.9083 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.2750 - accuracy: 0.9015 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.2700 - accuracy: 0.9010 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.2601 - accuracy: 0.9038 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.2654 - accuracy: 0.9010 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.2711 - accuracy: 0.8986 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.2742 - accuracy: 0.8984 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.2710 - accuracy: 0.8989 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.2757 - accuracy: 0.8970 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.2713 - accuracy: 0.8991 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.2697 - accuracy: 0.9000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.2722 - accuracy: 0.8988 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.2748 - accuracy: 0.8968 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.2750 - accuracy: 0.8954 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.2763 - accuracy: 0.8941 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.2755 - accuracy: 0.8938 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.2736 - accuracy: 0.8954 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.2794 - accuracy: 0.8931 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.2797 - accuracy: 0.8936 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.2803 - accuracy: 0.8933 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.2826 - accuracy: 0.8927 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.2798 - accuracy: 0.8945 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.2870 - accuracy: 0.8913 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.2878 - accuracy: 0.8911 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.2878 - accuracy: 0.8906 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.2861 - accuracy: 0.8908 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.2851 - accuracy: 0.8912 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.2878 - accuracy: 0.8896 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.2892 - accuracy: 0.8887 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.2919 - accuracy: 0.8868 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.2929 - accuracy: 0.8859 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.2930 - accuracy: 0.8864 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2926 - accuracy: 0.8867 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.2911 - accuracy: 0.8876 Batch 43\n",
            "44/44 [==============================] - 7s 163ms/step - loss: 0.2931 - accuracy: 0.8863\n",
            "Epoch 5/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.1351 - accuracy: 0.9583 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.1552 - accuracy: 0.9531 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.1679 - accuracy: 0.9410 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.1883 - accuracy: 0.9193 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.1810 - accuracy: 0.9250 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.1735 - accuracy: 0.9306 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 4s - loss: 0.1810 - accuracy: 0.9256 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.1653 - accuracy: 0.9336 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.1537 - accuracy: 0.9363 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.1515 - accuracy: 0.9406 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.1589 - accuracy: 0.9384 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.1688 - accuracy: 0.9358 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.1638 - accuracy: 0.9375 Batch 13\n",
            "14/44 [========>.....................] - ETA: 3s - loss: 0.1650 - accuracy: 0.9368 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.1608 - accuracy: 0.9382 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.1578 - accuracy: 0.9382 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.1676 - accuracy: 0.9369 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.1749 - accuracy: 0.9340 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.1714 - accuracy: 0.9348 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.1675 - accuracy: 0.9359 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.1692 - accuracy: 0.9355 Batch 21\n",
            "22/44 [==============>...............] - ETA: 2s - loss: 0.1784 - accuracy: 0.9313 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.1826 - accuracy: 0.9284 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.1824 - accuracy: 0.9284 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.1849 - accuracy: 0.9275 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.1834 - accuracy: 0.9283 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.1830 - accuracy: 0.9290 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.1867 - accuracy: 0.9278 Batch 28\n",
            "29/44 [==================>...........] - ETA: 1s - loss: 0.1883 - accuracy: 0.9267 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.1912 - accuracy: 0.9253 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.1901 - accuracy: 0.9254 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.1923 - accuracy: 0.9242 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.1959 - accuracy: 0.9230 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1968 - accuracy: 0.9225 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.2000 - accuracy: 0.9208 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.2006 - accuracy: 0.9207 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.2012 - accuracy: 0.9209 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.2006 - accuracy: 0.9211 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.2018 - accuracy: 0.9204 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.2033 - accuracy: 0.9201 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.2026 - accuracy: 0.9202 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.2024 - accuracy: 0.9201 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9196 Batch 43\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 0.2018 - accuracy: 0.9200\n",
            "Epoch 6/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.1653 - accuracy: 0.9375 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.1864 - accuracy: 0.9323 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.1739 - accuracy: 0.9306 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.1590 - accuracy: 0.9297 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.1541 - accuracy: 0.9312 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.1360 - accuracy: 0.9410 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 4s - loss: 0.1323 - accuracy: 0.9405 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.1442 - accuracy: 0.9375 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.1477 - accuracy: 0.9375 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.1479 - accuracy: 0.9385 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.1461 - accuracy: 0.9394 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.1425 - accuracy: 0.9418 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.1549 - accuracy: 0.9407 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.1567 - accuracy: 0.9405 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.1536 - accuracy: 0.9410 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.1562 - accuracy: 0.9401 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.1553 - accuracy: 0.9393 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.1552 - accuracy: 0.9392 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.1580 - accuracy: 0.9370 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.1526 - accuracy: 0.9401 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.1520 - accuracy: 0.9415 Batch 21\n",
            "22/44 [==============>...............] - ETA: 2s - loss: 0.1546 - accuracy: 0.9408 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.1610 - accuracy: 0.9384 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.1590 - accuracy: 0.9392 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.1639 - accuracy: 0.9362 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.1652 - accuracy: 0.9355 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.1669 - accuracy: 0.9356 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.1686 - accuracy: 0.9349 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.1702 - accuracy: 0.9339 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.1691 - accuracy: 0.9340 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.1719 - accuracy: 0.9325 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.1710 - accuracy: 0.9323 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.1701 - accuracy: 0.9331 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1698 - accuracy: 0.9335 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.1697 - accuracy: 0.9333 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.1708 - accuracy: 0.9326 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.1724 - accuracy: 0.9313 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.1707 - accuracy: 0.9320 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.1686 - accuracy: 0.9332 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.1676 - accuracy: 0.9336 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.1697 - accuracy: 0.9337 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.1701 - accuracy: 0.9330 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9322 Batch 43\n",
            "44/44 [==============================] - 7s 159ms/step - loss: 0.1704 - accuracy: 0.9326\n",
            "Epoch 7/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.1325 - accuracy: 0.9583 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.1539 - accuracy: 0.9427 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.1323 - accuracy: 0.9583 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.1179 - accuracy: 0.9661 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.1135 - accuracy: 0.9667 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.1068 - accuracy: 0.9688 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.1062 - accuracy: 0.9658 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.1006 - accuracy: 0.9688 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.1003 - accuracy: 0.9688 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.1136 - accuracy: 0.9677 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.1104 - accuracy: 0.9669 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.1042 - accuracy: 0.9688 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.1021 - accuracy: 0.9688 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.1012 - accuracy: 0.9680 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.1028 - accuracy: 0.9674 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.1014 - accuracy: 0.9674 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.1041 - accuracy: 0.9651 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.1044 - accuracy: 0.9641 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.1026 - accuracy: 0.9644 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.1014 - accuracy: 0.9646 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.1054 - accuracy: 0.9623 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.1022 - accuracy: 0.9635 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.1052 - accuracy: 0.9624 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.1036 - accuracy: 0.9631 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.1026 - accuracy: 0.9629 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.1074 - accuracy: 0.9611 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.1087 - accuracy: 0.9606 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.1105 - accuracy: 0.9602 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.1140 - accuracy: 0.9594 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.1147 - accuracy: 0.9594 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9587 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9596 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.1153 - accuracy: 0.9586 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.1181 - accuracy: 0.9562 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.1185 - accuracy: 0.9565 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.1205 - accuracy: 0.9560 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9564 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.1227 - accuracy: 0.9550 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.1242 - accuracy: 0.9535 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.1275 - accuracy: 0.9523 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.1282 - accuracy: 0.9522 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.1281 - accuracy: 0.9524 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9525 Batch 43\n",
            "44/44 [==============================] - 6s 136ms/step - loss: 0.1279 - accuracy: 0.9527\n",
            "Epoch 8/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.0894 - accuracy: 0.9688 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.1184 - accuracy: 0.9531 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0978 - accuracy: 0.9583 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0967 - accuracy: 0.9557 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0991 - accuracy: 0.9521 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0923 - accuracy: 0.9583 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0870 - accuracy: 0.9613 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.0838 - accuracy: 0.9635 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0825 - accuracy: 0.9653 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0882 - accuracy: 0.9625 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0847 - accuracy: 0.9640 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0803 - accuracy: 0.9661 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0778 - accuracy: 0.9679 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0758 - accuracy: 0.9688 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.0717 - accuracy: 0.9708 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0699 - accuracy: 0.9720 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0695 - accuracy: 0.9724 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0703 - accuracy: 0.9722 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0674 - accuracy: 0.9737 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0683 - accuracy: 0.9734 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0667 - accuracy: 0.9737 Batch 21\n",
            "22/44 [==============>...............] - ETA: 2s - loss: 0.0674 - accuracy: 0.9735 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0676 - accuracy: 0.9733 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0662 - accuracy: 0.9740 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0667 - accuracy: 0.9742 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0672 - accuracy: 0.9732 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0681 - accuracy: 0.9726 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0677 - accuracy: 0.9728 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0705 - accuracy: 0.9713 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0690 - accuracy: 0.9719 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0680 - accuracy: 0.9724 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0722 - accuracy: 0.9717 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0720 - accuracy: 0.9722 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0749 - accuracy: 0.9715 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0758 - accuracy: 0.9714 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0749 - accuracy: 0.9716 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0752 - accuracy: 0.9713 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0754 - accuracy: 0.9712 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0756 - accuracy: 0.9712 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0762 - accuracy: 0.9708 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0782 - accuracy: 0.9700 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9702 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9697 Batch 43\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.0809 - accuracy: 0.9694\n",
            "Epoch 9/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0397 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0584 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0622 - accuracy: 0.9757 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0697 - accuracy: 0.9714 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0667 - accuracy: 0.9729 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0641 - accuracy: 0.9740 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0608 - accuracy: 0.9762 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0597 - accuracy: 0.9779 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0560 - accuracy: 0.9803 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0606 - accuracy: 0.9760 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0592 - accuracy: 0.9763 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0592 - accuracy: 0.9757 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0574 - accuracy: 0.9768 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0565 - accuracy: 0.9769 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0551 - accuracy: 0.9771 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0557 - accuracy: 0.9766 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0534 - accuracy: 0.9779 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0577 - accuracy: 0.9763 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0632 - accuracy: 0.9759 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0609 - accuracy: 0.9771 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0635 - accuracy: 0.9767 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0635 - accuracy: 0.9763 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0610 - accuracy: 0.9774 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0620 - accuracy: 0.9770 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0665 - accuracy: 0.9758 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0659 - accuracy: 0.9760 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0669 - accuracy: 0.9753 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0660 - accuracy: 0.9758 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0669 - accuracy: 0.9752 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0696 - accuracy: 0.9747 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0709 - accuracy: 0.9735 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0697 - accuracy: 0.9740 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0727 - accuracy: 0.9732 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0737 - accuracy: 0.9721 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0741 - accuracy: 0.9711 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0762 - accuracy: 0.9699 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0769 - accuracy: 0.9690 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0775 - accuracy: 0.9690 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0798 - accuracy: 0.9677 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0795 - accuracy: 0.9682 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0800 - accuracy: 0.9672 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0805 - accuracy: 0.9675 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9673 Batch 43\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0809 - accuracy: 0.9673\n",
            "Epoch 10/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0254 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0294 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0327 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0296 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0314 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0305 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 4s - loss: 0.0281 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.0259 - accuracy: 0.9935 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0289 - accuracy: 0.9919 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0323 - accuracy: 0.9885 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0335 - accuracy: 0.9877 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0375 - accuracy: 0.9861 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0380 - accuracy: 0.9856 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0385 - accuracy: 0.9859 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0383 - accuracy: 0.9861 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0410 - accuracy: 0.9844 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0399 - accuracy: 0.9847 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0402 - accuracy: 0.9838 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0436 - accuracy: 0.9836 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0465 - accuracy: 0.9823 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0496 - accuracy: 0.9807 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0517 - accuracy: 0.9801 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0531 - accuracy: 0.9796 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0526 - accuracy: 0.9796 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0560 - accuracy: 0.9783 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0563 - accuracy: 0.9784 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0610 - accuracy: 0.9769 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0595 - accuracy: 0.9773 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0590 - accuracy: 0.9774 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0609 - accuracy: 0.9774 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0634 - accuracy: 0.9761 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0630 - accuracy: 0.9766 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0638 - accuracy: 0.9760 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0630 - accuracy: 0.9764 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0629 - accuracy: 0.9762 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0645 - accuracy: 0.9757 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0644 - accuracy: 0.9758 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0653 - accuracy: 0.9751 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0651 - accuracy: 0.9754 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0651 - accuracy: 0.9758 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0656 - accuracy: 0.9754 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0654 - accuracy: 0.9754 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9755 Batch 43\n",
            "44/44 [==============================] - 7s 163ms/step - loss: 0.0654 - accuracy: 0.9759\n",
            "Epoch 11/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0197 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0209 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0215 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0250 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0250 - accuracy: 0.9937 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0234 - accuracy: 0.9948 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0227 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0228 - accuracy: 0.9935 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0276 - accuracy: 0.9907 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0338 - accuracy: 0.9896 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0312 - accuracy: 0.9905 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0336 - accuracy: 0.9887 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0326 - accuracy: 0.9880 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0308 - accuracy: 0.9888 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0300 - accuracy: 0.9889 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0288 - accuracy: 0.9896 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0309 - accuracy: 0.9890 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0298 - accuracy: 0.9896 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0288 - accuracy: 0.9901 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0291 - accuracy: 0.9896 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0290 - accuracy: 0.9891 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0330 - accuracy: 0.9882 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0354 - accuracy: 0.9873 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0344 - accuracy: 0.9878 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0345 - accuracy: 0.9875 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0342 - accuracy: 0.9876 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0337 - accuracy: 0.9877 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0343 - accuracy: 0.9870 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0357 - accuracy: 0.9871 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0366 - accuracy: 0.9865 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0386 - accuracy: 0.9859 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0398 - accuracy: 0.9850 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0390 - accuracy: 0.9855 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0391 - accuracy: 0.9850 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0396 - accuracy: 0.9848 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0413 - accuracy: 0.9841 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0414 - accuracy: 0.9840 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0422 - accuracy: 0.9838 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0417 - accuracy: 0.9840 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9833 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9835 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0419 - accuracy: 0.9839 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9833 Batch 43\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0433 - accuracy: 0.9828\n",
            "Epoch 12/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0514 - accuracy: 0.9688 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0381 - accuracy: 0.9792 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0307 - accuracy: 0.9861 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0409 - accuracy: 0.9792 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0368 - accuracy: 0.9833 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0371 - accuracy: 0.9826 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0458 - accuracy: 0.9792 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.0418 - accuracy: 0.9805 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0416 - accuracy: 0.9803 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0400 - accuracy: 0.9802 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0526 - accuracy: 0.9782 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0492 - accuracy: 0.9800 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0486 - accuracy: 0.9808 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0499 - accuracy: 0.9807 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0498 - accuracy: 0.9806 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0484 - accuracy: 0.9811 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0478 - accuracy: 0.9810 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0470 - accuracy: 0.9815 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0489 - accuracy: 0.9819 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0480 - accuracy: 0.9823 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0501 - accuracy: 0.9821 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0531 - accuracy: 0.9811 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0514 - accuracy: 0.9819 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0507 - accuracy: 0.9822 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0489 - accuracy: 0.9829 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0476 - accuracy: 0.9836 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0475 - accuracy: 0.9830 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0488 - accuracy: 0.9833 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0472 - accuracy: 0.9838 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0465 - accuracy: 0.9840 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0451 - accuracy: 0.9845 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0453 - accuracy: 0.9844 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0474 - accuracy: 0.9839 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0469 - accuracy: 0.9841 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0463 - accuracy: 0.9842 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0457 - accuracy: 0.9844 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0448 - accuracy: 0.9848 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0465 - accuracy: 0.9836 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0468 - accuracy: 0.9834 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0460 - accuracy: 0.9839 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0485 - accuracy: 0.9837 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0485 - accuracy: 0.9839 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 0.9840 Batch 43\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 0.0483 - accuracy: 0.9840\n",
            "Epoch 13/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0111 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0289 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0203 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0200 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0295 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0404 - accuracy: 0.9844 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0361 - accuracy: 0.9866 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0325 - accuracy: 0.9883 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0316 - accuracy: 0.9884 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0306 - accuracy: 0.9885 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0361 - accuracy: 0.9867 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0359 - accuracy: 0.9870 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0390 - accuracy: 0.9864 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0375 - accuracy: 0.9874 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0393 - accuracy: 0.9868 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0392 - accuracy: 0.9857 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0378 - accuracy: 0.9865 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0388 - accuracy: 0.9861 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0399 - accuracy: 0.9857 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0399 - accuracy: 0.9859 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0388 - accuracy: 0.9861 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0382 - accuracy: 0.9863 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0388 - accuracy: 0.9864 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0377 - accuracy: 0.9870 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0376 - accuracy: 0.9867 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0384 - accuracy: 0.9864 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0373 - accuracy: 0.9869 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0381 - accuracy: 0.9862 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0370 - accuracy: 0.9867 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0382 - accuracy: 0.9865 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0372 - accuracy: 0.9869 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0382 - accuracy: 0.9867 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0372 - accuracy: 0.9871 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0386 - accuracy: 0.9871 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0385 - accuracy: 0.9869 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0376 - accuracy: 0.9873 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0369 - accuracy: 0.9876 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0363 - accuracy: 0.9877 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0357 - accuracy: 0.9880 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0372 - accuracy: 0.9875 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0372 - accuracy: 0.9876 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0365 - accuracy: 0.9878 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9876 Batch 43\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 0.0375 - accuracy: 0.9876\n",
            "Epoch 14/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0058 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0118 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0228 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0301 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0323 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0360 - accuracy: 0.9896 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0326 - accuracy: 0.9911 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0365 - accuracy: 0.9896 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0355 - accuracy: 0.9896 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0453 - accuracy: 0.9865 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0480 - accuracy: 0.9839 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0464 - accuracy: 0.9844 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0454 - accuracy: 0.9840 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0450 - accuracy: 0.9844 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.0431 - accuracy: 0.9854 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0412 - accuracy: 0.9863 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0425 - accuracy: 0.9859 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0425 - accuracy: 0.9861 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0428 - accuracy: 0.9863 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0421 - accuracy: 0.9865 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0428 - accuracy: 0.9861 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0432 - accuracy: 0.9858 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0420 - accuracy: 0.9864 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0434 - accuracy: 0.9861 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0432 - accuracy: 0.9858 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0443 - accuracy: 0.9856 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0439 - accuracy: 0.9853 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0429 - accuracy: 0.9855 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0423 - accuracy: 0.9856 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0417 - accuracy: 0.9858 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0428 - accuracy: 0.9856 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0448 - accuracy: 0.9857 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0452 - accuracy: 0.9855 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0462 - accuracy: 0.9856 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0450 - accuracy: 0.9860 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0475 - accuracy: 0.9855 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0468 - accuracy: 0.9856 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9852 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9845 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0491 - accuracy: 0.9844 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0497 - accuracy: 0.9842 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0488 - accuracy: 0.9846 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9847 Batch 43\n",
            "44/44 [==============================] - 7s 163ms/step - loss: 0.0488 - accuracy: 0.9842\n",
            "Epoch 15/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.0469 - accuracy: 0.9688 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0556 - accuracy: 0.9688 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0434 - accuracy: 0.9792 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0364 - accuracy: 0.9818 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0322 - accuracy: 0.9854 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0384 - accuracy: 0.9826 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0415 - accuracy: 0.9807 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0481 - accuracy: 0.9792 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0449 - accuracy: 0.9815 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0463 - accuracy: 0.9812 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0452 - accuracy: 0.9820 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0482 - accuracy: 0.9809 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0597 - accuracy: 0.9800 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0567 - accuracy: 0.9807 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.0574 - accuracy: 0.9806 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0552 - accuracy: 0.9811 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0579 - accuracy: 0.9810 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0569 - accuracy: 0.9815 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0551 - accuracy: 0.9825 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0568 - accuracy: 0.9818 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0562 - accuracy: 0.9816 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0577 - accuracy: 0.9801 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0570 - accuracy: 0.9801 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0554 - accuracy: 0.9805 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0537 - accuracy: 0.9812 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0521 - accuracy: 0.9816 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0524 - accuracy: 0.9811 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0522 - accuracy: 0.9810 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0547 - accuracy: 0.9799 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0535 - accuracy: 0.9806 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0520 - accuracy: 0.9812 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0515 - accuracy: 0.9811 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0501 - accuracy: 0.9817 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0496 - accuracy: 0.9816 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0485 - accuracy: 0.9821 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0490 - accuracy: 0.9815 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0479 - accuracy: 0.9820 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0471 - accuracy: 0.9822 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0663 - accuracy: 0.9821 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0650 - accuracy: 0.9826 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0647 - accuracy: 0.9825 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0640 - accuracy: 0.9826 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9826 Batch 43\n",
            "44/44 [==============================] - 7s 148ms/step - loss: 0.0634 - accuracy: 0.9828\n",
            "Epoch 16/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0153 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0253 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0238 - accuracy: 0.9896 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0257 - accuracy: 0.9896 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0279 - accuracy: 0.9896 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0318 - accuracy: 0.9878 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0317 - accuracy: 0.9896 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0300 - accuracy: 0.9909 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0283 - accuracy: 0.9919 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0268 - accuracy: 0.9927 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0266 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0296 - accuracy: 0.9922 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0290 - accuracy: 0.9920 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0280 - accuracy: 0.9918 Batch 14\n",
            "15/44 [=========>....................] - ETA: 3s - loss: 0.0295 - accuracy: 0.9903 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0279 - accuracy: 0.9909 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0288 - accuracy: 0.9908 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0299 - accuracy: 0.9902 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0289 - accuracy: 0.9907 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0333 - accuracy: 0.9901 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0319 - accuracy: 0.9906 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0307 - accuracy: 0.9910 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0325 - accuracy: 0.9905 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0317 - accuracy: 0.9905 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0309 - accuracy: 0.9904 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0304 - accuracy: 0.9904 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0296 - accuracy: 0.9907 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0291 - accuracy: 0.9907 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0283 - accuracy: 0.9910 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0278 - accuracy: 0.9913 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0274 - accuracy: 0.9916 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0276 - accuracy: 0.9912 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0271 - accuracy: 0.9915 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0273 - accuracy: 0.9914 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0285 - accuracy: 0.9914 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0280 - accuracy: 0.9916 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0281 - accuracy: 0.9916 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0286 - accuracy: 0.9915 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0284 - accuracy: 0.9915 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0292 - accuracy: 0.9914 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0295 - accuracy: 0.9914 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0291 - accuracy: 0.9916 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9918 Batch 43\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.0287 - accuracy: 0.9916\n",
            "Epoch 17/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0146 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0205 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0179 - accuracy: 0.9896 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0330 - accuracy: 0.9896 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0323 - accuracy: 0.9875 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0279 - accuracy: 0.9896 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0286 - accuracy: 0.9881 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.0264 - accuracy: 0.9896 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0244 - accuracy: 0.9907 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0258 - accuracy: 0.9906 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0263 - accuracy: 0.9905 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0267 - accuracy: 0.9905 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0286 - accuracy: 0.9904 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0266 - accuracy: 0.9911 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0258 - accuracy: 0.9910 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0243 - accuracy: 0.9915 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0248 - accuracy: 0.9914 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0239 - accuracy: 0.9919 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0229 - accuracy: 0.9923 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0227 - accuracy: 0.9927 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0243 - accuracy: 0.9926 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0308 - accuracy: 0.9910 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0300 - accuracy: 0.9914 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0314 - accuracy: 0.9905 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0304 - accuracy: 0.9908 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0298 - accuracy: 0.9908 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0310 - accuracy: 0.9900 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0312 - accuracy: 0.9896 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0324 - accuracy: 0.9881 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0339 - accuracy: 0.9878 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0342 - accuracy: 0.9876 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0348 - accuracy: 0.9876 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0342 - accuracy: 0.9880 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0343 - accuracy: 0.9877 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0345 - accuracy: 0.9878 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0376 - accuracy: 0.9873 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0383 - accuracy: 0.9870 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0404 - accuracy: 0.9866 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0420 - accuracy: 0.9861 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0430 - accuracy: 0.9854 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0432 - accuracy: 0.9855 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0431 - accuracy: 0.9856 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9857 Batch 43\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 0.0424 - accuracy: 0.9859\n",
            "Epoch 18/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0941 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0555 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0566 - accuracy: 0.9861 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0532 - accuracy: 0.9870 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0481 - accuracy: 0.9875 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0412 - accuracy: 0.9896 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0371 - accuracy: 0.9911 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0340 - accuracy: 0.9922 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0343 - accuracy: 0.9907 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0316 - accuracy: 0.9917 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0296 - accuracy: 0.9924 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0299 - accuracy: 0.9922 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0316 - accuracy: 0.9912 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0295 - accuracy: 0.9918 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0289 - accuracy: 0.9917 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0280 - accuracy: 0.9915 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0286 - accuracy: 0.9914 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0343 - accuracy: 0.9890 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0329 - accuracy: 0.9896 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0322 - accuracy: 0.9896 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0309 - accuracy: 0.9901 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0316 - accuracy: 0.9901 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0317 - accuracy: 0.9896 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0312 - accuracy: 0.9896 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0302 - accuracy: 0.9900 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0296 - accuracy: 0.9904 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0313 - accuracy: 0.9892 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0305 - accuracy: 0.9896 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0302 - accuracy: 0.9892 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0305 - accuracy: 0.9889 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0335 - accuracy: 0.9889 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0337 - accuracy: 0.9886 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0342 - accuracy: 0.9880 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0345 - accuracy: 0.9881 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0343 - accuracy: 0.9881 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0352 - accuracy: 0.9878 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0354 - accuracy: 0.9879 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0350 - accuracy: 0.9879 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0359 - accuracy: 0.9880 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0370 - accuracy: 0.9875 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0366 - accuracy: 0.9876 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0370 - accuracy: 0.9869 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9869 Batch 43\n",
            "44/44 [==============================] - 7s 166ms/step - loss: 0.0366 - accuracy: 0.9871\n",
            "Epoch 19/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.0256 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0195 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0260 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0224 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0225 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0390 - accuracy: 0.9896 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0351 - accuracy: 0.9896 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 4s - loss: 0.0311 - accuracy: 0.9909 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0281 - accuracy: 0.9919 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0278 - accuracy: 0.9917 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0418 - accuracy: 0.9886 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0390 - accuracy: 0.9896 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0371 - accuracy: 0.9904 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0350 - accuracy: 0.9911 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0329 - accuracy: 0.9917 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0334 - accuracy: 0.9902 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0318 - accuracy: 0.9908 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0322 - accuracy: 0.9902 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0332 - accuracy: 0.9901 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0320 - accuracy: 0.9906 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0307 - accuracy: 0.9911 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0307 - accuracy: 0.9910 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0309 - accuracy: 0.9909 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0301 - accuracy: 0.9913 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0311 - accuracy: 0.9904 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0555 - accuracy: 0.9880 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0543 - accuracy: 0.9880 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0526 - accuracy: 0.9885 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0523 - accuracy: 0.9881 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0511 - accuracy: 0.9882 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0513 - accuracy: 0.9879 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0505 - accuracy: 0.9880 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0497 - accuracy: 0.9880 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0495 - accuracy: 0.9877 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0484 - accuracy: 0.9881 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0484 - accuracy: 0.9876 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0622 - accuracy: 0.9873 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0681 - accuracy: 0.9871 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0664 - accuracy: 0.9874 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0655 - accuracy: 0.9875 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0643 - accuracy: 0.9876 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0643 - accuracy: 0.9871 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9869 Batch 43\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 0.0656 - accuracy: 0.9866\n",
            "Epoch 20/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 5s - loss: 0.0193 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0228 - accuracy: 0.9896 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0214 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0239 - accuracy: 0.9896 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0345 - accuracy: 0.9833 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0368 - accuracy: 0.9844 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0406 - accuracy: 0.9836 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0435 - accuracy: 0.9831 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0424 - accuracy: 0.9838 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0428 - accuracy: 0.9844 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0409 - accuracy: 0.9848 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0609 - accuracy: 0.9826 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0615 - accuracy: 0.9832 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0642 - accuracy: 0.9821 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0605 - accuracy: 0.9833 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0581 - accuracy: 0.9844 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0568 - accuracy: 0.9847 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0547 - accuracy: 0.9855 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0548 - accuracy: 0.9852 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0552 - accuracy: 0.9854 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0535 - accuracy: 0.9861 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0535 - accuracy: 0.9858 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0517 - accuracy: 0.9864 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0512 - accuracy: 0.9861 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0565 - accuracy: 0.9858 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0563 - accuracy: 0.9856 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0570 - accuracy: 0.9853 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0566 - accuracy: 0.9851 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0564 - accuracy: 0.9853 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0575 - accuracy: 0.9851 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0569 - accuracy: 0.9849 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0577 - accuracy: 0.9847 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 0.0568 - accuracy: 0.9848 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0589 - accuracy: 0.9835 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0599 - accuracy: 0.9833 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0584 - accuracy: 0.9838 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0572 - accuracy: 0.9842 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0570 - accuracy: 0.9841 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9840 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0583 - accuracy: 0.9839 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0578 - accuracy: 0.9837 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0583 - accuracy: 0.9834 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9833 Batch 43\n",
            "44/44 [==============================] - 8s 183ms/step - loss: 0.0572 - accuracy: 0.9835\n",
            "Epoch 21/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0352 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0437 - accuracy: 0.9792 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0459 - accuracy: 0.9826 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0493 - accuracy: 0.9792 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0410 - accuracy: 0.9833 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0400 - accuracy: 0.9826 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0404 - accuracy: 0.9836 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0356 - accuracy: 0.9857 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0321 - accuracy: 0.9873 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0294 - accuracy: 0.9885 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0275 - accuracy: 0.9896 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0257 - accuracy: 0.9905 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0259 - accuracy: 0.9904 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0240 - accuracy: 0.9911 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0235 - accuracy: 0.9910 Batch 15\n",
            "16/44 [=========>....................] - ETA: 3s - loss: 0.0223 - accuracy: 0.9915 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0215 - accuracy: 0.9920 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0207 - accuracy: 0.9925 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0197 - accuracy: 0.9929 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0187 - accuracy: 0.9932 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0181 - accuracy: 0.9936 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0197 - accuracy: 0.9929 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0191 - accuracy: 0.9932 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0197 - accuracy: 0.9931 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0190 - accuracy: 0.9933 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0195 - accuracy: 0.9932 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0239 - accuracy: 0.9923 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0235 - accuracy: 0.9926 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0231 - accuracy: 0.9925 Batch 29\n",
            "30/44 [===================>..........] - ETA: 1s - loss: 0.0242 - accuracy: 0.9920 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0272 - accuracy: 0.9919 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0319 - accuracy: 0.9906 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0380 - accuracy: 0.9883 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0378 - accuracy: 0.9881 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0391 - accuracy: 0.9881 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0391 - accuracy: 0.9878 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0396 - accuracy: 0.9879 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0406 - accuracy: 0.9874 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0412 - accuracy: 0.9872 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0415 - accuracy: 0.9870 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0422 - accuracy: 0.9870 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0420 - accuracy: 0.9871 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9872 Batch 43\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 0.0425 - accuracy: 0.9869\n",
            "Epoch 22/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0786 - accuracy: 0.9792 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0594 - accuracy: 0.9844 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0688 - accuracy: 0.9861 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0639 - accuracy: 0.9844 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0847 - accuracy: 0.9812 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0827 - accuracy: 0.9792 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0714 - accuracy: 0.9821 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0664 - accuracy: 0.9818 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 4s - loss: 0.0643 - accuracy: 0.9815 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0586 - accuracy: 0.9833 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0558 - accuracy: 0.9839 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0528 - accuracy: 0.9844 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0505 - accuracy: 0.9848 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0512 - accuracy: 0.9844 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0539 - accuracy: 0.9833 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0530 - accuracy: 0.9831 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0511 - accuracy: 0.9841 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0503 - accuracy: 0.9838 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0501 - accuracy: 0.9830 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0496 - accuracy: 0.9828 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0491 - accuracy: 0.9821 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0489 - accuracy: 0.9820 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0483 - accuracy: 0.9819 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0501 - accuracy: 0.9822 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0485 - accuracy: 0.9825 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0496 - accuracy: 0.9812 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0483 - accuracy: 0.9815 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0470 - accuracy: 0.9818 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0460 - accuracy: 0.9824 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0450 - accuracy: 0.9826 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0436 - accuracy: 0.9832 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0429 - accuracy: 0.9834 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0417 - accuracy: 0.9839 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0407 - accuracy: 0.9844 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0398 - accuracy: 0.9848 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0404 - accuracy: 0.9844 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0404 - accuracy: 0.9842 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0394 - accuracy: 0.9846 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0387 - accuracy: 0.9850 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0391 - accuracy: 0.9852 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0388 - accuracy: 0.9853 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0397 - accuracy: 0.9851 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9855 Batch 43\n",
            "44/44 [==============================] - 7s 168ms/step - loss: 0.0399 - accuracy: 0.9852\n",
            "Epoch 23/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0016 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0021 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0122 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0104 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0116 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0175 - accuracy: 0.9948 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0239 - accuracy: 0.9926 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0355 - accuracy: 0.9883 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0377 - accuracy: 0.9884 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0365 - accuracy: 0.9885 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0377 - accuracy: 0.9886 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0374 - accuracy: 0.9878 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0391 - accuracy: 0.9872 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0393 - accuracy: 0.9874 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0390 - accuracy: 0.9875 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0382 - accuracy: 0.9883 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0374 - accuracy: 0.9884 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0363 - accuracy: 0.9890 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0347 - accuracy: 0.9896 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0333 - accuracy: 0.9901 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0326 - accuracy: 0.9906 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0315 - accuracy: 0.9910 Batch 22\n",
            "23/44 [==============>...............] - ETA: 2s - loss: 0.0306 - accuracy: 0.9914 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0315 - accuracy: 0.9909 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0316 - accuracy: 0.9908 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0314 - accuracy: 0.9908 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0306 - accuracy: 0.9911 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0298 - accuracy: 0.9914 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0290 - accuracy: 0.9917 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0285 - accuracy: 0.9920 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0277 - accuracy: 0.9923 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0276 - accuracy: 0.9919 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0278 - accuracy: 0.9915 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0273 - accuracy: 0.9914 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0278 - accuracy: 0.9914 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0271 - accuracy: 0.9916 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0265 - accuracy: 0.9918 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0258 - accuracy: 0.9921 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0255 - accuracy: 0.9920 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0250 - accuracy: 0.9922 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0247 - accuracy: 0.9921 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0241 - accuracy: 0.9923 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9925 Batch 43\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 0.0236 - accuracy: 0.9926\n",
            "Epoch 24/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 4.3688e-04 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 0.0076 - accuracy: 0.9948     Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0232 - accuracy: 0.9931 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0295 - accuracy: 0.9922 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0315 - accuracy: 0.9917 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0263 - accuracy: 0.9931 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0231 - accuracy: 0.9940 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0203 - accuracy: 0.9948 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0213 - accuracy: 0.9942 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0192 - accuracy: 0.9948 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 0.0224 - accuracy: 0.9943 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 0.0213 - accuracy: 0.9948 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 0.0200 - accuracy: 0.9952 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0198 - accuracy: 0.9948 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0186 - accuracy: 0.9951 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0185 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0181 - accuracy: 0.9945 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0185 - accuracy: 0.9942 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0190 - accuracy: 0.9940 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0190 - accuracy: 0.9937 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0200 - accuracy: 0.9936 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0196 - accuracy: 0.9934 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 0.0190 - accuracy: 0.9937 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0214 - accuracy: 0.9935 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0209 - accuracy: 0.9937 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0204 - accuracy: 0.9940 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0204 - accuracy: 0.9938 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0198 - accuracy: 0.9940 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0217 - accuracy: 0.9939 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0211 - accuracy: 0.9941 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0206 - accuracy: 0.9943 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0202 - accuracy: 0.9945 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0199 - accuracy: 0.9943 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0195 - accuracy: 0.9945 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0199 - accuracy: 0.9943 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0194 - accuracy: 0.9945 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0190 - accuracy: 0.9947 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0187 - accuracy: 0.9948 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0190 - accuracy: 0.9947 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0186 - accuracy: 0.9948 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0189 - accuracy: 0.9947 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0185 - accuracy: 0.9948 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9949 Batch 43\n",
            "44/44 [==============================] - 7s 168ms/step - loss: 0.0181 - accuracy: 0.9950\n",
            "Epoch 25/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0063 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0035 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0027 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0023 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 0.0019 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0051 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0044 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0103 - accuracy: 0.9961 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0095 - accuracy: 0.9965 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0089 - accuracy: 0.9969 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0081 - accuracy: 0.9972 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0080 - accuracy: 0.9974 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0075 - accuracy: 0.9976 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0072 - accuracy: 0.9978 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0070 - accuracy: 0.9979 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0067 - accuracy: 0.9980 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0066 - accuracy: 0.9982 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0064 - accuracy: 0.9983 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0061 - accuracy: 0.9984 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0059 - accuracy: 0.9984 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0065 - accuracy: 0.9980 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0067 - accuracy: 0.9976 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0066 - accuracy: 0.9977 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0065 - accuracy: 0.9978 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0063 - accuracy: 0.9979 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0060 - accuracy: 0.9980 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0059 - accuracy: 0.9981 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0058 - accuracy: 0.9981 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0058 - accuracy: 0.9982 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0056 - accuracy: 0.9983 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0055 - accuracy: 0.9983 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0054 - accuracy: 0.9984 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0053 - accuracy: 0.9984 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0051 - accuracy: 0.9985 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0050 - accuracy: 0.9985 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0049 - accuracy: 0.9986 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0048 - accuracy: 0.9986 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988 Batch 43\n",
            "44/44 [==============================] - 6s 144ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 26/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 2.0116e-04 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0033 - accuracy: 1.0000     Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0022 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 0.0017 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0015 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0012 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 0.0011 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0018 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0016 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0015 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0013 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0012 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0021 - accuracy: 0.9992 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0020 - accuracy: 0.9993 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0021 - accuracy: 0.9993 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0027 - accuracy: 0.9987 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0036 - accuracy: 0.9975 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0037 - accuracy: 0.9977 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 0.0038 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0047 - accuracy: 0.9974 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0047 - accuracy: 0.9975 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0048 - accuracy: 0.9976 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0046 - accuracy: 0.9977 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0044 - accuracy: 0.9978 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0052 - accuracy: 0.9975 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0052 - accuracy: 0.9976 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0050 - accuracy: 0.9977 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0048 - accuracy: 0.9978 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0050 - accuracy: 0.9975 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0051 - accuracy: 0.9976 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0052 - accuracy: 0.9973 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0051 - accuracy: 0.9974 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0050 - accuracy: 0.9975 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0051 - accuracy: 0.9972 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0050 - accuracy: 0.9973 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0049 - accuracy: 0.9974 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0048 - accuracy: 0.9975 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0049 - accuracy: 0.9975 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9976 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 0.9977 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0047 - accuracy: 0.9977 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0048 - accuracy: 0.9975 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9973 Batch 43\n",
            "44/44 [==============================] - 7s 166ms/step - loss: 0.0050 - accuracy: 0.9974\n",
            "Epoch 27/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 0.0302 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0152 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0102 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0121 - accuracy: 0.9948 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0109 - accuracy: 0.9958 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0092 - accuracy: 0.9965 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0080 - accuracy: 0.9970 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0085 - accuracy: 0.9961 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0143 - accuracy: 0.9942 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0135 - accuracy: 0.9948 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0204 - accuracy: 0.9943 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0188 - accuracy: 0.9948 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0185 - accuracy: 0.9944 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0248 - accuracy: 0.9940 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0240 - accuracy: 0.9937 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0228 - accuracy: 0.9941 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0360 - accuracy: 0.9926 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0342 - accuracy: 0.9931 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0325 - accuracy: 0.9934 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0309 - accuracy: 0.9937 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0308 - accuracy: 0.9936 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0325 - accuracy: 0.9934 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0314 - accuracy: 0.9937 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0323 - accuracy: 0.9931 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0315 - accuracy: 0.9933 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0326 - accuracy: 0.9928 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0316 - accuracy: 0.9931 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0308 - accuracy: 0.9933 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0300 - accuracy: 0.9935 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0294 - accuracy: 0.9937 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0286 - accuracy: 0.9940 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0285 - accuracy: 0.9938 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0281 - accuracy: 0.9940 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0277 - accuracy: 0.9942 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0272 - accuracy: 0.9940 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0266 - accuracy: 0.9942 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0263 - accuracy: 0.9941 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0266 - accuracy: 0.9937 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0261 - accuracy: 0.9939 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0273 - accuracy: 0.9935 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0268 - accuracy: 0.9936 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0263 - accuracy: 0.9938 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9937 Batch 43\n",
            "44/44 [==============================] - 6s 148ms/step - loss: 0.0261 - accuracy: 0.9938\n",
            "Epoch 28/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0086 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 0.0053 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 0.0156 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0133 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0109 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 0.0106 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 0.0092 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0083 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0076 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0070 - accuracy: 0.9990 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0064 - accuracy: 0.9991 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0059 - accuracy: 0.9991 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0055 - accuracy: 0.9992 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0054 - accuracy: 0.9993 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 0.0053 - accuracy: 0.9993 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0107 - accuracy: 0.9987 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0102 - accuracy: 0.9988 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 0.0109 - accuracy: 0.9983 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0104 - accuracy: 0.9984 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0101 - accuracy: 0.9984 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0096 - accuracy: 0.9985 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 0.0112 - accuracy: 0.9981 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0107 - accuracy: 0.9982 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0113 - accuracy: 0.9978 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0109 - accuracy: 0.9979 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0105 - accuracy: 0.9980 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 0.0102 - accuracy: 0.9981 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0099 - accuracy: 0.9981 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0096 - accuracy: 0.9982 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0093 - accuracy: 0.9983 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0091 - accuracy: 0.9983 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0090 - accuracy: 0.9984 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0090 - accuracy: 0.9984 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0089 - accuracy: 0.9985 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0088 - accuracy: 0.9985 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0088 - accuracy: 0.9983 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0086 - accuracy: 0.9983 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 0.0085 - accuracy: 0.9984 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0083 - accuracy: 0.9984 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0081 - accuracy: 0.9984 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0085 - accuracy: 0.9982 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0087 - accuracy: 0.9980 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9978 Batch 43\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.0089 - accuracy: 0.9979\n",
            "Epoch 29/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0025 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 0.0019 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 0.0015 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0029 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0024 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0023 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0025 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0023 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0028 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 0.0082 - accuracy: 0.9979 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0079 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0076 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0077 - accuracy: 0.9976 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0162 - accuracy: 0.9970 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0151 - accuracy: 0.9972 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0142 - accuracy: 0.9974 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0134 - accuracy: 0.9975 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0131 - accuracy: 0.9977 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0125 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0146 - accuracy: 0.9969 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0154 - accuracy: 0.9965 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0156 - accuracy: 0.9962 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0154 - accuracy: 0.9959 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0148 - accuracy: 0.9961 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0144 - accuracy: 0.9962 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0139 - accuracy: 0.9964 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0138 - accuracy: 0.9965 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0134 - accuracy: 0.9967 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0145 - accuracy: 0.9960 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0141 - accuracy: 0.9962 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0137 - accuracy: 0.9963 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0143 - accuracy: 0.9958 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0144 - accuracy: 0.9956 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0140 - accuracy: 0.9957 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0137 - accuracy: 0.9958 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0134 - accuracy: 0.9959 Batch 36\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 0.0132 - accuracy: 0.9961 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0129 - accuracy: 0.9962 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0126 - accuracy: 0.9963 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0124 - accuracy: 0.9964 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0124 - accuracy: 0.9962 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0122 - accuracy: 0.9963 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9961 Batch 43\n",
            "44/44 [==============================] - 7s 148ms/step - loss: 0.0133 - accuracy: 0.9957\n",
            "Epoch 30/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0148 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 0.0078 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.0056 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 0.0056 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0046 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0081 - accuracy: 0.9965 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0070 - accuracy: 0.9970 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 0.0082 - accuracy: 0.9961 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0109 - accuracy: 0.9954 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 0.0150 - accuracy: 0.9937 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 0.0168 - accuracy: 0.9934 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0159 - accuracy: 0.9939 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0147 - accuracy: 0.9944 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 0.0140 - accuracy: 0.9948 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0148 - accuracy: 0.9944 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0143 - accuracy: 0.9948 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 0.0150 - accuracy: 0.9945 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0143 - accuracy: 0.9948 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0136 - accuracy: 0.9951 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0131 - accuracy: 0.9953 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0127 - accuracy: 0.9955 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0123 - accuracy: 0.9957 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0119 - accuracy: 0.9959 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0129 - accuracy: 0.9957 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0127 - accuracy: 0.9958 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0130 - accuracy: 0.9956 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0162 - accuracy: 0.9946 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0158 - accuracy: 0.9948 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0154 - accuracy: 0.9950 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0150 - accuracy: 0.9951 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0153 - accuracy: 0.9950 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 0.0169 - accuracy: 0.9948 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0168 - accuracy: 0.9946 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0164 - accuracy: 0.9948 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0160 - accuracy: 0.9949 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0155 - accuracy: 0.9951 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0179 - accuracy: 0.9941 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0174 - accuracy: 0.9942 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0174 - accuracy: 0.9941 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0171 - accuracy: 0.9944 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0167 - accuracy: 0.9945 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9947 Batch 43\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 0.0170 - accuracy: 0.9945\n",
            "Epoch 31/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 0.0108 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 0.0088 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 0.0064 - accuracy: 0.9965 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 0.0066 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 0.0060 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 0.0053 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 0.0051 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0067 - accuracy: 0.9974 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0061 - accuracy: 0.9977 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0056 - accuracy: 0.9979 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0052 - accuracy: 0.9981 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0048 - accuracy: 0.9983 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0069 - accuracy: 0.9976 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0066 - accuracy: 0.9978 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0067 - accuracy: 0.9979 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0064 - accuracy: 0.9980 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 0.0061 - accuracy: 0.9982 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0058 - accuracy: 0.9983 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0061 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0062 - accuracy: 0.9979 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0061 - accuracy: 0.9980 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0059 - accuracy: 0.9981 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0060 - accuracy: 0.9982 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0064 - accuracy: 0.9983 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0075 - accuracy: 0.9979 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0073 - accuracy: 0.9980 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0070 - accuracy: 0.9981 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0068 - accuracy: 0.9981 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0066 - accuracy: 0.9982 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0064 - accuracy: 0.9983 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0080 - accuracy: 0.9973 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0082 - accuracy: 0.9971 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0080 - accuracy: 0.9972 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0078 - accuracy: 0.9972 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0076 - accuracy: 0.9973 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0074 - accuracy: 0.9974 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0072 - accuracy: 0.9975 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0085 - accuracy: 0.9969 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0083 - accuracy: 0.9970 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0081 - accuracy: 0.9970 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9969 Batch 43\n",
            "44/44 [==============================] - 7s 155ms/step - loss: 0.0089 - accuracy: 0.9969\n",
            "Epoch 32/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 0.0732 - accuracy: 0.9896 Batch 1\n",
            " 2/44 [>.............................] - ETA: 10s - loss: 0.0367 - accuracy: 0.9948 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.0265 - accuracy: 0.9965  Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0204 - accuracy: 0.9974 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 0.0175 - accuracy: 0.9979 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 0.0149 - accuracy: 0.9983 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 0.0132 - accuracy: 0.9985 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 8s - loss: 0.0117 - accuracy: 0.9987 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 0.0111 - accuracy: 0.9988 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 0.0105 - accuracy: 0.9990 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 0.0099 - accuracy: 0.9991 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 0.0093 - accuracy: 0.9991 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 0.0088 - accuracy: 0.9992 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 0.0082 - accuracy: 0.9993 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 0.0078 - accuracy: 0.9993 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 0.0080 - accuracy: 0.9987 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0080 - accuracy: 0.9988 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 0.0082 - accuracy: 0.9983 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 0.0087 - accuracy: 0.9978 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 0.0085 - accuracy: 0.9979 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 0.0093 - accuracy: 0.9975 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0095 - accuracy: 0.9972 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0092 - accuracy: 0.9973 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 0.0089 - accuracy: 0.9974 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 0.0090 - accuracy: 0.9975 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 0.0087 - accuracy: 0.9976 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0089 - accuracy: 0.9973 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0087 - accuracy: 0.9974 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0085 - accuracy: 0.9975 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0083 - accuracy: 0.9976 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 0.0080 - accuracy: 0.9976 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0078 - accuracy: 0.9977 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0075 - accuracy: 0.9978 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0074 - accuracy: 0.9979 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0073 - accuracy: 0.9979 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0071 - accuracy: 0.9980 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0069 - accuracy: 0.9980 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9983 Batch 43\n",
            "44/44 [==============================] - 7s 158ms/step - loss: 0.0061 - accuracy: 0.9983\n",
            "Epoch 33/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 5.5352e-05 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.9763e-04 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.4993e-04 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 1.8564e-04 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 2.1619e-04 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.3320e-04 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.0790e-04 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 0.0012 - accuracy: 1.0000     Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 0.0013 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 0.0016 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 0.0014 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 0.0013 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 0.0012 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 0.0023 - accuracy: 0.9993 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 0.0022 - accuracy: 0.9993 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 0.0021 - accuracy: 0.9993 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 0.0020 - accuracy: 0.9994 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 0.0019 - accuracy: 0.9994 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 0.0019 - accuracy: 0.9995 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 0.0018 - accuracy: 0.9995 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 0.0017 - accuracy: 0.9995 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 0.0016 - accuracy: 0.9995 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 0.0016 - accuracy: 0.9995 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 0.0015 - accuracy: 0.9996 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 0.0015 - accuracy: 0.9996 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 0.0015 - accuracy: 0.9996 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 0.0014 - accuracy: 0.9996 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 0.0013 - accuracy: 0.9996 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 0.0040 - accuracy: 0.9993 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 0.0039 - accuracy: 0.9993 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 0.0038 - accuracy: 0.9993 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 0.0037 - accuracy: 0.9993 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 0.0036 - accuracy: 0.9994 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 0.0035 - accuracy: 0.9994 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 0.0034 - accuracy: 0.9994 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 0.0033 - accuracy: 0.9994 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 0.0032 - accuracy: 0.9994 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 0.0032 - accuracy: 0.9995 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995 Batch 43\n",
            "44/44 [==============================] - 7s 167ms/step - loss: 0.0028 - accuracy: 0.9995\n",
            "Epoch 34/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 1.2542e-04 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 10s - loss: 0.0024 - accuracy: 1.0000    Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 0.0017 - accuracy: 1.0000  Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 0.0013 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 7s - loss: 0.0011 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 9.6788e-04 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 8.4235e-04 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 8.8022e-04 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 8.1218e-04 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 7.5319e-04 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 7.5512e-04 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 7.0511e-04 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 6.5361e-04 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 6.3176e-04 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 6.0830e-04 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.7984e-04 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.5749e-04 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 5.3688e-04 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 5.1785e-04 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 4.9361e-04 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 4.7097e-04 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 4.5055e-04 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 4.4473e-04 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.2678e-04 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 4.1264e-04 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 3.9814e-04 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 3.8469e-04 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 6.0897e-04 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.9857e-04 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 5.8090e-04 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 5.6258e-04 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 5.4631e-04 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 5.4724e-04 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 5.3185e-04 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 5.2127e-04 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 5.0699e-04 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.9446e-04 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 4.8866e-04 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.7759e-04 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.6807e-04 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.7675e-04 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.6674e-04 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.6129e-04 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 152ms/step - loss: 4.6165e-04 - accuracy: 1.0000\n",
            "Epoch 35/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 3.3151e-05 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 2.2590e-05 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 4.5173e-05 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 5.5710e-05 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 5.2040e-05 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 5.4426e-05 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 5.0519e-05 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 4.9477e-05 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 5.1739e-05 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 4.9827e-05 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 4.5877e-05 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 4.3096e-05 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 6.3585e-05 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 6.1710e-05 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 6.1809e-05 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 6.2070e-05 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.8526e-05 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 6.8455e-05 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 6.5637e-05 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 6.4297e-05 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 6.3776e-05 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 6.1313e-05 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 5.9503e-05 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 5.9919e-05 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 5.7782e-05 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 6.0534e-05 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 5.9372e-05 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 5.7565e-05 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.5760e-05 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 5.4150e-05 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 5.2717e-05 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 5.1256e-05 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 5.0009e-05 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 5.0050e-05 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 4.9348e-05 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.8059e-05 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.7466e-05 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 4.6272e-05 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.5196e-05 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.4954e-05 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.4383e-05 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.4445e-05 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.3880e-05 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 4.3633e-05 - accuracy: 1.0000\n",
            "Epoch 36/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 1.2343e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 1.4398e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 4.0583e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 5.5067e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 4.6341e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 5.8336e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 6.2713e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 5.6864e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 5.9798e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 5.5236e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 5.5193e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 5.2399e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 6.2118e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 5.9389e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 5.6228e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.4651e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 5.4609e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 5.3175e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 6.3124e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 6.3622e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 6.0963e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 5.8310e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 5.9179e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 7.2268e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 7.2418e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 7.1724e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 7.0466e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 6.9588e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 6.7875e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 6.6262e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 6.5113e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 6.5136e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 6.3676e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 6.3556e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 6.4408e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 6.2731e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 6.3156e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 6.2071e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 6.0723e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 6.0985e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 6.2669e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 6.2740e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 6.2717e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 6.2081e-06 - accuracy: 1.0000\n",
            "Epoch 37/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 3.1974e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 2.1376e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.7777e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 2.7640e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 2.3215e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 3.0143e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 3.4249e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 3.3808e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 3.5955e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 3.5683e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 3.3697e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 3.3957e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 3.6972e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 3.6565e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 3.5829e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 4.8519e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 4.7189e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 4.8070e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 4.7998e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 4.6785e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 4.5921e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 4.4683e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 4.5750e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.4136e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.2905e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 4.1666e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 4.0688e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 3.9953e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 3.9029e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 3.9526e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 3.9913e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.8949e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 3.8245e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 3.7453e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 3.6960e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.6159e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.6178e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.5324e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 3.4866e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.4424e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.4269e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.5156e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.4401e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 173ms/step - loss: 3.4020e-06 - accuracy: 1.0000\n",
            "Epoch 38/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 3.9470e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 7.1436e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 5.8546e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 4.4900e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 3.6688e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 3.1248e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.7986e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 3.3453e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 3.0649e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 3.0926e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 3.0614e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 3.0280e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.8780e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.8217e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 2.6836e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.6060e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 2.4931e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 2.4006e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 2.3617e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.4155e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 2.3267e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.2772e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.2447e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 2.2438e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 2.1728e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 2.5975e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.5831e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.5726e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.5586e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.5080e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 2.4838e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 2.4169e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.4480e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.4043e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.3593e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.3396e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.2806e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 2.2265e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.1744e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.1839e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.1362e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.2078e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.1865e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 6s 147ms/step - loss: 2.1569e-06 - accuracy: 1.0000\n",
            "Epoch 39/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 9.5364e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.7955e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.5161e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.4328e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 2.1941e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.0769e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.8155e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.6398e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.7280e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.6229e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.5053e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 1.4015e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 1.3026e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 1.3146e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.2684e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.3408e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.3507e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.3124e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.2515e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.6713e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.6537e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.6404e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.5826e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.5634e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.5187e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.4730e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.4325e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.4224e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.3997e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.3791e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.4472e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.4225e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.4000e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.4765e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.4641e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.5357e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.5031e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.4670e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.4629e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.4347e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.4070e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.3774e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.3985e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 175ms/step - loss: 1.4561e-06 - accuracy: 1.0000\n",
            "Epoch 40/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 1.7372e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 2.2363e-06 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 5s - loss: 2.3058e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 1.8240e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 1.7319e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.6167e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.8866e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.9609e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.9578e-06 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 1.8572e-06 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 1.7488e-06 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 1.6583e-06 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.1309e-06 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.0206e-06 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.9065e-06 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.7932e-06 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 3s - loss: 1.7302e-06 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 1.6742e-06 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.6144e-06 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.5408e-06 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.4801e-06 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.4275e-06 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.3668e-06 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 2s - loss: 1.3169e-06 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 1.2843e-06 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.2846e-06 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.2699e-06 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.2300e-06 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.1915e-06 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.1676e-06 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 1.1594e-06 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.1726e-06 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.1619e-06 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.1435e-06 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.1178e-06 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.1046e-06 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.1226e-06 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 1.0991e-06 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.0883e-06 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.0733e-06 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.0675e-06 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.0523e-06 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.0645e-06 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 149ms/step - loss: 1.0514e-06 - accuracy: 1.0000\n",
            "Epoch 41/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 1.5199e-06 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 8.5244e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.3688e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 1.1852e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 1.2094e-06 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.0557e-06 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.1176e-06 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.0471e-06 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 9.8910e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 4s - loss: 9.0870e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 9.0330e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 8.6693e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 8.1840e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 8.0704e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 7.6019e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 7.2214e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 6.9281e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 6.5750e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 6.7701e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 6.5737e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 6.2713e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 6.1861e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 6.1126e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 6.0431e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 5.9072e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 5.7836e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 5.8040e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 5.9510e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.8374e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 5.9314e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 5.8578e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 5.7159e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 6.9181e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 6.7654e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 6.6306e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 6.4678e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 6.5394e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 6.5395e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 7.2410e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 7.1388e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 7.0589e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 7.6784e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 7.5146e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 170ms/step - loss: 7.6761e-07 - accuracy: 1.0000\n",
            "Epoch 42/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 4.6193e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 2.8436e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 4.0315e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 3.0920e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 4.3163e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 4.9152e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 6.5386e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 5.8470e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 5.6112e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 5.5580e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 5.2514e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 7.0747e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 6.5668e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 6.2893e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 6.0116e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.8337e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.5497e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 5.3463e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 5.4544e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 5.2972e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 5.3548e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 5.7599e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 5.6704e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 5.7585e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 5.6657e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 5.4645e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 5.3164e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 5.4015e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 5.2666e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 5.1937e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 5.0815e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 4.9762e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 4.9568e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 4.8931e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 5.0013e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 4.8724e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.9666e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 5.0787e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.9755e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.8986e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 5.0175e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 6.1000e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 6.0610e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 149ms/step - loss: 6.0069e-07 - accuracy: 1.0000\n",
            "Epoch 43/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 8.9901e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 9.5737e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 6.8378e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 6.4291e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 5.5108e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 4.8428e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 6s - loss: 5.8025e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 6s - loss: 5.3985e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 5.9686e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 5.5506e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 5.1634e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 5.2091e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 4.8571e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 4.7151e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 4.6607e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 4.7132e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 4.4717e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 4.2654e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 4.0945e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 3.9897e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 3.8210e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 3.6976e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 3.6961e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 3.5478e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 4.7627e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 4.7056e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 4.7590e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 4.8382e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 4.7048e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 4.6262e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 4.6316e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 4.7034e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 4.6030e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 5.0362e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 5.0520e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 5.2897e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 5.3333e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 5.2132e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 5.1181e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 5.0516e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.9696e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.9329e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.9080e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 177ms/step - loss: 4.8505e-07 - accuracy: 1.0000\n",
            "Epoch 44/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 2.1731e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 6.4321e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.3377e-06 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 1.0129e-06 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 8.4358e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 8.8159e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 8.3069e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 7.8444e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 7.7454e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 7.0851e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 6.6758e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 6.2023e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 6.0098e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 5.7402e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 5.5438e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 5.4239e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 5.2181e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 5.2421e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 5.1145e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 4.8892e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 4.6954e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 4.5068e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 4.6710e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 4.5266e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 4.3629e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 4.2505e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 4.1602e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 4.0875e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 3.9966e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 3.9106e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 3.8561e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 3.7372e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 3.7195e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 3.6485e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 3.9653e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.9404e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 4.1148e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 4.1081e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 4.1569e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 4.1809e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 4.1419e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 4.0737e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 4.0792e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 152ms/step - loss: 4.0315e-07 - accuracy: 1.0000\n",
            "Epoch 45/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 8s - loss: 1.8626e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 5.5879e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 9.1890e-08 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 4.2497e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 3.4867e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 3.7355e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 8s - loss: 4.8835e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 5.1268e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 5.1601e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 5.2327e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 4.8653e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 4.6575e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 4.6336e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 4.5465e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 4.4504e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 4.3243e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 4.4432e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 4.2757e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 4.3193e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 4.2908e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 4.1243e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 4.0667e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 3.9757e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 3.8520e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 3.7222e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 3.6125e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 3.5376e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 3.4441e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 3.3908e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 3.3250e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 3.3239e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 3.3011e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 3.2767e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 3.2011e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 3.7451e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 3.7072e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 3.7061e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 3.6628e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 3.6612e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.6063e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.5238e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.5162e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.4679e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 173ms/step - loss: 3.4278e-07 - accuracy: 1.0000\n",
            "Epoch 46/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 1.2914e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 2.6760e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 4.3503e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 4.2406e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 3.4868e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.9905e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.9128e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.6496e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.5083e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.3419e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 2.4361e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 2.3552e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.5819e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.4445e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 2.3717e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.3050e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.2286e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.1179e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 2.1188e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.5369e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 2.4238e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.6765e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.5747e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.5740e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 2.5833e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 2.7925e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.7332e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.6857e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.6098e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.6309e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 2.5740e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 2.5289e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.5339e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.4605e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.4239e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.3804e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.4258e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 2.5178e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.7210e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 3.1136e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 3.0644e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 3.0765e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 3.0125e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 162ms/step - loss: 2.9787e-07 - accuracy: 1.0000\n",
            "Epoch 47/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 3.1044e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 8s - loss: 1.7322e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 8s - loss: 1.9082e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 1.8688e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 1.6789e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 2.3676e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 2.4959e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 3.4862e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 3.1596e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 2.8958e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 2.7996e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 2.7898e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 2.6421e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 2.5704e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 2.4032e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 2.4936e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.3739e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.4414e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 2.4410e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 2.3624e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 2.4563e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.4192e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.3388e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.3738e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 2.3087e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 2.2285e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.1629e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.1642e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.1131e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.7306e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.6661e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 2.6298e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.5685e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.5744e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.5573e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.4938e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.5184e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.4773e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.4364e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.3900e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.5707e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.6044e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.6484e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 165ms/step - loss: 2.6205e-07 - accuracy: 1.0000\n",
            "Epoch 48/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 2.6822e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.6329e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.1424e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 9.4374e-08 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 2.0787e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.6760e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.4161e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.1343e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.9358e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.3544e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 2.2453e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 2.1513e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.9143e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 3.7890e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 3.6002e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 3.6041e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 3.5411e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 3.4327e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 3.2886e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 3.1279e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 3.0966e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 3.1568e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 3.1972e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 3.0712e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 2.9727e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 3.0360e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.9323e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.9261e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.9673e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.8767e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 2.8440e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 2.7776e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.7375e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.6584e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.6843e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.6135e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.5620e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.4982e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.4551e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.4195e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.3908e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.3655e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.3605e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 175ms/step - loss: 2.3420e-07 - accuracy: 1.0000\n",
            "Epoch 49/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 3.9736e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 6.7676e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.7592e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.4497e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 3.6879e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 3.8183e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 3.6170e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 3.5731e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 3.2050e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 3.0857e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 3.1743e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 2.9905e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.8464e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.7611e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 2.6432e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 2.5013e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.5835e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 2.4455e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 2.4070e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.4375e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 2.5024e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.4191e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.7583e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.6666e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 2.5639e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 2.4758e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.4310e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.3611e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.4544e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 2.3788e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 2.4114e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 2.4315e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 2.4410e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 2.3867e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.3551e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.3124e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.2801e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 2.2250e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.1778e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.1740e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 2.1503e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 2.1181e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 2.1011e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 152ms/step - loss: 2.0891e-07 - accuracy: 1.0000\n",
            "Epoch 50/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 5.2154e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 1.1052e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.6681e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.7633e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 1.5671e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.3452e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.4901e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.5832e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.6709e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.6776e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.5917e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 1.4932e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 1.3841e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 1.2888e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.2583e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.2410e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.4149e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.3666e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.4006e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.7397e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.6775e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.6419e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.0721e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.0235e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.9898e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 2.0489e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 2.0571e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 2.0019e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 2.0343e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.9835e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.9351e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.9278e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.9522e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.9897e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 2.0368e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 2.0496e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 2.0892e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 2.0459e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 2.0037e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 2.0358e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.9877e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.9528e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.9106e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 177ms/step - loss: 1.8852e-07 - accuracy: 1.0000\n",
            "Epoch 51/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 2.6698e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 6.8046e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 4.6606e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 5s - loss: 4.2560e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 3.5488e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 3.1581e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 2.8524e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.4959e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.6973e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.4412e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 2.5726e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 2.4172e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.2743e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.1154e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.9934e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.9348e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 2.3126e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 2.2234e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 2.2044e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 2.2097e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 2.1435e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 2.2346e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 2.1725e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 2.1011e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 2.0225e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.9739e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.9022e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.8653e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.8451e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.8841e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 1.8278e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.7947e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.7588e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.7604e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.7839e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.7436e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.7566e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 1.8031e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.7652e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.7294e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.6930e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.6678e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.6660e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 152ms/step - loss: 1.7178e-07 - accuracy: 1.0000\n",
            "Epoch 52/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 2.3593e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.7385e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 4.2634e-08 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 4.3462e-08 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 1.4603e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.8978e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.9797e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.8052e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.8226e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.7012e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 2.4259e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 2.3531e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.1816e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.0817e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.9487e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.8370e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.7961e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.7819e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.7312e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.6906e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.6557e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.5911e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.6013e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.5786e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.5427e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.4906e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.6626e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.6107e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.6404e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.5923e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.6083e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.5658e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.5495e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.5164e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.5245e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.5129e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.4867e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.4483e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.4331e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.4395e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.4301e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.5256e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.5403e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 174ms/step - loss: 1.5674e-07 - accuracy: 1.0000\n",
            "Epoch 53/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 1.7633e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 2.2290e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.6060e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.4808e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.2914e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.1817e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.1460e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.1145e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.0296e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.9098e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.8118e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 1.8564e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 1.8894e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 1.8812e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.7575e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.6639e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.5865e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 1.6653e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.6600e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.5981e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.5232e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.6081e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.5668e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.5154e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 1.4573e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.4442e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.4018e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.4422e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.4306e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.4744e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 1.4448e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.4331e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.5646e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.5310e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.4926e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.4773e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.4398e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 1.4022e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.4229e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.4780e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.4674e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.4478e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.4453e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 153ms/step - loss: 1.4447e-07 - accuracy: 1.0000\n",
            "Epoch 54/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 1.4901e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.1797e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 1.2004e-08 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.8129e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.5149e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.3866e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.5309e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.5941e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.6915e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.6180e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.4777e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 1.3763e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.3812e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 1.3615e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.5133e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.4412e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 1.5135e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.4432e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.3868e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.4187e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.3701e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 1.3704e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 1.3530e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 1.3452e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.3575e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.6167e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.5927e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.5668e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.5295e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.4789e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.4504e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.4400e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.5277e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.4912e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.4731e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.4518e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.4143e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.3924e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.3653e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.3833e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.3565e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.3435e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.3217e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 176ms/step - loss: 1.3342e-07 - accuracy: 1.0000\n",
            "Epoch 55/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 1.7385e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 3.9115e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 2.8063e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.8902e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 5s - loss: 2.5928e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 2.2207e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.9247e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 2.6263e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 2.3483e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 2.1631e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 4s - loss: 2.1381e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 2.1058e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 2.1081e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 2.0444e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.9214e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.8882e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.8100e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 3s - loss: 1.7405e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.6809e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.6143e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.5924e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.5262e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.4734e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.4554e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 1.4071e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.3645e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.3429e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.3007e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.3000e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.3307e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 1s - loss: 1.3279e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.3655e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.3317e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.3225e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.2879e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.3235e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.3095e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 1.3091e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.3385e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.3169e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.2905e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.2740e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.2599e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 151ms/step - loss: 1.2425e-07 - accuracy: 1.0000\n",
            "Epoch 56/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 3.3776e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 6s - loss: 1.7881e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 2.0158e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 7s - loss: 1.5460e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 1.2666e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 1.0720e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 1.3056e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 1.1471e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 1.0348e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 1.0319e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 1.0036e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 1.1579e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 1.1013e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 1.0342e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 6s - loss: 1.0182e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.0066e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 9.8829e-08 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 9.3891e-08 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 5s - loss: 9.6792e-08 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 5s - loss: 9.9341e-08 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 1.0472e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 1.0115e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 4s - loss: 1.3071e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 4s - loss: 1.3013e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.2716e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.2322e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.2077e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 3s - loss: 1.1739e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.1955e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.2989e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.2614e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.2282e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 2s - loss: 1.2056e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.3079e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.3049e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.2752e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.2515e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.2241e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.2201e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.1930e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.1666e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.1681e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.1698e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 179ms/step - loss: 1.1545e-07 - accuracy: 1.0000\n",
            "Epoch 57/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 6s - loss: 3.0050e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 7s - loss: 1.9061e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 7s - loss: 1.3866e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 1.5149e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.4404e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 6s - loss: 1.2252e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.0715e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.7850e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.8129e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.7422e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.6131e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 1.4849e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 1.4242e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 1.4768e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.5315e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.5382e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.5222e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.4577e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.3810e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.3225e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.2630e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.2378e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.2833e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.2418e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 1.2318e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.3573e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.3186e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.3118e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.2901e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.2720e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.2426e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.2445e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.2493e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.2334e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.2017e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.1772e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.1501e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 1.1391e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.1182e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.1005e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.0794e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.0948e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.0812e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 1.0844e-07 - accuracy: 1.0000\n",
            "Epoch 58/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 9s - loss: 5.3396e-08 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 5.0291e-08 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 9s - loss: 4.0150e-08 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 8s - loss: 6.7986e-08 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 5.7121e-08 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 8s - loss: 5.3603e-08 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 4.9316e-08 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 1.0244e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 7s - loss: 9.1890e-08 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 7s - loss: 8.2825e-08 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 7s - loss: 1.3761e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 6s - loss: 1.2883e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 6s - loss: 1.2456e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 6s - loss: 1.1655e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.1962e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 5s - loss: 1.1323e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 5s - loss: 1.0701e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 5s - loss: 1.0258e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.0078e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 9.6111e-08 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 4s - loss: 9.1889e-08 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 4s - loss: 9.7139e-08 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.1564e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.1797e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 1.1394e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.1606e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 3s - loss: 1.1737e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.1947e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.2113e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.1772e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.1528e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 2s - loss: 1.1288e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.0980e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.0738e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.0654e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.0413e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.0558e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 1.0483e-07 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.0319e-07 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 1.0133e-07 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.0261e-07 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 1.0378e-07 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.0171e-07 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 171ms/step - loss: 1.0167e-07 - accuracy: 1.0000\n",
            "Epoch 59/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 7s - loss: 4.2840e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 5s - loss: 3.0671e-07 - accuracy: 1.0000 Batch 2\n",
            " 3/44 [=>............................] - ETA: 6s - loss: 2.4959e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 6s - loss: 2.0551e-07 - accuracy: 1.0000 Batch 4\n",
            " 5/44 [==>...........................] - ETA: 6s - loss: 1.7484e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 5s - loss: 1.7509e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 5s - loss: 1.5238e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 5s - loss: 1.4109e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 5s - loss: 1.3921e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 5s - loss: 1.3287e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 5s - loss: 1.2779e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 4s - loss: 1.2521e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 4s - loss: 1.1787e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 4s - loss: 1.1344e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 4s - loss: 1.1275e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.1277e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.1337e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.0955e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 3s - loss: 1.0405e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 3s - loss: 1.0207e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 9.7626e-08 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 9.6067e-08 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.0107e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 1.2355e-07 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 2s - loss: 1.1886e-07 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 2s - loss: 1.1629e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.2303e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.1974e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.1625e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 1.1296e-07 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 1.1000e-07 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 1.0795e-07 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 1.0506e-07 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 1.0241e-07 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 1.0470e-07 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 1.0217e-07 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 1.0119e-07 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 1s - loss: 9.8556e-08 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 9.6825e-08 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 9.6329e-08 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 9.4494e-08 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 9.3457e-08 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 9.6135e-08 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 8s 173ms/step - loss: 9.5116e-08 - accuracy: 1.0000\n",
            "Epoch 60/60\n",
            " Batch 0\n",
            " 1/44 [..............................] - ETA: 10s - loss: 3.6135e-07 - accuracy: 1.0000 Batch 1\n",
            " 2/44 [>.............................] - ETA: 9s - loss: 1.8999e-07 - accuracy: 1.0000  Batch 2\n",
            " 3/44 [=>............................] - ETA: 10s - loss: 2.4173e-07 - accuracy: 1.0000 Batch 3\n",
            " 4/44 [=>............................] - ETA: 9s - loss: 1.8378e-07 - accuracy: 1.0000  Batch 4\n",
            " 5/44 [==>...........................] - ETA: 8s - loss: 2.1383e-07 - accuracy: 1.0000 Batch 5\n",
            " 6/44 [===>..........................] - ETA: 7s - loss: 1.9765e-07 - accuracy: 1.0000 Batch 6\n",
            " 7/44 [===>..........................] - ETA: 7s - loss: 1.7864e-07 - accuracy: 1.0000 Batch 7\n",
            " 8/44 [====>.........................] - ETA: 7s - loss: 1.7602e-07 - accuracy: 1.0000 Batch 8\n",
            " 9/44 [=====>........................] - ETA: 6s - loss: 1.6281e-07 - accuracy: 1.0000 Batch 9\n",
            "10/44 [=====>........................] - ETA: 6s - loss: 1.5659e-07 - accuracy: 1.0000 Batch 10\n",
            "11/44 [======>.......................] - ETA: 6s - loss: 1.4653e-07 - accuracy: 1.0000 Batch 11\n",
            "12/44 [=======>......................] - ETA: 5s - loss: 1.3525e-07 - accuracy: 1.0000 Batch 12\n",
            "13/44 [=======>......................] - ETA: 5s - loss: 1.3229e-07 - accuracy: 1.0000 Batch 13\n",
            "14/44 [========>.....................] - ETA: 5s - loss: 1.2852e-07 - accuracy: 1.0000 Batch 14\n",
            "15/44 [=========>....................] - ETA: 5s - loss: 1.2120e-07 - accuracy: 1.0000 Batch 15\n",
            "16/44 [=========>....................] - ETA: 4s - loss: 1.1556e-07 - accuracy: 1.0000 Batch 16\n",
            "17/44 [==========>...................] - ETA: 4s - loss: 1.1030e-07 - accuracy: 1.0000 Batch 17\n",
            "18/44 [===========>..................] - ETA: 4s - loss: 1.1493e-07 - accuracy: 1.0000 Batch 18\n",
            "19/44 [===========>..................] - ETA: 4s - loss: 1.0921e-07 - accuracy: 1.0000 Batch 19\n",
            "20/44 [============>.................] - ETA: 4s - loss: 1.0387e-07 - accuracy: 1.0000 Batch 20\n",
            "21/44 [=============>................] - ETA: 3s - loss: 1.0165e-07 - accuracy: 1.0000 Batch 21\n",
            "22/44 [==============>...............] - ETA: 3s - loss: 1.0425e-07 - accuracy: 1.0000 Batch 22\n",
            "23/44 [==============>...............] - ETA: 3s - loss: 1.0026e-07 - accuracy: 1.0000 Batch 23\n",
            "24/44 [===============>..............] - ETA: 3s - loss: 9.6495e-08 - accuracy: 1.0000 Batch 24\n",
            "25/44 [================>.............] - ETA: 3s - loss: 9.5069e-08 - accuracy: 1.0000 Batch 25\n",
            "26/44 [================>.............] - ETA: 3s - loss: 1.1276e-07 - accuracy: 1.0000 Batch 26\n",
            "27/44 [=================>............] - ETA: 2s - loss: 1.0872e-07 - accuracy: 1.0000 Batch 27\n",
            "28/44 [==================>...........] - ETA: 2s - loss: 1.0568e-07 - accuracy: 1.0000 Batch 28\n",
            "29/44 [==================>...........] - ETA: 2s - loss: 1.0247e-07 - accuracy: 1.0000 Batch 29\n",
            "30/44 [===================>..........] - ETA: 2s - loss: 9.9423e-08 - accuracy: 1.0000 Batch 30\n",
            "31/44 [====================>.........] - ETA: 2s - loss: 9.8018e-08 - accuracy: 1.0000 Batch 31\n",
            "32/44 [====================>.........] - ETA: 1s - loss: 9.7012e-08 - accuracy: 1.0000 Batch 32\n",
            "33/44 [=====================>........] - ETA: 1s - loss: 9.4862e-08 - accuracy: 1.0000 Batch 33\n",
            "34/44 [======================>.......] - ETA: 1s - loss: 9.3351e-08 - accuracy: 1.0000 Batch 34\n",
            "35/44 [======================>.......] - ETA: 1s - loss: 9.4196e-08 - accuracy: 1.0000 Batch 35\n",
            "36/44 [=======================>......] - ETA: 1s - loss: 9.2856e-08 - accuracy: 1.0000 Batch 36\n",
            "37/44 [========================>.....] - ETA: 1s - loss: 9.1084e-08 - accuracy: 1.0000 Batch 37\n",
            "38/44 [========================>.....] - ETA: 0s - loss: 9.1073e-08 - accuracy: 1.0000 Batch 38\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 8.9152e-08 - accuracy: 1.0000 Batch 39\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 8.9810e-08 - accuracy: 1.0000 Batch 40\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 8.8528e-08 - accuracy: 1.0000 Batch 41\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 8.8845e-08 - accuracy: 1.0000 Batch 42\n",
            "43/44 [============================>.] - ETA: 0s - loss: 9.0244e-08 - accuracy: 1.0000 Batch 43\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 8.9221e-08 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7949c9b815d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        print(f' Batch {batch}')\n",
        "        # print(f'Batch {batch}, Loss: {logs[\"loss\"]}, Accuracy: {logs[\"accuracy\"]}')\n",
        "\n",
        "model = build_and_compile_model(normalizer)\n",
        "\n",
        "# Example usage with the custom callback\n",
        "model.fit(train_features, train_labels, epochs=60, batch_size=96, callbacks=[CustomCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is probably overfitting going on as the network gets to be almost 100% accurate on the training data. Ways to counter overfitting is to get more data (this is only about 20 years of NFL data, including playoffs), stuff like dropping neurons mid training to decrease reliance on them, regularization which penalizes large weights of neurons in the network, early stopping, PCA, and several other strategies that I still have to research. This is pretty much a vanilla perceptron type network."
      ],
      "metadata": {
        "id": "2sCFItWW__Ss"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "# **Evaluate accuracy**\n",
        "\n",
        "Next, compare how the model performs on the test dataset (data the model hasn't seen before, generalization):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VflXLEeECaXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8f1f01-de7b-4a62-8f90-014861aa5e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 0.7144221663475037\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_features,  test_labels, verbose=0)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "The network is very overfit to the data, must learn and then implement the previously enumerated techniques to reduce this overfitting before using this model to predict next season.\n",
        "\n",
        "*   [Demonstrate overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
        "*   [Strategies to prevent overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### Make predictions\n",
        "\n",
        "Attach a softmax layer to convert the model's linear outputs—[logits](https://developers.google.com/machine-learning/glossary#logits)—to probabilities, which should be easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DnfNA0CrQLSD"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Gl91RPhdCaXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba0b407-f746-460e-8bb7-ea92b524ec47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = probability_model.predict(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each input in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3DmJEUinCaXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b567182f-36ac-4f5e-f4aa-a7067a269a8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.0217718e-18, 3.4082961e-28, 9.9999994e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "predictions[4] #[8.0217718e-18 -> away win confidence, 3.4082961e-28 -> tie confidence, 9.9999994e-01 -> home win confidence]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 3 numbers. They represent the model's \"confidence\" that the image corresponds one of the 3 outcomes (away W, tie, home W). You can see which outcome/label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qsqenuPnCaXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509e1be5-db79-4386-ba67-df037d687ba8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "np.argmax(predictions[4])\n",
        "# 9.9999994e-01 is largest value\n",
        "# represents home win expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this game input is a home win, or `class_names[2]`. Examining the test label shows that this classification is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a6e94f-44c1-41f7-e9b0-accce16f3fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "test_labels.iloc[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Define functions to observe the full set of 3 class predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "outputs": [],
      "source": [
        "def visualize_input(i, predictions_array, true_label):\n",
        "    plt.figure(figsize=(20, 5))  # Adjust the figure size as needed\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    # Assuming your input is non-image data\n",
        "    features = test_features.iloc[i]\n",
        "    max_value = features.max()\n",
        "\n",
        "    for idx, (feature_name, feature_value) in enumerate(features.items()):\n",
        "        # Calculate brightness based on the feature value\n",
        "        brightness = feature_value / max_value\n",
        "\n",
        "        # Draw a colored box with brightness based on the feature value\n",
        "        rect = plt.Rectangle((idx / len(features), 0), 1 / len(features), 1, linewidth=0, facecolor=plt.cm.viridis(brightness))\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    true_label_color = 'blue' if predicted_label == true_label else 'red'\n",
        "\n",
        "    # Move the xlabel up slightly for better visibility\n",
        "    plt.xlabel(\"Predicted: {} ({:.2%}), True: {}\".format(class_names[predicted_label],\n",
        "                                                           predictions_array[predicted_label],\n",
        "                                                           class_names[true_label]), color=true_label_color, position=(0, 60), fontsize=16)\n",
        "\n",
        "def feature_info(i, predictions_array, true_label):\n",
        "    # Assuming your input is non-image data\n",
        "    input_str = \", \".join([f\"{feature_name}: {feature_value}\" for feature_name, feature_value in test_features.iloc[i].items()])\n",
        "    print(f\"Input: \\n{input_str}\")\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    class_names = [\"Away Win\", \"Tie\", \"Home Win\"]\n",
        "\n",
        "    if predicted_label == true_label:\n",
        "        out = 'correct prediction'\n",
        "    else:\n",
        "        out = 'incorrect prediction'\n",
        "\n",
        "    print(out)\n",
        "    print(\"Predicted: {} ({:.2%}), True: {}\".format(class_names[predicted_label],\n",
        "                                                     predictions_array[predicted_label],\n",
        "                                                     class_names[true_label]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HV5jw-5HwSmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "fa2d83eb-5fa0-4e93-d110-413895c432aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAAGuCAYAAAAd9x6WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyh0lEQVR4nO3deZglZX0v8F/3DAwDMywCAgMMmyNkIciisgnIquKgcCESo4KJEQ0BlUiCGi+4Y25cENxiRKORXCM6XCVEBRQVXCAsKhrRwCCbD/uMwzADTHfdP36n+uzdp4d+u0fy+TzPPKfn1HLeqlP1Vp33W/XWUFVVVQAAAAAAABQwPNMFAAAAAAAAnroEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAipk9yEijo6Nxzz33xPz582NoaKh0mQAAAAAAgHVYVVWxYsWKWLBgQQwPj3/Pw0BBxD333BPbb7/9lBQOAAAAAAB4arjzzjtju+22G3ecgYKI+fPnR0TE84YXx1d/8bOIiDj2mbuPDR+avV5ERFRrnoiIiCW//GlERLz/wV0jIuKH+63ff+ZDjaSkGh2kKFNq9g4ZrlTLfxsREaOPPDo2rF6WQcyaPy8iIobmzo2IiF+fvHNERGz79z/qHrmxvMMb5DqpHs/PqUar5vw2yvmMPLIyJ5k1q+01ImL08ccHLt/shdvmZ/z2kZy2Xs7GOh+a3dwMqjVr8nVkpL3Yjc/ufD8iYnjOnLb/jz7eXHfDc3PY6KOr2qeZu0Fj5OZyjz72WFt545GcZuS3KxplG/w7aS1TPd9BjLec/XRtRyseGRs2mflMl7HyNtZrRMToitzWxtbxUEeC2WP/rNdxr/U7vH5jn5+V8xldtXrCcs3abNOIiBh5eFl7eXfeofmfRjlHHl7eVt66DopoWeeTqFPq8k5mvxrPWJkfy/mN3PtAV5mG522UbzXWzVR9dt8y7bQw/1jV/L5GHngoyzCJfWuq1dvj2LpqlGlovWZ9N7RBo76osr4YWba8bJlat7lHV/cs11iZWnRuu1Nervo7XJ51zEjLPjzU2NeGNszjR4zmtjbSqJemtVzLG/vnDNZ/Y9tVo86I6D6WjNX39XFoGs5Dxo7Hy7MsoytXdX12fXyszw+K1w07NC80qRr71mjj/KP+DlvPP8bGLfz99l1XLWZtunGOs7qxnz6ysmucKS/XOOeOERFD63efWneeA021sfPwlu9k1rwNIyJipOWcpKSx87roccwf51x/eI/d8nVZY5tr7KeD1Kdjx/7GfFvPpTs/q66nqmXNOrFamd/d8NZbNkZqfHer8zg5+uDDY+PW5zqd5+RDz9wpy3vzLT0K2DjnXz/LObRezr9tO12L30Fj5yxPrOmadmx/bizbSGN5622jLktE/3P+8XTVmy06f7+Mlbc+Jx9u3lVfbyNjx4/6/K4u7yTPS4Ybx77S+1rf31TRso4bv/FGVzfq7h7fbedv59qsTTdpzq8+Pxzgd0z9W7Re/rosvbb70fpYuC7+Rqm3h4iIxrrtPOcf+40RzWXoWpbx6py6rhrJYU/2GNtvn2v/zNwH6n1ukN9FU1KmiIjGZ4082DjnXxfOzZ7I73Lk3vvHhhUvV59touc299DDbWVqPQearnPGfnVjxAz/bussV+NY3fr9Tff5dWeZIsY59lUtbU/TdH7ddb7Y65y/Uc7idUPdzhYtx7HGeeKM1g3jHFvr9TVrkzw+jq7M73kybXxrXa4+7Xwzua46z30jmu1oax54cFrK0O+cf008EVfHZWP5wXgGCiLq7phmD60XG8+fNfZ3c3jjZKpxflmPM+ex9brG7Z553eA5A0HEcOOkYKhxwjjUrNSrSfRANasx/dBwvs6ak19Mz+Wuf5Q0pqk/pxpqCSLq+Q093nid1faaZe3+AdBPczkfb0xbL2cjiGgpZ9X4rquOhuj6szvfb12WZtm6h40Orek9TctyjA6NtpU3hkfayjeZ76S1TPV8BzHecvbTvR21rs917zEsY+Udblbeo41tY2wdd5W7x4n82PL2GtZYB431OTo0cWU9a7je7tv3m7HtISJi+Im2ceryDvVc55P4Ud+YfjL71Xia2/BQR/laTjzG6oCRKf3sicvU/Jy12bemWrNc+VKXaWioeXiq69Y6uOzcRoqVKSJiuL2erMs1VqYW01au4frY0HocntVerqq7fp/ucs1k/dcsU/O43l1v1PV9vU9MQxAxdrxoNHSOHRt71Q2NIdNVN0Trcaw+JjQCrqEeQUTh77f/umqqjxvVUL29l/1R2V6u7nPHLEP3Pter7FOp1z7XPJcsXwdEdJ539WkU7HUuMSvX5/Bwo1G8cW4ySLk7j61V277S0dg0du7T0ojZ+O6Gx+qLxnFnuF6O7nPJznPyoUb5e5a345x/7PjRup0+qXOW+uDdEkSMLcuatnJVHWXJ93qf84+nu95s6vz90ixvfc7fEkQ0tpHOunptz0v6/d6Yav1/U3Wv49Fxji39lnNW2/fTaCgf4HfMrI7lr8vSa7sfXQeO0f20n391bsONt3uc83cty3h1ztj2ODXn3/32uV6fWZdzkN9FU1KmiK7z2HXj3Kw+t5jG38x9tonxt7nuc6DpOmfsVzdmGYp+9Lj619nN72+6z6/HP+fvPPY1yzJd59fd54vjtQdMX93QPI6tO3VDr2Nrvb7qc/562GTa+J58udrb+WZyXfVqV6rXTcz0OX9jlxrkcQ7r3hkIAAAAAADwlCGIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAihFEAAAAAAAAxQgiAAAAAACAYgQRAAAAAABAMYIIAAAAAACgGEEEAAAAAABQjCACAAAAAAAoRhABAAAAAAAUI4gAAAAAAACKEUQAAAAAAADFCCIAAAAAAIBiBBEAAAAAAEAxgggAAAAAAKAYQQQAAAAAAFCMIAIAAAAAAChGEAEAAAAAABQjiAAAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGzBxmpqqqIiFhTPRG/XTEy9ndtqKrHy/fqcR575InGuEPjzL2RhVSjAxd6yow+lh9dPZ7/bVmmquXvidTTD43OioiIkcdWR0T7OmrK5R1urJP6c+p13Dq/kcawoca6GWpZR6OTKF/f5Rybb+tnr2m8jrTNov7szvdzWdrzrNay1cM6yztczao/sHu6RnljtH09TOY7aS3TZNbVeMvZ17jb0STmM13q8jbWb0SzzM113JFR9tg/+323OayxzzeWf5DvoOr4vjvLm3/33iaGmptRc51Pok6pyzup/Wo8fbbh1jINN7aXehmm7LMHLFNruSazb025Puuqtb4bGq2PE1XbOMXLNE65xsrUYtrK1WNfGWps9/VxqN7WipdpnHLNaP03wPberO/rk5hpOA+Z4Hgc0Tw+Tnvd0KNc9Xc41GPdFP9+xzm2jpVh9PG2caZze+9XrtZzqrFJCpereR7e/E6mdZ1Ey3ld9Fre/uf6wyO5Poc7zk0GKffYsb9zX+71WT3Ofep9bHisvhhpG3e06j5P6jwnH2qUv3d563P+aJumfdzJ/w5qnrOs6Z52gvp4uO18qfc5/3i66s0W/ba5sXPylt+DU3nOn5/Rv56YUgOc83edU/b4bjt/Ozfn8XjX3wOdQ/epu8c/5193f6Pk3723ieGW7ahehu5lGafOqdrPk570NjPOuVnzM4cb5VwzNZ85aJl6lGvdODfLsoz02H/K6bNNDLCuWs+Bpu2ccZztal383db6/U37+fW45/wdx75ebU+FyzXYOf/gbSZTUaZe5VoX6oaex716exqth03T8X6ccs3kuuo8980/s3y925+nXr9z/jXR3bbdz1A1wFh33XVXbL/99mtTRgAAAAAA4CnqzjvvjO22227ccQYKIkZHR+Oee+6J+fPnx9DQeHc3AAAAAAAAT3VVVcWKFStiwYIFMTw8/lMgBgoiAAAAAAAA1oaHVQMAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBADQZscdI4aG2v/NmROxcGHEy14W8b3vzXQJm845J8t3zjnt73/2s/n+ySdPf5mmSr9lezLq7/b226dunjTN1HZ3440Rs2ZFnHZa97DLLsttaPHiiAULmvv0XXdNPN/HH494//sj9tgjYqONIjbbLOKQQyIuvnjiab/0pRx3s81y2j32iPj7v4944olJLlyL66+POOGEiK22ithgg4iddsplvu++8ae7996Iv/qrHH/OnJz+hBMibrih/zSXXx7x7Gfn52y9dcTpp0esWtV73NHRiOc8J8d7+OHe4yxfHrH55hHPfW5EVQ22vBO56qruunqQf1NZp8yk22/P5dlxx5kuyVPXySfnOv7sZ2e6JADAU8HsmS4AALBuOuCAiGc8I/9etiziP/8z4t/+LRsY/+EfIs44Y0aLN2123DHi17+OWLpUgxfrptNOi5g7N+Ltb+8e9vKXZyP4ZD36aMQRR0R8//sRm24a8YIXRDzySMS3vhXxne9E/PVfZz3QyxvfGHHeeRGzZ0ccemjEvHk53d/+bcTXvhbxzW9meSfj4osj/uRPItasyYBgp52yTrrggqyTrr66WV+1+uUvI573vAwrdt454qUvzX354osjLrkk67Rjj22f5qabIl70ooj114846qiIW2+NOP/8nO5rX+v+jPPPj7juuoh//dcMXnrZZJOIt7wl4swzIz73uYiTTprc8vey9da953PTTRE//nEGLi94QffwZz3ryX82AABMliACAOjpNa9pv7J79eqIU07JRrS/+ZuIF7844pnPnLHijevYYyP23Tcb/2C6zMR2d/HFEddckw3cT3969/DjjotYtChir73yX69xennrWzOE2H33DBG22CLfv/76vNPhAx/I1xe/uH26Sy7JEGLevAws9tor33/ggQwlrr46A5N+IUYv99yTDe5r1kR88pMRr31tvj8yknXUv/xLBi4/+lFevV2rqogTT8wQ4pWvjPjMZ/LOkYiIf/zHrM9e9aqIX/0qG/Vr73hHftbll+cyrlmTocyll2b4sc8+zXHvvDPi7/4ug4sTTxx/Of7qr/KukLe8JcedM2fwddDLbrv1vlL9nHMyiOg3HAb1vvdFnHVWxDbbzHRJAICnAl0zAQAD2WCDiI9+NLtZGRmJ+MpXZrpE/W2ySTbCaTxhOs3EdvehD+Xrn/957+EXXpgN30cdFbHlloPN8+GHIz7+8fz74x9vhhAREXvvnXc2RES85z3d0773vfl61lnNECIi5/Gxj+XfF1wwubs0PvzhvEPj8MObIUREhgof/3iu9+uuyzstWv3Hf2S3VZtump9dhxAROZ/DDsu7PM47r326//zPDG8OOST/P3t2BrMRGc60OvXUDDzqZRvPBhtkYPKb30R88YsDLDjMsG22yTpNqA8ATAVBBAAwsHnzInbdNf9ufc5A3fd4RF51vN9+2XDR+TyCe+7JLp1+7/ciNtwwYv787GblggvyquNeVq3KK3wXLcoriLfZJq+OvuOO/uWcqK/+u+/OK8h33z3LsNFGeXfHySc3Gxrrefz61/n/nXZq72f9qqva5zldyzZVvv3tiCOPzK5k5s7NRuPPfa7/+I8+GnHuuTne/Pm5jH/wB3k1eK9+8Vv7bx8djfjIRyL+6I9yum22iXjd6yIeeijHfeyxiHe9Kxu85s7NZxm84Q0RK1f2L8/110f86Z/ms0vmzIl42tOysf2yyya3Ho47LsvZGaytWdPchv/4j7un+7M/y2EXXth8r992V/flf8gh+YyE978/193cufncgOOOi/iv/5pcuSOykf3738+7MOr9cipcdlk+H2LhwuyirdPLX56vP/xhbve1u+/OQKB1nFYHHhix/fb5fU/me1qypP88582LOOaY/LvzO6ynO+aYHK/fcnRO9+CDuT212nzzfH3kkeZ7F1+cXTW9+90RO+ww8XJENLeNj350sPGn2iGHNOuv730vnx2y5ZYRw8PNuycmei7ARPXrL3+Zd5vsskuGL5tsEnHQQXnnSilVlXe57L131uebbJL12w9+0H+au+7Kbs0WLWqW84AD8q6bkZHu8VuXe/nyrO933DGnXbQo9+vR0Rz37rtzHWy/fdZPu+6aXXiN5+KLsyutLbfMbsG23TbiFa+I+PnPJ7cettgiv88HH2wfdu21zeNXr+Bs551z2G23Nd/rty20PsPo/vszkNt++yz39tvnel22bPByAwD/MwgiAIBJ+e1v87VXtyKnnZZXDs+eHXH00flg1jqg+O53I/7wD/MK7tWrs6uTAw7I/tdPOy3H73yQ7aOPZncu73hHXkV85JHZ3/s3vpEN4kuXTr78V16Z5fiHf8guWw47LD97000jLrooG7Misr/5k07KRq2IiP/1v/L/9b/Wrlyme9nqh06vbbcrF16Yy/3QQ9nw9axnZaP2SSfl1eedHnool+ctb8llOvTQ7Irmvvvyqvi99x7/AdiveEVeIb/tthkWjI5mY9/hh2fYcPjh+X3sumv+/eijGVyccELv+Z13Xj4c+KKLsoH4mGOyYf+qq3Jdv/Odg6+Lww/P1yuuaH//2mub2/q3vtX9gOErr2yffhBPPJHr7Z3vzEb+o4/O7WvJkoj995/8Q8QvuWTyZRjEjTfma2sXRK123rnZUH/TTd3TPe1pGdz1Us+zHnciK1ZE/Pd/j1+efvOcaDnq93/1q/bQa8cdcztv3WfroGjbbfN1+fJ8gPU+++TroJ71rGxovvba3O9nSv0w8dtuy+3niCOefFdR9Xz32CPr0fXXz+19n33yweCvfGUGeJ3q0LIzuJ6MV786u77adNPsLmzrrbNrrec/P7vs6nTddVnOCy7I0O2lL8198IYbMiQ9+uh8v5dlyzJs/8IXctkOPjiDh7POygD11lvz/f/4j5xnfSw4/fQMKzqtWRPxspdlfXfVVRmKv/SluZ3Un/H1rw+2HoaGsn6uqmYdVWut4zrru9tuy2POTjvl/j2oO+/M49WXv5x18hFH5D57wQV5THsyD6cHAJ6CKgCAFjvsUFURVfWZz3QP+/GPq2p4OIdfeGHz/Wz2qKqNN66qH/yge7rf/KaqNt+8qoaGqupjH6uqkZHmsAceqKpDD83p3/GO9une/OZ8f7fdquruu5vvr1xZVS95SfNzzz67fbrPfCbfP+mk9vfvuKOqNtkkh511VlU99lj78Hvvrarvfa/3+li6tHu5ZmLZWsvU6zsaTz3deutV1de+1j6sXmebbFJVjz7aPuxlL8thz31uLlNtxYqqeuELc9j++7dPs3Rpcxl22aWqbr+9OeyBB6pq0aIctvvuVfWc57TP97bbqmqzzXL41Ve3z/frX891vcUWVfWd77QP+8lPqmq77XK6q64abJ3cckuOv2hR+/vveEe+/0d/lK/XXz/xNP22u29/u7ku9twzt5naqlVVddRROey1rx2szLUDD8zp/v3fB5+mLsedd/Yf57jjcpw3vrH/OPV6ueCC5nsf+Ui+96xn9Z/u9NNznOOPH6y8P/lJs8zLlvUe5ytfyeFbbNH+/tOelu9fcknv6R56qDnvm29uvn/WWfneGWdU1cMPV9W111bVggVVtf76ze/ulFOqavbsqrrxxsGWo9Uxx+T8P//5yU87iLPPzvkffHD3sIMPbi7zRz/ae/qTThq/fum3nf/kJ1U1Z05VbbBBVX35y+3Dbr899/WIqvrnf24f1lpX9Ktne2mdbocdcr+srVlTVX/2ZznsyCPbp1u9ulkXvu51VfX4481ht95aVTvumMPe+tbeyx1RVYsXZ11du/763B6Gh6vq938/5/vEE83hl1zSPEa2TldV+Tl1/Xrbbe3DvvSlqpo1K+vDhx8ebL188pM5v7/4i/b3n//83IZ3262qNt0019FE0/TbFuptLKKqTj4512ntjjuqatttc9hFFw1WZgDgfwZ3RAAAE1q+PLtSOe64vJp9wYLe3dW8+c3ZTUynD384u4k49dSI178+u42obb55dgm03np5FWV95fmqVXnVfETeabBgQXOaDTeM+MQnskuMyfjgB3NZFi/Oh3Cuv3778Kc/PbuPmYyZWLZddsm7B9a23+7TTut+yPDJJ2fXSMuXZx/5tTvuyKuch4byKue6i5qI7O7mU5/Ksn7/+93959c+8pH2rms23zzXVUTEzTdHfPrT7fPdaae8iyKi+6res8/O9fiJT2R3L6123z2/44iJu0GpPfOZ2ZXIr37V3iXWFVfkcp19dv7/8svbh0VM/k6EoaHsuqz1bpoNNsi7YlrnO6j6iv/f+73JTTeRFSvytb4bqJe6q6P6rpEnM90gZRlvvv3mOVF5Wrtrap32rLNy//rgB7Prsuc8J+9e+PCH87u75prcF844I+9wqD3+eP9u2Fr9wR/k6w03TDxuKYceGvGXfzm183zPe7LbrXe/O48VrXbYIffziKwPWq23Xq7vXXfNv9fG+efnvlybNav5DJPvfKf9yvwvfSm73FuwIL/T1s/ceefmg9TPPz/vcOs0b17EP/1T1tW1vfbKuz9GR7P7rg99KO8MrL3kJVk//fa37fXrQw/luBtskHcVdN5JdPzx2cXTww8P3rVVr7u8Vq3K+nm//fL4t2xZeznWtk7bbrvsZqz1bpq6a6bOMgAACCIAgJ5e/epmdxmbbppdVdx6azaCX3ZZ78a944/vPa9///d8fdnLeg/fdtvsY/v++7NBOCIb6VasyP6uX/CC7mm23jq7fpiMunuL1gfePlkzsWxXXhnxi19EHHvs2pV58eLe79cN2nff3Xzvu9/NxrU998xnPHSqu1uKyOdOdJo9u/eyLFqUrwsXZrdW/Ya3PoPggQeyS5u5c/svQ/2A4X6hSC9141sdNqxcmc8/OPDAXLb11uvdrclkG+0WLszuYDr1Wu8TWbmy2Z1Qa4jDk7fJJtlIe/75WVeceWZ27/P612eD9imnZIP1Oefk+FdemQ3Rc+bkv4MOGr/rqfr7uvfe4ovSV7+6em2NjmZXRBH968J99slG/BtvbG/g33bbrM9+8Ytm11eTMXt2/3p0s80yHGl9XkL9fJ8TT+zdHdVxx+V0K1bks2g67b13htad6jrr+c/vHST3qtO+/e0MCQ44oP+yT7ZO23nnDDSWLs1jdkQ+D+Sxx7LrpM6goqqy+7mhoeyybzIOO6w9kKmtTZ0GADz1zZ54FADgf6IDDsjnJETknQNPf3re7fCCF7Rf6dlqxx17v18//PJ5z5v4c++/P69sveuu8ecZ0b8f+n7qB0/vttvkphvPurJsk7FwYe/3N944X1sbCeuGpPHKs8su7eO22mab3ttLfTV6v7LMn99dlqVLs9Fs1aqJ+7O///7xh7c6/PC8U+GKKyL+/M+bV1AfcUQGbvvuG3H11VmW9dfPxsPh4byqfDImWu+PPTb4vJYvb/5dr6upUs9vvIeF1w9trsv+ZKYbpCz1fHvdBdRvnvPn5xXn/crT+uDpzmnnzctnDnQ699yIn/0sQ6u5czOweOELs5H5//7f3Dbf9rZsjL755rxivFP9Wb0e8j5dxqt71saDDzbvKtl++8HGX5vQoZdttul/J8XGG+d6nkydNjSUwx5+uHed1m8/Xps6rT5+XHll83lK/Uy2TvvUp7JO22WXZuhwxBF5Z8acOfne296WwdCDD2bYPNlQczLHEgAAQQQA0NNrXpPd9UzG3Lm93x8dzdfjjx+/25aI372ru38Xl214Gu+JneizJlOWel3Pm5cPD58qhx2WjYBXXplBR2ujXUQ26n3vexlGbLxxdmvy7GfnnUKTMZXrvfWzV6wYvGF/EHUjdWtXVZ16hWn133fe2X+6etigDeGtXXrdcUc2og46zx13zCCi33LU0w0NtX9OP7/8ZXb386pXNa8q/8AHMrRasqTZNdDWW2c48bGPRbz3vd3zqUOkzTab+DNL6VdXD6LeD/u9d9JJE89jKh6MXZvO+myQz1ubOu0Zz8jwfzyTCdDrIOLyy/MOniuuyO1tn32yfPvvn12MPfro2t/hFTH96x4A+N0miAAAiqv74P/bv82GkEHUV8vefnv/ccYb1svChRG33JJdgNR3ezxZ68qylVKXtb5yt5d62FRd4dxPfaX10FDEhRdOXSPYVltl91A//WnEj3+cDXNbbNHs///ww/NZEVdc0WzwX5tGu6m04YYZfK1cmVczT2UQsdde+drah3yr227LBv6IvIq6Vv/94IN590qvK87redafMZGNN8599b//O6ftFUT0m+dee2U3aP2Wo35/0aL250X0c8opeVV7/RySiIibbsptpfX5BPVzZm66qfd86m6Cttpq4s+cCfWzc1qfz9GqvrOs1RZbZLixalU+Y2GLLcqV78kapE5burR93FLqOm3XXSM++9mpm28drn772xH33Zfb4rHHNuvMww/PYd/97pMLIgAAJsM1DABAcS98Yb7+278NPs3ee2fj4AMPRHzzm93D77239/vjqfsR/9SnBp+mbpTr9xDadWXZSjnooGy8uummbKTv9JvfNJ+98fznly3LggX5nIoVK5qfOVXqRrgvfCG71Kkb8iLyYcUbb5xXF69LjXZ1w/vPfz61833Ri3K7v+OOvGq600UX5eu++7Y/aH277fJOkdZxWl19dd6FMGdOfsag6meh9JrnI49EfO1r+XfnA5Lr6b761d7dM9Xz65yulwsvzGcLfOhD7Xc2DQ3lVeX1g+gjmp/Vr6udm2/O1733nvhzZ0Ld+P5f/9U9rKqaz4JoNWtW8w6iydSFM6F+5sIXv9i766AlS7Jbpvnzy39Hhx2W+9pVV2VgMFU23zyD1Iceivg//ye/t/r7iWjWX5demvvlnDmDdS8IAPBkCCIAgOLOPDO7kvngB7Mrk8cf7x5n6dKIf/mX5v/nzm0+VPpNb8oG79qqVfng2FWrJleOM87IxqWvfjXi7/4uu1Rpdd992SjTqu7j/Wc/6z3PmVi2ww7LbjqWLOk/zlRZuDDihBOyIeuUU9of+rpyZS7H6tXZ1cf++5cvz7vfna+vfnWzAbpVVeWDhScb5NQNcxdc0N1oN3t2xMEHZxhzzTX5/U3Ujcp0qIOfH/xgaue72Wa5DUZE/OVftn/nN9wQ8f73599ve1v3tG99a76ee26OW3vwwZxXRD57ofNZD0uW5Dbd62G5b3xj3gFyxRXtIeLISM6z7iqr86HoL3xh3qWxbFmONzLSHPaP/5hdcc2bF/GGN/RZEQ333Zf7+ZFHRrziFe3D9torg4h//df2edfDeqm/r17PGDnkkAww6gdhz4R6X/j859tDrieeyDu/rruu93Rnn52N6meeGfHP/9y7C6ebb474ylfa37v77vzud9tteh5ufMIJWa/dc08eE1pD5qVLI/76r/Pv007r/dDpqbTVVvk5K1dGLF6cd2V1euyxPGb94heTm3drnRbRXqfts08etz796TzW7L//k+uuCwBgEIIIAKC47baL+H//Lxs43/zm7I7isMOyUW/x4ux6Zeedmw0mtXe+M69G//nPs+uTY46J+OM/znG/+93sq30yFi6MuPjiDCPe854sx7HH5jyf+9ws5z/9U/s09bMIXvGK/Ps1r8l/t9wyc8t26635+a0PLC7pox+N2GOPbODfZZdcZyeckF3vXHppvn7hC9NTlsWLI847L6/0PeaY7FbnxS+O+NM/zYbirbfOK/W/9a3Jzffgg/OBt/UV0q2NdhHZqDc6mkHTgQdObR/3a+ulL83Xyy/vP8673pXro/5XO+aY5nt1QNDqve+N2G+/iJ/8JNfx8cdnw/6+++ZdCGeckeu9V5lOPz3H2XffnOb443M/+OlPM8B517u6p1u+PLfpW2/tHrZgQXZbM2tWBl/77htx4om533z+89mYe9FF3XcgDA1lQLDllhGf+1yOf+KJua+fckoGTJ/7XG4z43njG3O7+MQnuoedeWY2Vr/qVbmshx4a8b//d16R3mu91g8Gfs5z8iHLnerG+34PX54OBxwQ8ZKX5He4zz65X73kJVk3ffKT/YObvfZqBq4nn5zP3TjqqKwLX/SirBt33737joknnsjv/pZbusPhEubMyePA054W8fGP57Z54okRRx8d8fu/n2HEUUdlsDIdzj034uUvj7j22ryLYa+9cp858cSsazbfPNf/ZLvrq4OI1auzjt5ll+aw4eEMMuv6bl24wwsAeOoTRAAA0+Kgg/Kugre/PRvvr7su4ktfyqvMt9oqG306u0zaaKPsx/rtb89xvvGNbKQ/7LDs371XH/QTOfLIvCr3DW/IK0K//vXsamTZsohXvjLida9rH//1r4943/uyUe2yy/IK0k9/uv0uhnVl2UrZfPOI738/18NOO+XdBpdemv3Av/WtEddfP/jDh6fC6adng+5rX9t8yPQll2Qj9p57RnzkIznOZGy0UbOhftGiDK1atTbUrSuNdnvumVcyX3tt7250InKd/OhHzX+1G29svtera6cNN8zuYt73vuyq57LL8kr+/fbLhuQPfKB/uc47L7u92W+/3G4uuyz3i3PPzYBoba68PuGELOtxx2Xf/kuW5B0Op56aXYb1e+bLrrtmmHLqqTn+kiXZ0HzccTm/uvumfr7xjQwzzjmn9z65xx65TAceGPGd7+S+f/TR+XDzXkFD/RyAU0/tHrZmTZZ1zpzuOy+m2xe/mHeNbbNNbgc//GF23XPDDc1np/RywglZF77pTVm/XnNNxJe/nNvYM56R28B73jNNCzGOZz876+dTT82Aa8mS/M723DPDiUsvbXbLV9rs2RnkXnZZBnn33Zd3QHzjGxm4Ll6cQdtBB01uvs97XjMw7VVnrYt1GgDw1DZUVa09mgIAAL8rLr44G3/POGP8cICZt3p13hWw3noZhnTeVXPNNRlovOlN7Q/EBgCApwJ3RAAAwO+o44/PrnQ++cl8yDnrrvPPzwfUv+99vbv2+uY386HovZ69AQAAv+vcEQEAAL/Dbrwx+/J//eu7n0XCumH58nzGwjOekd0cdT7PAgAAnuoEEQAAAAAAQDG6ZgIAAAAAAIoRRAAAAAAAAMUIIgAAAAAAgGIEEQAAAAAAQDGCCAAAAAAAoBhBBAAAAAAAUIwgAgAAAAAAKEYQAQAAAAAAFCOIAAAAAAAAivn/aqraTLW9zaoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "seasonWeek: 17.0, seasonYear: 2013.0, weekday: 0.0, monthDay: 29.0, month: 3.0, year: 2013.0, militaryTime: 1625.0, stadium: 3.0, field: 6.0, visSeasonWinsComingIntoGame: 6.0, visSeasonTiesComingIntoGame: 10.0, visSeasonLossesComingIntoGame: 0.0, vis_coach_games: 0.0, vis_coach_wins: 0.0, vis_coach_losses: 0.0, vis_coach_ties: 0.0, vis_coach_mean_SRS: 0.0, vis_coach_mean_OSRS: 0.0, vis_coach_mean_DSRS: 0.0, vis_coach_playoff_games: 0.0, vis_coach_playoff_wins: 0.0, vis_coach_playoff_losses: 0.0, vis_coach_mean_division_placement: 0.0, vis_qb_hand: 1.0, vis_qb_height: 183.0, vis_qb_weight: 90.0, vis_qb_age: 28.0, vis_qb_av: 0.0, vis_qb_games: 1.0, vis_qb_wins: 0.0, vis_qb_losses: 1.0, vis_qb_ties: 0.0, vis_qb_cmp_pg: 78.0, vis_qb_patt_pg: 128.0, vis_qb_pyds_pg: 847.0, vis_qb_ptd_pg: 4.0, vis_qb_int_pg: 3.0, vis_qb_p1D_pg: 12.0, vis_qb_psucc_ps: 54.3, vis_qb_plng_ps: 23.0, vis_qb_sk_pg: 13.0, vis_qb_skyds_pg: 67.0, vis_qb_gwd_pg: 0.0, vis_qb_ratt_pg: 18.0, vis_qb_ryds_pg: 38.0, vis_qb_rtd_pg: 2.0, vis_qb_r1d_pg: 0.0, vis_qb_rsucc_ps: 0.0, vis_qb_rlng_ps: 3.0, vis_qb_fmb_pg: 4.0, vis_R1_height: 180.0, vis_R1_weight: 87.0, vis_R1_age: 26.0, vis_R1_av: 23.0, vis_R1_games: 46.0, vis_R1_gs: 21.0, vis_R1_tgts_pg: 3.739130434782609, vis_R1_recs_pg: 2.8260869565217392, vis_R1_cyds_pg: 22.065217391304348, vis_R1_ctd_pg: 0.108695652173913, vis_R1_c1d_pg: 0.9347826086956522, vis_R1_csucc_ps: 43.86666666666667, vis_R1_clng_ps: 42.0, vis_R1_ratt_pg: 11.73913043478261, vis_R1_ryds_pg: 61.391304347826086, vis_R1_rtd_pg: 0.3043478260869565, vis_R1_r1d_pg: 1.9565217391304348, vis_R1_rsucc_ps: 48.96666666666667, vis_R1_rlng_ps: 40.0, vis_R1_fmb_pg: 0.2391304347826087, vis_R2_height: 178.0, vis_R2_weight: 108.0, vis_R2_age: 28.0, vis_R2_av: 0.0, vis_R2_games: 2.0, vis_R2_gs: 1.0, vis_R2_tgts_pg: 4.0, vis_R2_recs_pg: 3.5, vis_R2_cyds_pg: 39.5, vis_R2_ctd_pg: 0.5, vis_R2_c1d_pg: 0.0, vis_R2_csucc_ps: 0.0, vis_R2_clng_ps: 0.0, vis_R2_ratt_pg: 6.0, vis_R2_ryds_pg: 23.0, vis_R2_rtd_pg: 0.5, vis_R2_r1d_pg: 0.0, vis_R2_rsucc_ps: 0.0, vis_R2_rlng_ps: 0.0, vis_R2_fmb_pg: 0.0, vis_R3_height: 183.0, vis_R3_weight: 88.0, vis_R3_age: 21.0, vis_R3_av: 0.0, vis_R3_games: 0.0, vis_R3_gs: 0.0, vis_R3_tgts_pg: 0.0, vis_R3_recs_pg: 0.0, vis_R3_cyds_pg: 0.0, vis_R3_ctd_pg: 0.0, vis_R3_c1d_pg: 0.0, vis_R3_csucc_ps: 0.0, vis_R3_clng_ps: 0.0, vis_R3_ratt_pg: 0.0, vis_R3_ryds_pg: 0.0, vis_R3_rtd_pg: 0.0, vis_R3_r1d_pg: 0.0, vis_R3_rsucc_ps: 0.0, vis_R3_rlng_ps: 0.0, vis_R3_fmb_pg: 0.0, vis_R4_height: 188.0, vis_R4_weight: 95.0, vis_R4_age: 24.0, vis_R4_av: 3.0, vis_R4_games: 15.0, vis_R4_gs: 11.0, vis_R4_tgts_pg: 7.4, vis_R4_recs_pg: 3.4, vis_R4_cyds_pg: 41.4, vis_R4_ctd_pg: 0.1333333333333333, vis_R4_c1d_pg: 1.0, vis_R4_csucc_ps: 37.9, vis_R4_clng_ps: 51.0, vis_R4_ratt_pg: 0.3333333333333333, vis_R4_ryds_pg: 1.2666666666666666, vis_R4_rtd_pg: 0.0, vis_R4_r1d_pg: 0.0, vis_R4_rsucc_ps: 100.0, vis_R4_rlng_ps: 5.0, vis_R4_fmb_pg: 0.0666666666666666, vis_R5_height: 198.0, vis_R5_weight: 120.0, vis_R5_age: 26.0, vis_R5_av: 0.0, vis_R5_games: 26.0, vis_R5_gs: 10.0, vis_R5_tgts_pg: 0.6538461538461539, vis_R5_recs_pg: 0.5, vis_R5_cyds_pg: 3.923076923076923, vis_R5_ctd_pg: 0.0769230769230769, vis_R5_c1d_pg: 0.1153846153846153, vis_R5_csucc_ps: 37.5, vis_R5_clng_ps: 5.5, vis_R5_ratt_pg: 0.0, vis_R5_ryds_pg: 0.0, vis_R5_rtd_pg: 0.0, vis_R5_r1d_pg: 0.0, vis_R5_rsucc_ps: 0.0, vis_R5_rlng_ps: 0.0, vis_R5_fmb_pg: 0.0, vis_D1_height: 198.0, vis_D1_weight: 158.0, vis_D1_age: 29.0, vis_D1_av: 21.0, vis_D1_games: 82.0, vis_D1_gs: 37.0, vis_D1_int_pg: 0.0, vis_D1_pick6_pg: 0.0, vis_D1_pd_pg: 0.0975609756097561, vis_D1_ff_pg: 0.024390243902439, vis_D1_ftd_pg: 0.0, vis_D1_sk_pg: 0.1097560975609756, vis_D1_qbh_pg: 0.3414634146341463, vis_D1_sltk_pg: 1.5, vis_D1_astk_pg: 0.7073170731707317, vis_D1_tfl_pg: 0.2195121951219512, vis_D1_sfty_pg: 0.0, vis_D2_height: 193.0, vis_D2_weight: 136.0, vis_D2_age: 25.0, vis_D2_av: 0.0, vis_D2_games: 1.0, vis_D2_gs: 0.0, vis_D2_int_pg: 0.0, vis_D2_pick6_pg: 0.0, vis_D2_pd_pg: 0.0, vis_D2_ff_pg: 0.0, vis_D2_ftd_pg: 0.0, vis_D2_sk_pg: 1.0, vis_D2_qbh_pg: 2.0, vis_D2_sltk_pg: 7.0, vis_D2_astk_pg: 6.0, vis_D2_tfl_pg: 3.0, vis_D2_sfty_pg: 0.0, vis_D3_height: 185.0, vis_D3_weight: 137.0, vis_D3_age: 30.0, vis_D3_av: 49.0, vis_D3_games: 99.0, vis_D3_gs: 94.0, vis_D3_int_pg: 0.0, vis_D3_pick6_pg: 0.0, vis_D3_pd_pg: 0.0505050505050505, vis_D3_ff_pg: 0.0303030303030303, vis_D3_ftd_pg: 0.0, vis_D3_sk_pg: 0.2929292929292929, vis_D3_qbh_pg: 0.8080808080808081, vis_D3_sltk_pg: 2.686868686868687, vis_D3_astk_pg: 1.4646464646464648, vis_D3_tfl_pg: 0.7373737373737373, vis_D3_sfty_pg: 0.0, vis_D4_height: 198.0, vis_D4_weight: 136.0, vis_D4_age: 28.0, vis_D4_av: 53.0, vis_D4_games: 98.0, vis_D4_gs: 98.0, vis_D4_int_pg: 0.0, vis_D4_pick6_pg: 0.0, vis_D4_pd_pg: 0.1836734693877551, vis_D4_ff_pg: 0.1428571428571428, vis_D4_ftd_pg: 0.010204081632653, vis_D4_sk_pg: 0.7806122448979592, vis_D4_qbh_pg: 1.2653061224489797, vis_D4_sltk_pg: 2.6122448979591835, vis_D4_astk_pg: 0.6632653061224489, vis_D4_tfl_pg: 0.9285714285714286, vis_D4_sfty_pg: 0.0, vis_D5_height: 196.0, vis_D5_weight: 108.0, vis_D5_age: 29.0, vis_D5_av: 40.0, vis_D5_games: 98.0, vis_D5_gs: 82.0, vis_D5_int_pg: 0.0204081632653061, vis_D5_pick6_pg: 0.0, vis_D5_pd_pg: 0.1938775510204081, vis_D5_ff_pg: 0.0816326530612244, vis_D5_ftd_pg: 0.0, vis_D5_sk_pg: 0.2244897959183673, vis_D5_qbh_pg: 0.4489795918367347, vis_D5_sltk_pg: 3.071428571428572, vis_D5_astk_pg: 1.0612244897959184, vis_D5_tfl_pg: 0.4591836734693877, vis_D5_sfty_pg: 0.0, vis_D6_height: 190.0, vis_D6_weight: 108.0, vis_D6_age: 23.0, vis_D6_av: 0.0, vis_D6_games: 0.0, vis_D6_gs: 0.0, vis_D6_int_pg: 0.0, vis_D6_pick6_pg: 0.0, vis_D6_pd_pg: 0.0, vis_D6_ff_pg: 0.0, vis_D6_ftd_pg: 0.0, vis_D6_sk_pg: 0.0, vis_D6_qbh_pg: 0.0, vis_D6_sltk_pg: 0.0, vis_D6_astk_pg: 0.0, vis_D6_tfl_pg: 0.0, vis_D6_sfty_pg: 0.0, vis_D7_height: 188.0, vis_D7_weight: 109.0, vis_D7_age: 24.0, vis_D7_av: 4.0, vis_D7_games: 16.0, vis_D7_gs: 11.0, vis_D7_int_pg: 0.0, vis_D7_pick6_pg: 0.0, vis_D7_pd_pg: 0.125, vis_D7_ff_pg: 0.0, vis_D7_ftd_pg: 0.0, vis_D7_sk_pg: 0.0, vis_D7_qbh_pg: 0.0, vis_D7_sltk_pg: 3.875, vis_D7_astk_pg: 2.25, vis_D7_tfl_pg: 0.1875, vis_D7_sfty_pg: 0.0, vis_D8_height: 180.0, vis_D8_weight: 86.0, vis_D8_age: 28.0, vis_D8_av: 18.0, vis_D8_games: 64.0, vis_D8_gs: 33.0, vis_D8_int_pg: 0.109375, vis_D8_pick6_pg: 0.015625, vis_D8_pd_pg: 0.734375, vis_D8_ff_pg: 0.046875, vis_D8_ftd_pg: 0.0, vis_D8_sk_pg: 0.0, vis_D8_qbh_pg: 0.015625, vis_D8_sltk_pg: 3.046875, vis_D8_astk_pg: 0.5625, vis_D8_tfl_pg: 0.046875, vis_D8_sfty_pg: 0.0, vis_D9_height: 183.0, vis_D9_weight: 86.0, vis_D9_age: 23.0, vis_D9_av: 5.0, vis_D9_games: 16.0, vis_D9_gs: 16.0, vis_D9_int_pg: 0.1875, vis_D9_pick6_pg: 0.0, vis_D9_pd_pg: 1.625, vis_D9_ff_pg: 0.125, vis_D9_ftd_pg: 0.0, vis_D9_sk_pg: 0.0, vis_D9_qbh_pg: 0.0, vis_D9_sltk_pg: 5.0, vis_D9_astk_pg: 0.875, vis_D9_tfl_pg: 0.0625, vis_D9_sfty_pg: 0.0, vis_D10_height: 173.0, vis_D10_weight: 85.0, vis_D10_age: 31.0, vis_D10_av: 30.0, vis_D10_games: 117.0, vis_D10_gs: 67.0, vis_D10_int_pg: 0.1196581196581196, vis_D10_pick6_pg: 0.0085470085470085, vis_D10_pd_pg: 0.2991452991452991, vis_D10_ff_pg: 0.0512820512820512, vis_D10_ftd_pg: 0.0, vis_D10_sk_pg: 0.0427350427350427, vis_D10_qbh_pg: 0.1367521367521367, vis_D10_sltk_pg: 2.8034188034188032, vis_D10_astk_pg: 0.7435897435897436, vis_D10_tfl_pg: 0.1538461538461538, vis_D10_sfty_pg: 0.0, vis_D11_height: 183.0, vis_D11_weight: 92.0, vis_D11_age: 27.0, vis_D11_av: 27.0, vis_D11_games: 62.0, vis_D11_gs: 57.0, vis_D11_int_pg: 0.3548387096774194, vis_D11_pick6_pg: 0.032258064516129, vis_D11_pd_pg: 0.532258064516129, vis_D11_ff_pg: 0.1612903225806451, vis_D11_ftd_pg: 0.0, vis_D11_sk_pg: 0.0483870967741935, vis_D11_qbh_pg: 0.064516129032258, vis_D11_sltk_pg: 4.161290322580645, vis_D11_astk_pg: 1.532258064516129, vis_D11_tfl_pg: 0.2096774193548387, vis_D11_sfty_pg: 0.0, vis_K_age: 28.0, vis_K_av: 15.0, vis_K_games: 77.0, vis_K_fga_pg: 2.389610389610389, vis_K_fgm_pg: 1.9870129870129871, vis_K_fga_0-19_pg: 0.0259740259740259, vis_K_fgm_0-19_pg: 0.0259740259740259, vis_K_fga_20-29_pg: 0.4675324675324675, vis_K_fgm_20-29_pg: 0.4545454545454545, vis_K_fga_30-39_pg: 0.4675324675324675, vis_K_fgm_30-39_pg: 0.4415584415584415, vis_K_fga_40-49_pg: 0.8051948051948052, vis_K_fgm_40-49_pg: 0.6103896103896104, vis_K_fga_50+_pg: 0.2597402597402597, vis_K_fgm_50+_pg: 0.1298701298701298, vis_K_fglng_ps: 54.6, vis_K_xpa_pg: 2.415584415584416, vis_K_xpm_pg: 2.389610389610389, homeSeasonWinsComingIntoGame: 12.0, homeSeasonTiesComingIntoGame: 4.0, homeSeasonLossesComingIntoGame: 0.0, home_coach_games: 288.0, home_coach_wins: 187.0, home_coach_losses: 101.0, home_coach_ties: 0.0, home_coach_mean_SRS: 6.244444444444444, home_coach_mean_OSRS: 3.938888888888888, home_coach_mean_DSRS: 2.322222222222222, home_coach_playoff_games: 26.0, home_coach_playoff_wins: 18.0, home_coach_playoff_losses: 8.0, home_coach_mean_dihomeion_placement: 1.8888888888888888, home_qb_hand: 1.0, home_qb_height: 193.0, home_qb_weight: 102.0, home_qb_age: 36.0, home_qb_av: 179.0, home_qb_games: 201.0, home_qb_wins: 153.0, home_qb_losses: 46.0, home_qb_ties: 0.0, home_qb_cmp_pg: 23.0, home_qb_patt_pg: 36.23880597014925, home_qb_pyds_pg: 268.11442786069654, home_qb_ptd_pg: 1.9651741293532337, home_qb_int_pg: 0.7611940298507462, home_qb_p1D_pg: 12.651741293532336, home_qb_psucc_ps: 46.53076923076923, home_qb_plng_ps: 65.23076923076923, home_qb_sk_pg: 1.845771144278607, home_qb_skyds_pg: 11.611940298507465, home_qb_gwd_pg: 0.1840796019900497, home_qb_ratt_pg: 2.383084577114428, home_qb_ryds_pg: 4.253731343283582, home_qb_rtd_pg: 0.1044776119402985, home_qb_r1d_pg: 0.8208955223880597, home_qb_rsucc_ps: 36.16153846153846, home_qb_rlng_ps: 10.923076923076923, home_qb_fmb_pg: 0.4527363184079602, home_R1_height: 183.0, home_R1_weight: 112.0, home_R1_age: 27.0, home_R1_av: 13.0, home_R1_games: 40.0, home_R1_gs: 21.0, home_R1_tgts_pg: 0.975, home_R1_recs_pg: 0.575, home_R1_cyds_pg: 5.05, home_R1_ctd_pg: 0.0, home_R1_c1d_pg: 0.15, home_R1_csucc_ps: 18.1, home_R1_clng_ps: 14.666666666666666, home_R1_ratt_pg: 13.875, home_R1_ryds_pg: 63.05, home_R1_rtd_pg: 0.45, home_R1_r1d_pg: 1.925, home_R1_rsucc_ps: 42.2, home_R1_rlng_ps: 47.333333333333336, home_R1_fmb_pg: 0.275, home_R2_height: 190.0, home_R2_weight: 115.0, home_R2_age: 25.0, home_R2_av: 0.0, home_R2_games: 1.0, home_R2_gs: 0.0, home_R2_tgts_pg: 4.0, home_R2_recs_pg: 4.0, home_R2_cyds_pg: 62.0, home_R2_ctd_pg: 0.0, home_R2_c1d_pg: 0.0, home_R2_csucc_ps: 0.0, home_R2_clng_ps: 0.0, home_R2_ratt_pg: 3.0, home_R2_ryds_pg: 6.0, home_R2_rtd_pg: 1.0, home_R2_r1d_pg: 0.0, home_R2_rsucc_ps: 0.0, home_R2_rlng_ps: 0.0, home_R2_fmb_pg: 0.0, home_R3_height: 178.0, home_R3_weight: 89.0, home_R3_age: 27.0, home_R3_av: 11.0, home_R3_games: 53.0, home_R3_gs: 15.0, home_R3_tgts_pg: 4.283018867924528, home_R3_recs_pg: 2.830188679245283, home_R3_cyds_pg: 29.37735849056604, home_R3_ctd_pg: 0.1886792452830188, home_R3_c1d_pg: 0.7735849056603774, home_R3_csucc_ps: 90.825, home_R3_clng_ps: 45.75, home_R3_ratt_pg: 0.2641509433962264, home_R3_ryds_pg: 1.5471698113207548, home_R3_rtd_pg: 0.0566037735849056, home_R3_r1d_pg: 0.1132075471698113, home_R3_rsucc_ps: 75.0, home_R3_rlng_ps: 20.5, home_R3_fmb_pg: 0.1320754716981132, home_R4_height: 190.0, home_R4_weight: 95.0, home_R4_age: 22.0, home_R4_av: 0.0, home_R4_games: 0.0, home_R4_gs: 0.0, home_R4_tgts_pg: 0.0, home_R4_recs_pg: 0.0, home_R4_cyds_pg: 0.0, home_R4_ctd_pg: 0.0, home_R4_c1d_pg: 0.0, home_R4_csucc_ps: 0.0, home_R4_clng_ps: 0.0, home_R4_ratt_pg: 0.0, home_R4_ryds_pg: 0.0, home_R4_rtd_pg: 0.0, home_R4_r1d_pg: 0.0, home_R4_rsucc_ps: 0.0, home_R4_rlng_ps: 0.0, home_R4_fmb_pg: 0.0, home_R5_height: 193.0, home_R5_weight: 120.0, home_R5_age: 25.0, home_R5_av: 2.0, home_R5_games: 32.0, home_R5_gs: 18.0, home_R5_tgts_pg: 1.875, home_R5_recs_pg: 1.15625, home_R5_cyds_pg: 14.8125, home_R5_ctd_pg: 0.125, home_R5_c1d_pg: 0.53125, home_R5_csucc_ps: 50.26666666666667, home_R5_clng_ps: 34.666666666666664, home_R5_ratt_pg: 0.0, home_R5_ryds_pg: 0.0, home_R5_rtd_pg: 0.0, home_R5_r1d_pg: 0.0, home_R5_rsucc_ps: 0.0, home_R5_rlng_ps: 0.0, home_R5_fmb_pg: 0.0, home_D1_height: 188.0, home_D1_weight: 117.0, home_D1_age: 29.0, home_D1_av: 25.0, home_D1_games: 78.0, home_D1_gs: 48.0, home_D1_int_pg: 0.0641025641025641, home_D1_pick6_pg: 0.0128205128205128, home_D1_pd_pg: 0.2051282051282051, home_D1_ff_pg: 0.1282051282051282, home_D1_ftd_pg: 0.0, home_D1_sk_pg: 0.391025641025641, home_D1_qbh_pg: 0.717948717948718, home_D1_sltk_pg: 2.4743589743589745, home_D1_astk_pg: 1.9230769230769231, home_D1_tfl_pg: 0.4871794871794871, home_D1_sfty_pg: 0.0, home_D2_height: 185.0, home_D2_weight: 132.0, home_D2_age: 23.0, home_D2_av: 0.0, home_D2_games: 0.0, home_D2_gs: 0.0, home_D2_int_pg: 0.0, home_D2_pick6_pg: 0.0, home_D2_pd_pg: 0.0, home_D2_ff_pg: 0.0, home_D2_ftd_pg: 0.0, home_D2_sk_pg: 0.0, home_D2_qbh_pg: 0.0, home_D2_sltk_pg: 0.0, home_D2_astk_pg: 0.0, home_D2_tfl_pg: 0.0, home_D2_sfty_pg: 0.0, home_D3_height: 188.0, home_D3_weight: 156.0, home_D3_age: 23.0, home_D3_av: 0.0, home_D3_games: 1.0, home_D3_gs: 0.0, home_D3_int_pg: 0.0, home_D3_pick6_pg: 0.0, home_D3_pd_pg: 0.0, home_D3_ff_pg: 0.0, home_D3_ftd_pg: 0.0, home_D3_sk_pg: 2.0, home_D3_qbh_pg: 2.0, home_D3_sltk_pg: 5.0, home_D3_astk_pg: 10.0, home_D3_tfl_pg: 2.0, home_D3_sfty_pg: 0.0, home_D4_height: 196.0, home_D4_weight: 120.0, home_D4_age: 23.0, home_D4_av: 6.0, home_D4_games: 16.0, home_D4_gs: 14.0, home_D4_int_pg: 0.0, home_D4_pick6_pg: 0.0, home_D4_pd_pg: 0.25, home_D4_ff_pg: 0.25, home_D4_ftd_pg: 0.0625, home_D4_sk_pg: 1.09375, home_D4_qbh_pg: 2.1875, home_D4_sltk_pg: 3.9375, home_D4_astk_pg: 3.6875, home_D4_tfl_pg: 1.3125, home_D4_sfty_pg: 0.0, home_D5_height: 190.0, home_D5_weight: 115.0, home_D5_age: 24.0, home_D5_av: 0.0, home_D5_games: 0.0, home_D5_gs: 0.0, home_D5_int_pg: 0.0, home_D5_pick6_pg: 0.0, home_D5_pd_pg: 0.0, home_D5_ff_pg: 0.0, home_D5_ftd_pg: 0.0, home_D5_sk_pg: 0.0, home_D5_qbh_pg: 0.0, home_D5_sltk_pg: 0.0, home_D5_astk_pg: 0.0, home_D5_tfl_pg: 0.0, home_D5_sfty_pg: 0.0, home_D6_height: 190.0, home_D6_weight: 117.0, home_D6_age: 23.0, home_D6_av: 7.0, home_D6_games: 16.0, home_D6_gs: 15.0, home_D6_int_pg: 0.0, home_D6_pick6_pg: 0.0, home_D6_pd_pg: 0.375, home_D6_ff_pg: 0.0, home_D6_ftd_pg: 0.0625, home_D6_sk_pg: 0.3125, home_D6_qbh_pg: 0.9375, home_D6_sltk_pg: 6.25, home_D6_astk_pg: 3.5625, home_D6_tfl_pg: 1.0, home_D6_sfty_pg: 0.0, home_D7_height: 190.0, home_D7_weight: 113.0, home_D7_age: 26.0, home_D7_av: 14.0, home_D7_games: 41.0, home_D7_gs: 33.0, home_D7_int_pg: 0.073170731707317, home_D7_pick6_pg: 0.0, home_D7_pd_pg: 0.3414634146341463, home_D7_ff_pg: 0.1219512195121951, home_D7_ftd_pg: 0.0, home_D7_sk_pg: 0.048780487804878, home_D7_qbh_pg: 0.2195121951219512, home_D7_sltk_pg: 4.853658536585366, home_D7_astk_pg: 3.1707317073170733, home_D7_tfl_pg: 0.3902439024390244, home_D7_sfty_pg: 0.0, home_D8_height: 185.0, home_D8_weight: 94.0, home_D8_age: 27.0, home_D8_av: 23.0, home_D8_games: 66.0, home_D8_gs: 52.0, home_D8_int_pg: 0.3484848484848485, home_D8_pick6_pg: 0.0606060606060606, home_D8_pd_pg: 1.0757575757575757, home_D8_ff_pg: 0.0303030303030303, home_D8_ftd_pg: 0.0, home_D8_sk_pg: 0.0, home_D8_qbh_pg: 0.0, home_D8_sltk_pg: 3.272727272727273, home_D8_astk_pg: 0.4848484848484848, home_D8_tfl_pg: 0.0909090909090909, home_D8_sfty_pg: 0.0, home_D9_height: 180.0, home_D9_weight: 88.0, home_D9_age: 22.0, home_D9_av: 0.0, home_D9_games: 0.0, home_D9_gs: 0.0, home_D9_int_pg: 0.0, home_D9_pick6_pg: 0.0, home_D9_pd_pg: 0.0, home_D9_ff_pg: 0.0, home_D9_ftd_pg: 0.0, home_D9_sk_pg: 0.0, home_D9_qbh_pg: 0.0, home_D9_sltk_pg: 0.0, home_D9_astk_pg: 0.0, home_D9_tfl_pg: 0.0, home_D9_sfty_pg: 0.0, home_D10_height: 180.0, home_D10_weight: 90.0, home_D10_age: 30.0, home_D10_av: 22.0, home_D10_games: 106.0, home_D10_gs: 46.0, home_D10_int_pg: 0.0660377358490566, home_D10_pick6_pg: 0.0094339622641509, home_D10_pd_pg: 0.2735849056603773, home_D10_ff_pg: 0.0188679245283018, home_D10_ftd_pg: 0.0094339622641509, home_D10_sk_pg: 0.0188679245283018, home_D10_qbh_pg: 0.0471698113207547, home_D10_sltk_pg: 2.69811320754717, home_D10_astk_pg: 0.8113207547169812, home_D10_tfl_pg: 0.0471698113207547, home_D10_sfty_pg: 0.0, home_D11_height: 183.0, home_D11_weight: 92.0, home_D11_age: 22.0, home_D11_av: 0.0, home_D11_games: 0.0, home_D11_gs: 0.0, home_D11_int_pg: 0.0, home_D11_pick6_pg: 0.0, home_D11_pd_pg: 0.0, home_D11_ff_pg: 0.0, home_D11_ftd_pg: 0.0, home_D11_sk_pg: 0.0, home_D11_qbh_pg: 0.0, home_D11_sltk_pg: 0.0, home_D11_astk_pg: 0.0, home_D11_tfl_pg: 0.0, home_D11_sfty_pg: 0.0, home_K_age: 29.0, home_K_av: 20.0, home_K_games: 116.0, home_K_fga_pg: 2.2155172413793105, home_K_fgm_pg: 1.896551724137931, home_K_fga_0-19_pg: 0.0086206896551724, home_K_fgm_0-19_pg: 0.0086206896551724, home_K_fga_20-29_pg: 0.603448275862069, home_K_fgm_20-29_pg: 0.5689655172413793, home_K_fga_30-39_pg: 0.7068965517241379, home_K_fgm_30-39_pg: 0.6206896551724138, home_K_fga_40-49_pg: 0.5, home_K_fgm_40-49_pg: 0.3534482758620689, home_K_fga_50+_pg: 0.0948275862068965, home_K_fgm_50+_pg: 0.0689655172413793, home_K_fglng_ps: 49.42857142857143, home_K_xpa_pg: 3.7413793103448274, home_K_xpm_pg: 3.7327586206896552\n",
            "correct prediction\n",
            "Predicted: Home Win (100.00%), True: Home Win\n"
          ]
        }
      ],
      "source": [
        "i = 550  # value within test dataset size 1047 im pretty sure\n",
        "visualize_input(i, predictions[i], test_labels.iloc[i])\n",
        "plt.show()\n",
        "\n",
        "feature_info(i, predictions[i], test_labels.iloc[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "## Use the trained model\n",
        "\n",
        "Finally, use the trained model to make a prediction about a single game."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dict_from_features(feature_names, feature_values):\n",
        "    return dict(zip(feature_names, feature_values))\n",
        "\n",
        "# Example usage\n",
        "feature_names = column_names[1:]\n",
        "feature_values = [22,2023,0,11,5,2024,1830,0,0,14,6,0,386.0,247.0,138.0,1.0,4.720833333333333,2.9250000000000003,1.7874999999999996,38.0,22.0,16.0,1.8333333333333333,1.0,188.0,102.0,27.0,94.0,94.0,75.0,19.0,0.0,27.97872340425532,41.97872340425532,334.4148936170213,2.6595744680851063,0.6595744680851063,14.946808510638299,53.050000000000004,73.33333333333333,1.7659574468085106,11.702127659574469,0.19148936170212766,4.4361702127659575,23.28723404255319,0.24468085106382978,1.3936170212765957,45.28333333333333,22.333333333333332,0.44680851063829785,178.0,97.0,27.0,7.0,20.0,14.0,3.55,3.25,23.5,0.1,0.5,135.7,50.0,22.15,104.35,0.8,2.25,105.7,70.0,0.25,188.0,97.0,27.0,5.0,60.0,9.0,2.1333333333333333,1.1333333333333333,17.1,0.11666666666666667,0.5,53.08,27.4,0.0,0.0,0.016666666666666666,0.0,0.0,0.0,0.016666666666666666,193.0,93.0,27.0,26.0,83.0,54.0,4.819277108433735,2.4698795180722892,42.33734939759036,0.2289156626506024,1.5421686746987953,86.42,86.2,0.10843373493975904,0.5783132530120482,0.0,0.03614457831325301,35.0,7.2,0.012048192771084338,188.0,92.0,27.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,196.0,113.0,27.0,100.0,162.0,155.0,8.950617283950617,6.5246913580246915,80.74074074074075,0.5740740740740741,3.8950617283950617,111.88000000000002,71.6,0.06172839506172839,0.12962962962962962,0.012345679012345678,0.037037037037037035,45.0,1.3,0.08641975308641975,193.0,119.0,27.0,7.0,20.0,20.0,0.0,0.0,0.55,0.0,0.0,0.875,1.5,2.65,1.9,0.9,0.0,188.0,116.0,27.0,5.0,52.0,7.0,0.0,0.0,0.07692307692307693,0.07692307692307693,0.0,0.3269230769230769,0.8269230769230769,1.4423076923076923,1.2884615384615385,0.3076923076923077,0.0,198.0,140.0,27.0,71.0,122.0,99.0,0.01639344262295082,0.00819672131147541,0.39344262295081966,0.10655737704918032,0.0,0.639344262295082,1.5491803278688525,1.680327868852459,0.8032786885245902,0.6721311475409836,0.00819672131147541,193.0,149.0,27.0,18.0,128.0,20.0,0.0,0.0,0.0390625,0.015625,0.0,0.015625,0.1328125,0.9765625,0.765625,0.0859375,0.0,190.0,113.0,27.0,4.0,20.0,8.0,0.0,0.0,0.0,0.0,0.0,0.1,0.15,1.15,0.9,0.2,0.0,188.0,106.0,27.0,14.0,48.0,28.0,0.041666666666666664,0.0,0.16666666666666666,0.041666666666666664,0.0,0.20833333333333334,0.3541666666666667,5.604166666666667,2.5,0.5416666666666666,0.0,180.0,107.0,27.0,13.0,39.0,34.0,0.07692307692307693,0.0,0.2564102564102564,0.02564102564102564,0.05128205128205128,0.05128205128205128,0.2564102564102564,6.538461538461538,4.256410256410256,0.5897435897435898,0.0,185.0,87.0,27.0,14.0,50.0,47.0,0.22,0.0,0.9,0.1,0.0,0.17,0.3,5.44,2.02,0.46,0.0,180.0,87.0,27.0,3.0,14.0,14.0,0.0,0.0,1.5,0.5,0.0,0.2857142857142857,0.6428571428571429,7.357142857142857,2.857142857142857,0.5,0.0,185.0,93.0,27.0,23.0,80.0,76.0,0.1,0.0125,0.5125,0.0375,0.0,0.0875,0.225,4.975,1.75,0.2625,0.0,178.0,92.0,27.0,14.0,65.0,26.0,0.16923076923076924,0.046153846153846156,0.49230769230769234,0.015384615384615385,0.015384615384615385,0.046153846153846156,0.06153846153846154,2.7846153846153845,1.353846153846154,0.15384615384615385,0.0,27.0,22.0,105.0,2.380952380952381,2.1142857142857143,0.01904761904761905,0.01904761904761905,0.45714285714285713,0.45714285714285713,0.6190476190476191,0.580952380952381,0.5333333333333333,0.44761904761904764,0.38095238095238093,0.2571428571428571,56.5,3.723809523809524,3.5238095238095237,14,5,0,98.0,52.0,46.0,0.0,2.516666666666667,1.45,1.05,9.0,6.0,3.0,2.6666666666666665,1.0,185.0,99.0,27.0,6.0,12.0,7.0,1.0,0.0,36.083333333333336,52.416666666666664,490.0833333333333,3.6666666666666665,1.25,7.75,50.3,54.0,3.0833333333333335,19.25,0.16666666666666666,5.5,17.666666666666668,0.5833333333333334,0.6666666666666666,27.3,13.0,0.16666666666666666,180.0,92.0,27.0,63.0,79.0,72.0,8.405063291139241,6.772151898734177,57.43037974683544,0.3924050632911392,2.6455696202531644,74.95,46.333333333333336,17.189873417721518,81.9620253164557,0.7341772151898734,3.0253164556962027,62.76666666666666,56.666666666666664,0.13924050632911392,188.0,106.0,27.0,22.0,166.0,121.0,2.2048192771084336,1.6626506024096386,15.674698795180722,0.10240963855421686,0.6927710843373494,75.57000000000001,40.5,0.4036144578313253,1.4216867469879517,0.030120481927710843,0.18674698795180722,52.5,8.8,0.04819277108433735,183.0,90.0,27.0,24.0,52.0,50.0,8.423076923076923,5.576923076923077,82.21153846153847,0.5,2.673076923076923,96.96666666666668,71.33333333333333,0.25,2.25,0.038461538461538464,0.07692307692307693,68.89999999999999,20.666666666666668,0.07692307692307693,183.0,97.0,27.0,35.0,60.0,52.0,8.233333333333333,5.433333333333334,78.78333333333333,0.35,2.4833333333333334,88.725,91.25,3.4833333333333334,21.45,0.3333333333333333,0.75,97.975,55.25,0.18333333333333332,193.0,113.0,27.0,46.0,91.0,83.0,7.549450549450549,5.395604395604396,73.9010989010989,0.42857142857142855,2.912087912087912,86.43333333333334,68.33333333333333,0.14285714285714285,0.8241758241758241,0.0,0.03296703296703297,73.33333333333333,8.333333333333334,0.04395604395604396,196.0,119.0,27.0,19.0,28.0,27.0,0.0,0.0,0.32142857142857145,0.21428571428571427,0.03571428571428571,0.5892857142857143,1.1428571428571428,2.607142857142857,1.2857142857142858,0.75,0.0,188.0,138.0,27.0,52.0,119.0,104.0,0.0,0.0,0.07563025210084033,0.03361344537815126,0.008403361344537815,0.39915966386554624,0.6890756302521008,1.8739495798319328,1.4789915966386555,0.4957983193277311,0.0,193.0,120.0,27.0,43.0,60.0,58.0,0.016666666666666666,0.0,0.16666666666666666,0.2,0.0,1.0583333333333333,2.683333333333333,3.033333333333333,1.1833333333333333,1.3833333333333333,0.0,201.0,131.0,27.0,42.0,113.0,94.0,0.0,0.0,0.05309734513274336,0.035398230088495575,0.0,0.3584070796460177,0.8849557522123894,1.7433628318584071,1.2123893805309736,0.4247787610619469,0.0,183.0,104.0,27.0,23.0,56.0,48.0,0.08928571428571429,0.017857142857142856,0.30357142857142855,0.05357142857142857,0.017857142857142856,0.0625,0.17857142857142858,6.0,3.1964285714285716,0.39285714285714285,0.0,190.0,104.0,27.0,60.0,90.0,90.0,0.1111111111111111,0.011111111111111112,0.5666666666666667,0.13333333333333333,0.0,0.1,0.3111111111111111,6.088888888888889,3.3555555555555556,0.43333333333333335,0.0,183.0,86.0,27.0,3.0,29.0,7.0,0.06896551724137931,0.0,0.4482758620689655,0.034482758620689655,0.0,0.0,0.0,2.8275862068965516,0.8275862068965517,0.034482758620689655,0.0,185.0,88.0,27.0,20.0,87.0,73.0,0.11494252873563218,0.011494252873563218,0.8735632183908046,0.034482758620689655,0.0,0.011494252873563218,0.034482758620689655,3.9080459770114944,1.3103448275862069,0.09195402298850575,0.0,185.0,96.0,27.0,65.0,164.0,156.0,0.20121951219512196,0.018292682926829267,0.4268292682926829,0.018292682926829267,0.0,0.021341463414634148,0.042682926829268296,3.152439024390244,1.2073170731707317,0.11585365853658537,0.0,180.0,91.0,27.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,178.0,90.0,27.0,6.0,33.0,18.0,0.18181818181818182,0.0,0.5757575757575758,0.0,0.0,0.030303030303030304,0.06060606060606061,4.363636363636363,1.9090909090909092,0.24242424242424243,0.0,27.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n"
      ],
      "metadata": {
        "id": "cNelw1nMBSwo"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624bf6f5-2efb-46b6-e172-30a011a028d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(701,)\n",
            "seasonWeek             22.0\n",
            "seasonYear           2023.0\n",
            "weekday                 0.0\n",
            "monthDay               11.0\n",
            "month                   5.0\n",
            "                      ...  \n",
            "home_K_fga_50+_pg       0.0\n",
            "home_K_fgm_50+_pg       0.0\n",
            "home_K_fglng_ps         0.0\n",
            "home_K_xpa_pg           0.0\n",
            "home_K_xpm_pg           0.0\n",
            "Length: 701, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Grab an image from the test dataset.\n",
        "# singleGame = test_features.iloc[500]\n",
        "\n",
        "# print(singleGame.shape)\n",
        "# print(singleGame)\n",
        "\n",
        "\n",
        "singleGame_data = create_dict_from_features(feature_names, feature_values)\n",
        "singleGame = pd.Series(singleGame_data)\n",
        "\n",
        "print(singleGame.shape)\n",
        "print(singleGame)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "lDFh5yF_CaXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48187b3-ecba-470c-d5a9-f306bbb9372d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 701)\n"
          ]
        }
      ],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "singleGame = (np.expand_dims(singleGame,0))\n",
        "\n",
        "print(singleGame.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Now predict the correct label for this game:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39202291-1898-4f1e-b675-6831263d840b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n",
            "[[3.9240393e-07 9.2317113e-15 9.9999964e-01]]\n"
          ]
        }
      ],
      "source": [
        "predictions_single = probability_model.predict(singleGame)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`tf.keras.Model.predict` returns a list of lists—one list for each game input in the batch of data. Grab the predictions for our (only) game in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2tRmdq_8CaXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa387b9-21e1-4f9a-c871-ba051c33a731"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 500\n",
        "visualize_input(i, predictions[i], test_labels.iloc[i])\n",
        "plt.show()\n",
        "\n",
        "feature_info(i, predictions[i], test_labels.iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "Cn8pAqP2qF34",
        "outputId": "fdbb60ec-0022-4c43-8d80-ce3cc03cb08d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "seasonWeek: 2.0, seasonYear: 2013.0, weekday: 4.0, monthDay: 12.0, month: 0.0, year: 2013.0, militaryTime: 2029.0, stadium: 3.0, field: 6.0, visSeasonWinsComingIntoGame: 1.0, visSeasonTiesComingIntoGame: 1.0, visSeasonLossesComingIntoGame: 0.0, vis_coach_games: 64.0, vis_coach_wins: 34.0, vis_coach_losses: 30.0, vis_coach_ties: 0.0, vis_coach_mean_SRS: 2.525, vis_coach_mean_OSRS: -0.1499999999999999, vis_coach_mean_DSRS: 2.625, vis_coach_playoff_games: 6.0, vis_coach_playoff_wins: 4.0, vis_coach_playoff_losses: 2.0, vis_coach_mean_division_placement: 2.25, vis_qb_hand: 1.0, vis_qb_height: 190.0, vis_qb_weight: 100.0, vis_qb_age: 23.0, vis_qb_av: 0.0, vis_qb_games: 0.0, vis_qb_wins: 0.0, vis_qb_losses: 0.0, vis_qb_ties: 0.0, vis_qb_cmp_pg: 0.0, vis_qb_patt_pg: 0.0, vis_qb_pyds_pg: 0.0, vis_qb_ptd_pg: 0.0, vis_qb_int_pg: 0.0, vis_qb_p1D_pg: 0.0, vis_qb_psucc_ps: 0.0, vis_qb_plng_ps: 0.0, vis_qb_sk_pg: 0.0, vis_qb_skyds_pg: 0.0, vis_qb_gwd_pg: 0.0, vis_qb_ratt_pg: 0.0, vis_qb_ryds_pg: 0.0, vis_qb_rtd_pg: 0.0, vis_qb_r1d_pg: 0.0, vis_qb_rsucc_ps: 0.0, vis_qb_rlng_ps: 0.0, vis_qb_fmb_pg: 0.0, vis_R1_height: 178.0, vis_R1_weight: 92.0, vis_R1_age: 25.0, vis_R1_av: 3.0, vis_R1_games: 16.0, vis_R1_gs: 2.0, vis_R1_tgts_pg: 2.625, vis_R1_recs_pg: 1.375, vis_R1_cyds_pg: 11.375, vis_R1_ctd_pg: 0.0, vis_R1_c1d_pg: 0.5625, vis_R1_csucc_ps: 16.65, vis_R1_clng_ps: 11.5, vis_R1_ratt_pg: 8.4375, vis_R1_ryds_pg: 30.4375, vis_R1_rtd_pg: 0.25, vis_R1_r1d_pg: 1.5625, vis_R1_rsucc_ps: 23.2, vis_R1_rlng_ps: 12.0, vis_R1_fmb_pg: 0.125, vis_R2_height: 180.0, vis_R2_weight: 85.0, vis_R2_age: 27.0, vis_R2_av: 2.0, vis_R2_games: 26.0, vis_R2_gs: 2.0, vis_R2_tgts_pg: 1.4230769230769231, vis_R2_recs_pg: 0.7307692307692307, vis_R2_cyds_pg: 10.0, vis_R2_ctd_pg: 0.0, vis_R2_c1d_pg: 0.5, vis_R2_csucc_ps: 22.75, vis_R2_clng_ps: 26.5, vis_R2_ratt_pg: 0.0769230769230769, vis_R2_ryds_pg: 0.6153846153846154, vis_R2_rtd_pg: 0.0, vis_R2_r1d_pg: 0.0769230769230769, vis_R2_rsucc_ps: 50.0, vis_R2_rlng_ps: 8.0, vis_R2_fmb_pg: 0.0, vis_R3_height: 180.0, vis_R3_weight: 87.0, vis_R3_age: 29.0, vis_R3_av: 50.0, vis_R3_games: 99.0, vis_R3_gs: 83.0, vis_R3_tgts_pg: 7.212121212121212, vis_R3_recs_pg: 3.878787878787879, vis_R3_cyds_pg: 59.81818181818182, vis_R3_ctd_pg: 0.404040404040404, vis_R3_c1d_pg: 2.898989898989899, vis_R3_csucc_ps: 66.58571428571429, vis_R3_clng_ps: 75.71428571428571, vis_R3_ratt_pg: 0.1818181818181818, vis_R3_ryds_pg: 0.9696969696969696, vis_R3_rtd_pg: 0.0, vis_R3_r1d_pg: 0.0505050505050505, vis_R3_rsucc_ps: 55.71428571428572, vis_R3_rlng_ps: 11.714285714285714, vis_R3_fmb_pg: 0.1717171717171717, vis_R4_height: 193.0, vis_R4_weight: 97.0, vis_R4_age: 22.0, vis_R4_av: 2.0, vis_R4_games: 11.0, vis_R4_gs: 8.0, vis_R4_tgts_pg: 4.2727272727272725, vis_R4_recs_pg: 1.9090909090909087, vis_R4_cyds_pg: 22.90909090909091, vis_R4_ctd_pg: 0.2727272727272727, vis_R4_c1d_pg: 1.5454545454545454, vis_R4_csucc_ps: 42.6, vis_R4_clng_ps: 33.0, vis_R4_ratt_pg: 0.0, vis_R4_ryds_pg: 0.0, vis_R4_rtd_pg: 0.0909090909090909, vis_R4_r1d_pg: 0.0, vis_R4_rsucc_ps: 0.0, vis_R4_rlng_ps: 0.0, vis_R4_fmb_pg: 0.0, vis_R5_height: 193.0, vis_R5_weight: 108.0, vis_R5_age: 30.0, vis_R5_av: 39.0, vis_R5_games: 93.0, vis_R5_gs: 80.0, vis_R5_tgts_pg: 7.741935483870968, vis_R5_recs_pg: 4.78494623655914, vis_R5_cyds_pg: 52.97849462365591, vis_R5_ctd_pg: 0.2580645161290322, vis_R5_c1d_pg: 2.6666666666666665, vis_R5_csucc_ps: 48.0625, vis_R5_clng_ps: 34.0, vis_R5_ratt_pg: 0.010752688172043, vis_R5_ryds_pg: 0.075268817204301, vis_R5_rtd_pg: 0.0, vis_R5_r1d_pg: 0.0, vis_R5_rsucc_ps: 0.0, vis_R5_rlng_ps: 0.875, vis_R5_fmb_pg: 0.075268817204301, vis_D1_height: 190.0, vis_D1_weight: 131.0, vis_D1_age: 23.0, vis_D1_av: 0.0, vis_D1_games: 0.0, vis_D1_gs: 0.0, vis_D1_int_pg: 0.0, vis_D1_pick6_pg: 0.0, vis_D1_pd_pg: 0.0, vis_D1_ff_pg: 0.0, vis_D1_ftd_pg: 0.0, vis_D1_sk_pg: 0.0, vis_D1_qbh_pg: 0.0, vis_D1_sltk_pg: 0.0, vis_D1_astk_pg: 0.0, vis_D1_tfl_pg: 0.0, vis_D1_sfty_pg: 0.0, vis_D2_height: 190.0, vis_D2_weight: 158.0, vis_D2_age: 25.0, vis_D2_av: 0.0, vis_D2_games: 5.0, vis_D2_gs: 0.0, vis_D2_int_pg: 0.0, vis_D2_pick6_pg: 0.0, vis_D2_pd_pg: 0.0, vis_D2_ff_pg: 0.0, vis_D2_ftd_pg: 0.0, vis_D2_sk_pg: 0.0, vis_D2_qbh_pg: 0.0, vis_D2_sltk_pg: 0.8, vis_D2_astk_pg: 0.4, vis_D2_tfl_pg: 0.2, vis_D2_sfty_pg: 0.0, vis_D3_height: 193.0, vis_D3_weight: 142.0, vis_D3_age: 24.0, vis_D3_av: 17.0, vis_D3_games: 32.0, vis_D3_gs: 31.0, vis_D3_int_pg: 0.0, vis_D3_pick6_pg: 0.0, vis_D3_pd_pg: 0.21875, vis_D3_ff_pg: 0.125, vis_D3_ftd_pg: 0.03125, vis_D3_sk_pg: 0.28125, vis_D3_qbh_pg: 0.59375, vis_D3_sltk_pg: 2.25, vis_D3_astk_pg: 1.5, vis_D3_tfl_pg: 0.65625, vis_D3_sfty_pg: 0.03125, vis_D4_height: 190.0, vis_D4_weight: 122.0, vis_D4_age: 29.0, vis_D4_av: 5.0, vis_D4_games: 29.0, vis_D4_gs: 7.0, vis_D4_int_pg: 0.0, vis_D4_pick6_pg: 0.0, vis_D4_pd_pg: 0.0344827586206896, vis_D4_ff_pg: 0.0689655172413793, vis_D4_ftd_pg: 0.0, vis_D4_sk_pg: 0.1206896551724138, vis_D4_qbh_pg: 0.2068965517241379, vis_D4_sltk_pg: 1.2413793103448276, vis_D4_astk_pg: 0.6551724137931034, vis_D4_tfl_pg: 0.1724137931034483, vis_D4_sfty_pg: 0.0, vis_D5_height: 193.0, vis_D5_weight: 120.0, vis_D5_age: 33.0, vis_D5_av: 58.0, vis_D5_games: 145.0, vis_D5_gs: 113.0, vis_D5_int_pg: 0.0206896551724137, vis_D5_pick6_pg: 0.0, vis_D5_pd_pg: 0.1655172413793103, vis_D5_ff_pg: 0.1310344827586207, vis_D5_ftd_pg: 0.0068965517241379, vis_D5_sk_pg: 0.3137931034482759, vis_D5_qbh_pg: 0.4068965517241379, vis_D5_sltk_pg: 2.8482758620689657, vis_D5_astk_pg: 0.8137931034482758, vis_D5_tfl_pg: 0.4689655172413793, vis_D5_sfty_pg: 0.0, vis_D6_height: 188.0, vis_D6_weight: 112.0, vis_D6_age: 24.0, vis_D6_av: 3.0, vis_D6_games: 16.0, vis_D6_gs: 3.0, vis_D6_int_pg: 0.0, vis_D6_pick6_pg: 0.0, vis_D6_pd_pg: 0.0, vis_D6_ff_pg: 0.0, vis_D6_ftd_pg: 0.0, vis_D6_sk_pg: 0.0, vis_D6_qbh_pg: 0.0625, vis_D6_sltk_pg: 2.125, vis_D6_astk_pg: 0.5625, vis_D6_tfl_pg: 0.0625, vis_D6_sfty_pg: 0.0, vis_D7_height: 188.0, vis_D7_weight: 113.0, vis_D7_age: 29.0, vis_D7_av: 58.0, vis_D7_games: 97.0, vis_D7_gs: 90.0, vis_D7_int_pg: 0.0721649484536082, vis_D7_pick6_pg: 0.0103092783505154, vis_D7_pd_pg: 0.2371134020618556, vis_D7_ff_pg: 0.0618556701030927, vis_D7_ftd_pg: 0.0, vis_D7_sk_pg: 0.2525773195876288, vis_D7_qbh_pg: 0.5051546391752577, vis_D7_sltk_pg: 4.948453608247423, vis_D7_astk_pg: 2.1649484536082477, vis_D7_tfl_pg: 0.3402061855670103, vis_D7_sfty_pg: 0.0, vis_D8_height: 183.0, vis_D8_weight: 91.0, vis_D8_age: 22.0, vis_D8_av: 0.0, vis_D8_games: 0.0, vis_D8_gs: 0.0, vis_D8_int_pg: 0.0, vis_D8_pick6_pg: 0.0, vis_D8_pd_pg: 0.0, vis_D8_ff_pg: 0.0, vis_D8_ftd_pg: 0.0, vis_D8_sk_pg: 0.0, vis_D8_qbh_pg: 0.0, vis_D8_sltk_pg: 0.0, vis_D8_astk_pg: 0.0, vis_D8_tfl_pg: 0.0, vis_D8_sfty_pg: 0.0, vis_D9_height: 188.0, vis_D9_weight: 95.0, vis_D9_age: 29.0, vis_D9_av: 54.0, vis_D9_games: 121.0, vis_D9_gs: 95.0, vis_D9_int_pg: 0.2231404958677686, vis_D9_pick6_pg: 0.024793388429752, vis_D9_pd_pg: 0.7272727272727273, vis_D9_ff_pg: 0.0165289256198347, vis_D9_ftd_pg: 0.0082644628099173, vis_D9_sk_pg: 0.0, vis_D9_qbh_pg: 0.0, vis_D9_sltk_pg: 2.4049586776859506, vis_D9_astk_pg: 0.2809917355371901, vis_D9_tfl_pg: 0.0082644628099173, vis_D9_sfty_pg: 0.0, vis_D10_height: 185.0, vis_D10_weight: 96.0, vis_D10_age: 31.0, vis_D10_av: 40.0, vis_D10_games: 103.0, vis_D10_gs: 101.0, vis_D10_int_pg: 0.145631067961165, vis_D10_pick6_pg: 0.029126213592233, vis_D10_pd_pg: 0.3980582524271844, vis_D10_ff_pg: 0.029126213592233, vis_D10_ftd_pg: 0.0, vis_D10_sk_pg: 0.058252427184466, vis_D10_qbh_pg: 0.116504854368932, vis_D10_sltk_pg: 4.466019417475728, vis_D10_astk_pg: 1.3689320388349515, vis_D10_tfl_pg: 0.1844660194174757, vis_D10_sfty_pg: 0.0, vis_D11_height: 185.0, vis_D11_weight: 95.0, vis_D11_age: 25.0, vis_D11_av: 1.0, vis_D11_games: 7.0, vis_D11_gs: 1.0, vis_D11_int_pg: 0.0, vis_D11_pick6_pg: 0.0, vis_D11_pd_pg: 0.0, vis_D11_ff_pg: 0.0, vis_D11_ftd_pg: 0.0, vis_D11_sk_pg: 0.1428571428571428, vis_D11_qbh_pg: 0.1428571428571428, vis_D11_sltk_pg: 1.1428571428571428, vis_D11_astk_pg: 0.5714285714285714, vis_D11_tfl_pg: 0.1428571428571428, vis_D11_sfty_pg: 0.0, vis_K_age: 29.0, vis_K_av: 15.0, vis_K_games: 98.0, vis_K_fga_pg: 1.8265306122448977, vis_K_fgm_pg: 1.4285714285714286, vis_K_fga_0-19_pg: 0.0204081632653061, vis_K_fgm_0-19_pg: 0.0204081632653061, vis_K_fga_20-29_pg: 0.4591836734693877, vis_K_fgm_20-29_pg: 0.3979591836734694, vis_K_fga_30-39_pg: 0.5510204081632653, vis_K_fgm_30-39_pg: 0.4795918367346938, vis_K_fga_40-49_pg: 0.5204081632653061, vis_K_fgm_40-49_pg: 0.3673469387755102, vis_K_fga_50+_pg: 0.2448979591836734, vis_K_fgm_50+_pg: 0.1326530612244898, vis_K_fglng_ps: 52.833333333333336, vis_K_xpa_pg: 2.5816326530612246, vis_K_xpm_pg: 2.5816326530612246, homeSeasonWinsComingIntoGame: 2.0, homeSeasonTiesComingIntoGame: 0.0, homeSeasonLossesComingIntoGame: 0.0, home_coach_games: 288.0, home_coach_wins: 187.0, home_coach_losses: 101.0, home_coach_ties: 0.0, home_coach_mean_SRS: 6.244444444444444, home_coach_mean_OSRS: 3.938888888888888, home_coach_mean_DSRS: 2.322222222222222, home_coach_playoff_games: 26.0, home_coach_playoff_wins: 18.0, home_coach_playoff_losses: 8.0, home_coach_mean_dihomeion_placement: 1.8888888888888888, home_qb_hand: 1.0, home_qb_height: 193.0, home_qb_weight: 102.0, home_qb_age: 36.0, home_qb_av: 179.0, home_qb_games: 201.0, home_qb_wins: 153.0, home_qb_losses: 46.0, home_qb_ties: 0.0, home_qb_cmp_pg: 21.791044776119403, home_qb_patt_pg: 34.3134328358209, home_qb_pyds_pg: 253.9452736318408, home_qb_ptd_pg: 1.8805970149253728, home_qb_int_pg: 0.7263681592039801, home_qb_p1D_pg: 12.651741293532336, home_qb_psucc_ps: 46.53076923076923, home_qb_plng_ps: 65.23076923076923, home_qb_sk_pg: 1.7213930348258706, home_qb_skyds_pg: 10.81592039800995, home_qb_gwd_pg: 0.1840796019900497, home_qb_ratt_pg: 2.298507462686567, home_qb_ryds_pg: 4.119402985074627, home_qb_rtd_pg: 0.0845771144278607, home_qb_r1d_pg: 0.8208955223880597, home_qb_rsucc_ps: 36.16153846153846, home_qb_rlng_ps: 10.923076923076923, home_qb_fmb_pg: 0.4477611940298507, home_R1_height: 190.0, home_R1_weight: 115.0, home_R1_age: 25.0, home_R1_av: 0.0, home_R1_games: 1.0, home_R1_gs: 0.0, home_R1_tgts_pg: 0.0, home_R1_recs_pg: 0.0, home_R1_cyds_pg: 0.0, home_R1_ctd_pg: 0.0, home_R1_c1d_pg: 0.0, home_R1_csucc_ps: 0.0, home_R1_clng_ps: 0.0, home_R1_ratt_pg: 0.0, home_R1_ryds_pg: 0.0, home_R1_rtd_pg: 0.0, home_R1_r1d_pg: 0.0, home_R1_rsucc_ps: 0.0, home_R1_rlng_ps: 0.0, home_R1_fmb_pg: 0.0, home_R2_height: 180.0, home_R2_weight: 99.0, home_R2_age: 24.0, home_R2_av: 15.0, home_R2_games: 35.0, home_R2_gs: 15.0, home_R2_tgts_pg: 0.6285714285714286, home_R2_recs_pg: 0.3142857142857143, home_R2_cyds_pg: 2.3142857142857145, home_R2_ctd_pg: 0.0, home_R2_c1d_pg: 0.0857142857142857, home_R2_csucc_ps: 99.3, home_R2_clng_ps: 22.5, home_R2_ratt_pg: 12.085714285714284, home_R2_ryds_pg: 54.94285714285714, home_R2_rtd_pg: 0.4, home_R2_r1d_pg: 3.2, home_R2_rsucc_ps: 106.4, home_R2_rlng_ps: 54.0, home_R2_fmb_pg: 0.2285714285714285, home_R3_height: 183.0, home_R3_weight: 88.0, home_R3_age: 25.0, home_R3_av: 0.0, home_R3_games: 0.0, home_R3_gs: 0.0, home_R3_tgts_pg: 0.0, home_R3_recs_pg: 0.0, home_R3_cyds_pg: 0.0, home_R3_ctd_pg: 0.0, home_R3_c1d_pg: 0.0, home_R3_csucc_ps: 0.0, home_R3_clng_ps: 0.0, home_R3_ratt_pg: 0.0, home_R3_ryds_pg: 0.0, home_R3_rtd_pg: 0.0, home_R3_r1d_pg: 0.0, home_R3_rsucc_ps: 0.0, home_R3_rlng_ps: 0.0, home_R3_fmb_pg: 0.0, home_R4_height: 178.0, home_R4_weight: 89.0, home_R4_age: 27.0, home_R4_av: 11.0, home_R4_games: 53.0, home_R4_gs: 15.0, home_R4_tgts_pg: 2.490566037735849, home_R4_recs_pg: 1.6037735849056605, home_R4_cyds_pg: 16.37735849056604, home_R4_ctd_pg: 0.1509433962264151, home_R4_c1d_pg: 0.7735849056603774, home_R4_csucc_ps: 90.825, home_R4_clng_ps: 45.75, home_R4_ratt_pg: 0.2641509433962264, home_R4_ryds_pg: 1.5471698113207548, home_R4_rtd_pg: 0.0, home_R4_r1d_pg: 0.1132075471698113, home_R4_rsucc_ps: 75.0, home_R4_rlng_ps: 20.5, home_R4_fmb_pg: 0.1132075471698113, home_R5_height: 193.0, home_R5_weight: 120.0, home_R5_age: 25.0, home_R5_av: 2.0, home_R5_games: 32.0, home_R5_gs: 18.0, home_R5_tgts_pg: 1.375, home_R5_recs_pg: 0.8125, home_R5_cyds_pg: 10.71875, home_R5_ctd_pg: 0.09375, home_R5_c1d_pg: 0.53125, home_R5_csucc_ps: 50.26666666666667, home_R5_clng_ps: 34.666666666666664, home_R5_ratt_pg: 0.0, home_R5_ryds_pg: 0.0, home_R5_rtd_pg: 0.0, home_R5_r1d_pg: 0.0, home_R5_rsucc_ps: 0.0, home_R5_rlng_ps: 0.0, home_R5_fmb_pg: 0.0, home_D1_height: 188.0, home_D1_weight: 117.0, home_D1_age: 29.0, home_D1_av: 25.0, home_D1_games: 78.0, home_D1_gs: 48.0, home_D1_int_pg: 0.0641025641025641, home_D1_pick6_pg: 0.0128205128205128, home_D1_pd_pg: 0.1923076923076923, home_D1_ff_pg: 0.1025641025641025, home_D1_ftd_pg: 0.0, home_D1_sk_pg: 0.3012820512820512, home_D1_qbh_pg: 0.5384615384615384, home_D1_sltk_pg: 2.0384615384615383, home_D1_astk_pg: 1.358974358974359, home_D1_tfl_pg: 0.3846153846153846, home_D1_sfty_pg: 0.0, home_D2_height: 198.0, home_D2_weight: 140.0, home_D2_age: 33.0, home_D2_av: 50.0, home_D2_games: 129.0, home_D2_gs: 117.0, home_D2_int_pg: 0.0077519379844961, home_D2_pick6_pg: 0.0, home_D2_pd_pg: 0.1317829457364341, home_D2_ff_pg: 0.0775193798449612, home_D2_ftd_pg: 0.0, home_D2_sk_pg: 0.2674418604651162, home_D2_qbh_pg: 0.4651162790697674, home_D2_sltk_pg: 2.2868217054263567, home_D2_astk_pg: 1.0465116279069768, home_D2_tfl_pg: 0.3488372093023256, home_D2_sfty_pg: 0.0, home_D3_height: 188.0, home_D3_weight: 147.0, home_D3_age: 32.0, home_D3_av: 91.0, home_D3_games: 156.0, home_D3_gs: 144.0, home_D3_int_pg: 0.0128205128205128, home_D3_pick6_pg: 0.0, home_D3_pd_pg: 0.1602564102564102, home_D3_ff_pg: 0.032051282051282, home_D3_ftd_pg: 0.0064102564102564, home_D3_sk_pg: 0.1217948717948717, home_D3_qbh_pg: 0.25, home_D3_sltk_pg: 2.3974358974358974, home_D3_astk_pg: 1.064102564102564, home_D3_tfl_pg: 0.2692307692307692, home_D3_sfty_pg: 0.0, home_D4_height: 196.0, home_D4_weight: 120.0, home_D4_age: 23.0, home_D4_av: 6.0, home_D4_games: 16.0, home_D4_gs: 14.0, home_D4_int_pg: 0.0, home_D4_pick6_pg: 0.0, home_D4_pd_pg: 0.25, home_D4_ff_pg: 0.1875, home_D4_ftd_pg: 0.0, home_D4_sk_pg: 0.375, home_D4_qbh_pg: 0.8125, home_D4_sltk_pg: 1.8125, home_D4_astk_pg: 1.5, home_D4_tfl_pg: 0.5625, home_D4_sfty_pg: 0.0, home_D5_height: 190.0, home_D5_weight: 117.0, home_D5_age: 23.0, home_D5_av: 7.0, home_D5_games: 16.0, home_D5_gs: 15.0, home_D5_int_pg: 0.0, home_D5_pick6_pg: 0.0, home_D5_pd_pg: 0.1875, home_D5_ff_pg: 0.0, home_D5_ftd_pg: 0.0625, home_D5_sk_pg: 0.25, home_D5_qbh_pg: 0.625, home_D5_sltk_pg: 3.125, home_D5_astk_pg: 1.25, home_D5_tfl_pg: 0.75, home_D5_sfty_pg: 0.0, home_D6_height: 188.0, home_D6_weight: 104.0, home_D6_age: 27.0, home_D6_av: 47.0, home_D6_games: 82.0, home_D6_gs: 80.0, home_D6_int_pg: 0.0365853658536585, home_D6_pick6_pg: 0.0, home_D6_pd_pg: 0.2195121951219512, home_D6_ff_pg: 0.1219512195121951, home_D6_ftd_pg: 0.0, home_D6_sk_pg: 0.0914634146341463, home_D6_qbh_pg: 0.2804878048780488, home_D6_sltk_pg: 5.743902439024391, home_D6_astk_pg: 3.024390243902439, home_D6_tfl_pg: 0.2926829268292683, home_D6_sfty_pg: 0.0, home_D7_height: 185.0, home_D7_weight: 94.0, home_D7_age: 27.0, home_D7_av: 23.0, home_D7_games: 66.0, home_D7_gs: 52.0, home_D7_int_pg: 0.2878787878787879, home_D7_pick6_pg: 0.0606060606060606, home_D7_pd_pg: 0.8636363636363636, home_D7_ff_pg: 0.0151515151515151, home_D7_ftd_pg: 0.0, home_D7_sk_pg: 0.0, home_D7_qbh_pg: 0.0, home_D7_sltk_pg: 2.8484848484848486, home_D7_astk_pg: 0.3939393939393939, home_D7_tfl_pg: 0.0909090909090909, home_D7_sfty_pg: 0.0, home_D8_height: 178.0, home_D8_weight: 92.0, home_D8_age: 24.0, home_D8_av: 3.0, home_D8_games: 12.0, home_D8_gs: 9.0, home_D8_int_pg: 0.25, home_D8_pick6_pg: 0.0833333333333333, home_D8_pd_pg: 0.75, home_D8_ff_pg: 0.1666666666666666, home_D8_ftd_pg: 0.0, home_D8_sk_pg: 0.0, home_D8_qbh_pg: 0.0, home_D8_sltk_pg: 3.4166666666666665, home_D8_astk_pg: 0.1666666666666666, home_D8_tfl_pg: 0.1666666666666666, home_D8_sfty_pg: 0.0, home_D9_height: 178.0, home_D9_weight: 88.0, home_D9_age: 26.0, home_D9_av: 22.0, home_D9_games: 52.0, home_D9_gs: 52.0, home_D9_int_pg: 0.2692307692307692, home_D9_pick6_pg: 0.0, home_D9_pd_pg: 0.8269230769230769, home_D9_ff_pg: 0.0769230769230769, home_D9_ftd_pg: 0.0, home_D9_sk_pg: 0.0192307692307692, home_D9_qbh_pg: 0.0192307692307692, home_D9_sltk_pg: 4.326923076923077, home_D9_astk_pg: 1.2307692307692308, home_D9_tfl_pg: 0.2115384615384615, home_D9_sfty_pg: 0.0, home_D10_height: 180.0, home_D10_weight: 90.0, home_D10_age: 30.0, home_D10_av: 22.0, home_D10_games: 106.0, home_D10_gs: 46.0, home_D10_int_pg: 0.0660377358490566, home_D10_pick6_pg: 0.0094339622641509, home_D10_pd_pg: 0.2547169811320754, home_D10_ff_pg: 0.0188679245283018, home_D10_ftd_pg: 0.0094339622641509, home_D10_sk_pg: 0.0188679245283018, home_D10_qbh_pg: 0.0377358490566037, home_D10_sltk_pg: 2.330188679245283, home_D10_astk_pg: 0.5660377358490566, home_D10_tfl_pg: 0.0471698113207547, home_D10_sfty_pg: 0.0, home_D11_height: 178.0, home_D11_weight: 88.0, home_D11_age: 27.0, home_D11_av: 15.0, home_D11_games: 64.0, home_D11_gs: 44.0, home_D11_int_pg: 0.125, home_D11_pick6_pg: 0.015625, home_D11_pd_pg: 0.53125, home_D11_ff_pg: 0.0625, home_D11_ftd_pg: 0.0, home_D11_sk_pg: 0.0, home_D11_qbh_pg: 0.03125, home_D11_sltk_pg: 3.578125, home_D11_astk_pg: 0.90625, home_D11_tfl_pg: 0.078125, home_D11_sfty_pg: 0.0, home_K_age: 29.0, home_K_av: 20.0, home_K_games: 116.0, home_K_fga_pg: 1.9396551724137927, home_K_fgm_pg: 1.646551724137931, home_K_fga_0-19_pg: 0.0086206896551724, home_K_fgm_0-19_pg: 0.0086206896551724, home_K_fga_20-29_pg: 0.603448275862069, home_K_fgm_20-29_pg: 0.5689655172413793, home_K_fga_30-39_pg: 0.7068965517241379, home_K_fgm_30-39_pg: 0.6206896551724138, home_K_fga_40-49_pg: 0.5, home_K_fgm_40-49_pg: 0.3534482758620689, home_K_fga_50+_pg: 0.0948275862068965, home_K_fgm_50+_pg: 0.0689655172413793, home_K_fglng_ps: 49.42857142857143, home_K_xpa_pg: 3.396551724137931, home_K_xpm_pg: 3.3879310344827585\n",
            "correct prediction\n",
            "Predicted: Home Win (100.00%), True: Home Win\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model.save('/content/sample_data/NFLmodel.keras')"
      ],
      "metadata": {
        "id": "SlX1CMGLFCx6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('NFLmodel.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "02ScCL5OFqmU",
        "outputId": "5125963d-78d0-4f7d-a9ff-5dd4a841178a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: NFLmodel.keras",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-05f671d3991c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NFLmodel.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: NFLmodel.keras"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}